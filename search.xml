<?xml version="1.0" encoding="utf-8"?>
<search>
  
    
    <entry>
      <title><![CDATA[GC之“Stop The World”]]></title>
      <url>%2F2017%2F03%2F01%2Fgc-stop-the-world-01%2F</url>
      <content type="text"><![CDATA[“Stop The World”是什么，和GC有什么关系？在谈这个之前，先简要叙述以下两点：1、对象内存分代2、JVM垃圾收集器 大家都知道，JVM内存堆可以简单分为年轻代、老年代、持久代；其中年轻代又分为三部分：1个Eden区和2个Survivor区域（From和To） JVM提供了多种垃圾收集器，例如：serial、parnew、parallel scavenge、serial old、parallelold、cms、G1；每种垃圾收集器采用的收集算法又不一样。 关于垃圾收集算法有标记-清除、复制算法、标记-整理、分代收集 回到正题，“Stop The World”是什么？因为JVM内存堆是分代的，不同的分代采用的垃圾收集器是不一样的；例如在JDK1.3.1之前Serial收集器是年轻代垃圾收集的唯一选择；Serial收集器，是单线程收集器，在进行垃圾收集时，必须暂停其他所有工作线程，直到它收集结束。这个就是Serial收集器的工作特性，我们也把这个特性称为“Stop The World”；自然我们会想到，“Stop The World”的存在，假如GC耗时较长，那么我们的系统会处于一种假死状态。当然随着JVM虚拟机的发展，“Stop The World”得到的很大的优化和缓解，具体大家可以了解CMS、G1垃圾收集器工作原理，大家也可以参考下我之前的读书笔记“读《深入理解Java虚拟机》-垃圾收集器”]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[可靠性设计之服务故障隔离]]></title>
      <url>%2F2017%2F02%2F22%2Fsystem-design-service-fault-isulate-01%2F</url>
      <content type="text"><![CDATA[案例场景程序首先做黑名单规则校验，将命中规则的黑名单数据先写入DB，后邮件发送给相关业务人员 一般步骤在做完黑名单规则校验之后，可以直接返回客户端命中结果，后面的写入DB和邮件发送操作可以放到线程池中异步进行。那么是不是两个操作都放到一个线程池中进行操作呢？当然不是，至于为什么，看下面分析 案例分析从业务场景分析得出，写入DB操作明显是主要业务，邮件发送是次要业务，所以从服务优先级考虑首先要保证的是主要业务的可用，然后再保证次要业务的可用。 再回到上面的问题，为什么不能将这两个操作放到同一个线程池中进行操作。 假如这两个操作从同一个池中取线程，第一个写入DB顺利完成，第二个发送邮件由于网络原因（如连接超时等）导致发送失败，这里的失败的结果可能导致线程夯住；最坏的结果会是随着服务请求的增多，因为发送邮件这个操作导致线程池资源耗尽，使得写入DB这个操作无法分配到可以用线程资源，进入队列中等待，这样可能会出现等待超时，导致写入DB操作被丢弃，从而导致DB数据丢失；这样因为一个次要业务不可用故障级联主要业务不可用是程序设计中不允许的。这里我们可以将写入DB操作分配到一个线程池，发送邮件操作分配到另外一个线程池，这样即使发送邮件操作失败导致线程池不可用，也不会影响到写入DB操作这个功能； 总结上面是关于服务故障隔离的一点点思路，也是我们能在代码层面进行实施的东西；其实关于服务故障隔离远不止这么简单，这里只是提供一点思路，就是从我们的业务进行分析，哪些是核心业务哪些是非核心业务，我们要做的就是优先保证核心业务的高可用，其次再是保证非核心业务的可用。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[集成Spring Security]]></title>
      <url>%2F2016%2F07%2F04%2Fspring-security-integration%2F</url>
      <content type="text"><![CDATA[SpringSecurity说明Spring Security是一个强大的和高度可定制的身份认证和访问控制框架。一个能够为基于Spring的企业应用系统提供声明式的安全访问控制解决方案的安全框架。它提供了一组可以在Spring应用上下文中配置的Bean，充分利用了Spring IoC，DI和AOP功能，为应用系统提供声明式的安全访问控制功能，减少了为企业系统安全控制编写大量重复代码的工作。 SpringSecurity核心点Spring Security核心是他提供的过滤器，默认情况下用到了以下过滤器，及通过实例化一个虚拟过滤器链来对这些过滤器进行递归调用，源码如下图： 集成代码集成代码已经托管到github上，Spring Security版本是3.2.0，项目结构是Maven]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[读《深入理解Java虚拟机》-类文件结构]]></title>
      <url>%2F2016%2F06%2F27%2Fjvm-note-classfile%2F</url>
      <content type="text"><![CDATA[读书笔记 JVM语言无关性 Java虚拟机作为一个通用的、机器无关的执行平台，任何其他语言的实现者都可以将Java虚拟机作为语言的产品交付媒介，虚拟机只识别Class文件，并不关心Class的来源是何种语言 class类文件的结构 Class文件是一组以8位字节为基础单位的二进制流，各数据项目严格按照顺序紧凑排列在Class文件中，中间没有任何分隔符 Class文件格式采用类似C语言结构体的伪结构来存储数据，这种伪结构只有两种数据类型：无符号数和表 无符号数 属于基本的数据类型 u1、u2、u4、u8来分别代表1、2、4、8个字节的无符号数 可以用来描述数字、索引引用、数量值或者按照UTF-8编码构成的字符串值 表 是由多个无符号数或者其他表作为数据项构成的复合数据类型 以“_info”结尾 整个class文件本质上就是一张表 下面来看下class文件格式中各个数据项的具体含义： 魔数与Class文件的版本magic：魔数（Magic Number），占用4个字节，作用是确定这个文件是否为一个能被虚拟机接受的class文件；值为：0xCAFEBABEminor_version：次版本号，占用2个字节major_version：主版本号，占用2个字节;Java的版本号是从45开始的，JDK1.1之后的每个JDK大版本发布，主版本号向上加1（JDK1.0-1.1使用了45.0-45.3的版本号）,例如JDK版本为1.7，可生成的Class文件主版本号最大值为51.0 常量池 占用Class文件空间最大的数据项目之一 constant_pool_count：常量池容量计数值，从1开始；例如：常量池容量十六进制数为0x0016，即十进制为22，就表示常量池中有21项常量；Class文件结构中只有常量池的容量计数是从1开始，其他的集合类型，例如接口索引集合、字段表集合、方法表集合等的容量计数都是从0开始的。 constant_pool：主要存放两大类常量：字面量(Literal)和符号引用(Symbolic References)字面量：文本字符串、声明为final的常量值等符号引用： 类和接口的全限定名 字段的名称和描述符 方法的名称和描述符 常量池中每一项常量都是一个表，一共有14种： 这14种表都有一个共同的特点，就是表开始第一位是一个u1类型的标志位(tag)，代表当前这个常量属于哪种常量类型 访问标志access_flags：用于识别一些类或接口层次的访问信息，包括：这个Class是类还是接口；是否定义为public类型；是否定义为abstract类型；如果是类的话，是否被声明为final等 access_flags中一共有16个标志位可以使用，当前只定义了其中8个，没有使用到的标志位要求一律为0 类索引、父类索引与接口索引集合Class文件中通过类索引（this_class）和父类索引（super_class）和接口索引集合（interfaces）这三项数据来确定这个类的继承关系。 下图显示类索引（this_class）查找全限定名的过程： 字段表集合用于描述接口或者类中声明的变量，字段包括类级变量和实例级变量，不包括方法内部声明的局部变量 字段修饰符放在access_flags项目中，与类中的access_flags项目类似，都是一个u2的数据类型，含义如下： 紧跟access_flags标志的是两项索引值：name_index和descriptor_index，都是对常量池的引用，分别代表字段的简单名称及字段和方法的描述符 对于数组类型，每一维度将使用一个前置的“[”字符来描述，例如定义一个“java.lang.String[][]”类型的二维数组，将被记录为：”[[Ljava/lang/String;“，一个整型数组“int[]”将被记录为“[I” 用描述符来描述方法时，按照先参数列表，后返回值的顺序描述，参数列表按照参数的严格顺序放在一组小括号“()”之内。例如方法 void inc()的描述符为“()V”,方法java.lang.String.toString()的描述符为“()Ljava/lang/String;”,方法int indexOf(char[]source,int sourceOffset,int sourceCount,char[]target,int targetOffset,int targetCount,int fromIndex)的描述符为“([CII[CIII)I” 字段表集合不会列出从超类或父接口中继承而来的字段 方法表集合Class文件存储格式对方法的描述与对字段的描述几乎采用了完全一致的方式 与字段相比，除去了volatile关键字和transient关键字对应的标志，增加了synchronized、native、strictfp和abstract关键字对应的标志 方法中的Java代码，经过编译器编译成字节码指令后，存放在方法属性表集合中一个名为“Code”的属性里面了 属性表集合为了能正确解析Class文件，在《Java虚拟机规范（Java SE 7）》版中，预定义了21项属性。 每个属性的名称都需从常量池中引用一个CONSTANT_Utf8_info类型的常量来表示，而属性值的结构则是完全自定义的，只需要通过一个u4的长度属性去说明属性值所占用的位数即可。 一个符合规则的属性表应该满足如下定义的结构： Code属性Java程序方法体中的代码经过Javac编译器处理后，最终变成字节码指令存储在Code属性中。 attribute_name_index：指向CONSTANT_Utf8_info型常量的索引，常量固定值为Codeattribute_length：属性值的长度，由于属性名称索引和属性长度一共为6字节，所以属性值的长度固定为整个属性表长度减去6个字节max_stack：操作数栈深度的最大值，在方法执行的任意时刻，操作数栈都不会超过这个深度，虚拟机运行的时候需要根据这个值来分配栈帧中的操作栈深度max_locals：局部变量所需的存储空间，单位是Slot，Slot是虚拟机为局部变量分配内存所使用的最小单位，对于长度不超过32位的数据类型，每个局部变量占用1个Slot，而double和long这两种64位的数据类型需要2个Slot来存放；局部变量表中的Slot是可以重用的，Javac编译器会根据变量的作用域来分配Slot给各个变量使用，然后计算出max_locals的大小code：存储Java源程序编译后生成的字节码指令code_length：字节码长度 LineNumberTable属性用于描述Java源码行号与字节码行号之间的对应关系；可以在javac中分别使用-g:none或-g:lines来选择取消或要求生成这项信息，如果不生成，对程序运行产生的最主要影响就是抛出异常时，堆栈中将不会显示出错的行号，并且在调试程序的时候，也无法按照源码行来设置断点 LocalVariableTable属性用于描述栈帧中局部变量表中的变量与Java源码中定义的变量之间的关系；可以在javac中分别使用-g:none或-g:vars来选择取消或生成该信息，如果没有生成，最大的影响就是当其他人引用这个方法时，所有参数名都将丢失，IDE将会使用诸如arg0、arg1的占位符代替原有的参数名 SourceFile属性记录生成这个Class文件的源码文件名称；可以分别使用javac的-g:none或-g:source来关闭或生成，如果不生成这项属性，当抛出异常时，堆栈中将不会显示出错代码所属的文件名 ConstantValue属性作用是通知虚拟机自动为静态变量赋值。只有被static关键字修饰的变量（类变量）才可以使用这项属性。 对于非static类型的变量（实例变量）的赋值，虚拟机是在实例构造器方法中进行对于类变量，在类构造器方法中或使用ConstantValue属性。目前Sun Javac编译器的选择是：如果同时使用final和static来修饰一个变量（常量），并且这个变量的数据类型是基本类型或者java.lang.String的话，就生成ConstantValue属性来进行初始化，如果没有被final修饰或者并非基本类型及字符串，则将会选择在方法中进行初始化 字节码指令简介这里不详细记录了，具体字节码介绍可以参考WIKI]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[读《深入理解Java虚拟机》-垃圾收集器]]></title>
      <url>%2F2016%2F06%2F23%2Fjvm-note-gc%2F</url>
      <content type="text"><![CDATA[读书笔记 对象生死 引用计数算法 优点：实现简单，判断效率也高 缺点：很难解决对象之间互相循环引用的问题 Java虚拟机里面没有选用引用计数算法来管理内存 可达性分析算法 主流的商业程序语言（Java、C#）的主流实现中，都是通过可达性分析来判定对象是否存活的 基本思路：通过一系列的称为“GC Roots”的对象作为起始点，从这些节点开始向下搜索，搜索所走过的路径称为引用链（Reference Chain），当一个对象到GC Roots没有任何引用链相连时，则证明此对象是不可用的上图中，对象object 5、object 6、object 7 虽然互相有关联，但是他们到GC Roots是不可达的，所以他们将会被判定为是可回收的对象 在Java语言中，可作为GC Roots的对象包括下面几种： 虚拟机栈（栈帧中的本地变量表）中引用的对象 方法区中类静态属性引用的对象 方法区中常量引用的对象 本地方法栈中JNI引用的对象 引用 分为强引用、软引用、弱引用、虚引用 强引用：类似“Object obj = new Object()”这类的引用，只要强引用还存在，垃圾收集器永远不会回收掉被引用的对象 软引用：描述一些还有用但并非必须的对象。在系统将要发生内存溢出之前，将会把这些对象列进回收范围之中进行第二次回收。在JDK1.2之后，提供了SoftReference类来实现软引用 弱引用：描述非必须对象的，被弱引用关联的对象只能生存到下一次垃圾收集发生之前。当垃圾收集器工作时，无论当前内存是否足够，都会回收掉被弱引用关联的对象。在JDK1.2之后，提供了WeakReference类来实现弱引用 虚引用：也称为幽灵引用或幻影引用，是最弱的一种引用关系。无法通过虚引用来取得一个对象实例。为一个对象设置虚引用关联的唯一目的就是能在这个对象被收集器回收时收到一个系统通知。在JDK1.2之后，提供了PhantomReference类来实现虚引用 垃圾收集算法 标记-清除算法 最基础的收集算法，分为“标记”和“清除”两个阶段：首先标记出所有需要回收的对象，在标记完成后统一回收所有被标记的对象；后续的收集算法都是基于该算法的不足而进行改进得到的，主要不足有两方面： 效率问题：标记和清除两个过程的效率都不高 空间问题：标记清除后会产生大量不连续的内存碎片，空间碎片太多可能会导致以后在程序运行过程中需要分配较大对象时，无法找到足够的连续内存而不得不提前触发另一次GC操作 复制算法 为了解决标记-清除算法的效率问题而出现 原理：将可用内存按容量划分为大小相等的两块，每次只使用其中的一块。当这块的内存使用完了，就将还存活的对象复制到另外一块上去，然后再把已使用过的内存空间一次清理掉。这样内存分配时就不用考虑内存碎片等复杂情况了。 商业虚拟机都采用这种收集算法来回收新生代 标记-整理算法 针对老年代采用的收集算法 标记过程与“标记-清除”算法一样 原理：先标记所有待回收的对象，然后将所有存活的对象都向一端移动，然后直接清理掉端边界以外的内存 分代收集算法 当前商业虚拟机的垃圾收集都采用这种算法 思路：根据对象存活周期的不同将内存划分为几块，把java堆分为新生代和老年代，然后针对各个年代的特点采用最合适的收集算法。在新生代，每次GC都有大批对象死去，只有少量存活，就选用复制算法。老年代对象存活率高、没有额外空间对他进行分配担保，就必须使用“标记-清除”或“标记-整理”算法来进行回收 垃圾收集器上图展示了7种作用不同分代的收集器，如果两个收集器之间存在连线，就说明他们可以搭配使用。虚拟机所处的区域，则表示它是属于新生代收集器还是老年代收集器 serial收集器 单线程收集器 在进行垃圾收集时，必须暂停其他所有的工作线程，直到它收集结束 对于运行在Client模式下的虚拟机来说是一个很好的选择 parnew收集器 serial收集器的多线程版本 parallel scavenge收集器 使用复制算法的收集器，又是并行的多线程收集器 吞吐量优先收集器 serial old收集器 serial收集器的老年代版本 单线程收集器，使用标记-整理算法 parallel old收集器 parallel scavenge收集器的老年代版本 多线程收集器，使用标记-整理算法 cms收集器 CMS(Concurrent Mark Sweep)是一种以获取最短回收停顿时间为目标的收集器 整个过程分为4个步骤 初始标记(CMS initial mark) 停掉所有工作线程，仅仅是标记下GC Roots能直接关联到的对象，速度很快 并发标记(CMS concurrent mark) 进行GC Roots Tracing的过程，耗时最长的过程之一 重新标记(CMS remark) 停掉所有工作线程，为了修正并发标记期间因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段稍长一些，但远比并发标记的时间短 并发清除(CMS concurrent sweep) 耗时最长的过程之一 由于整个过程中耗时最长的并发标记和并发清除过程收集器线程都可以与用户线程一起工作，所以总体上来说CMS收集器的内存回收过程是与用户线程一起并发执行的 cms是一款优秀的收集器，并发收集、低停顿；也有如下缺点： 对CPU资源非常敏感 无法处理浮动垃圾 因为是基于标记-清除算法实现，所以会有大量空间碎片产生 G1收集器 当今收集器技术发展最前沿成果之一，面向服务端应用的垃圾收集器 与其他GC收集器相比，G1具备如下特点： 并行与并发 G1能充分利用多CPU、多核环境下的硬件优势来缩短Stop-The-World停顿的时间，部分其他收集器原本需要停顿Java线程执行的GC动作，G1收集器仍然可以通过并发的方式让Java程序继续执行 分代收集 空间整合 G1运作期间不会产生内存空间碎片，收集后能提供规整的可用内存 可预测的停顿 理解gc日志 垃圾收集器参数总结]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[读《深入理解Java虚拟机》-Java内存区域]]></title>
      <url>%2F2016%2F06%2F13%2Fjvm-note-javamemoryarea%2F</url>
      <content type="text"><![CDATA[读书笔记 运行时数据区域 程序计数器 一块较小的内存空间，是当前线程所执行的字节码的行号指示器，字节码解释器工作室就是通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等基础功能都需要依赖这个计数器来完成 这块内存区域为线程私有，每条线程都有一个独立的程序计数器，各线程之间计数器互不影响 此内存区域是Java虚拟机规范中没有规定任何OutOfMemoryError情况的区域 Java虚拟机栈 线程私有，生命周期同线程相同 每个方法从调用到执行完成的过程，对应着一个栈帧在虚拟机栈中入栈到出栈的过程 栈帧包含局部变量表、操作数栈、动态链接、方法出口等信息 Java虚拟机规范中对这个区域规定了两种异常状况： StackOverflowError：如果线程请求的栈深度大于虚拟机所允许的深度，抛出此异常 OutOfMemoryError：如果虚拟机栈扩展时无法申请到足够的内存，抛出此异常 本地方法栈 作用与Java虚拟机栈类似，只是本地方法栈为虚拟机使用到的Native方法服务 同样也会抛出StackOverflowError和OutOfMemoryError异常 Java堆 所有线程共享的区域 所有对象实例和数组在堆上进行分配内存 细分为：新生代、老年代；或Eden空间、From Survivor空间、To Survivor空间 无法扩展堆大小时会抛出OutOfMemoryError异常 方法区 所有线程共享的区域 存储被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据 Not-Heap(非堆)、永久代 对于HotSpot虚拟机，有放弃永久代并逐步改为采用Native Memory来实现方法区的规划，在目前已经发布的JDK1.7的HotSpot中，已经把原本放在永久代的字符串常量池移出了。可以看测试结果 无法满足内存分配需求时，将抛出OutOfMemoryError异常 运行时常量池 JDK1.7以前是方法区的一部分，JDK1.7以后是Java堆的一部分 存放字面量和符号引用 可以通过String类的intern()方法动态生成新的常量并放入池中 无法再申请到内存时会抛出OutOfMemoryError异常 直接内存 不是虚拟机运行时数据区的一部分，也不是Java虚拟机规范中定义的内存区域 NIO引入了一种基于通道（Channel）和缓冲区（Buffer）的I/O方式，可以使用Native函数库直接分配堆外内存，然后通过一个存储在Java堆中的DirectByteBuffer对象作为这块内存的引用进行操作。这样能在一些场景中显著提高性能，因为避免了在java堆和Native堆中来回复制数据 受本机总内存（包括RAM以及SWAP区或者分页文件）大小以及处理器寻址空间的限制，会抛出OutOfMemoryError异常 hotspot虚拟机对象探秘 对象的创建 在语言层面上，创建对象通常仅仅是一个new关键字而已，而在虚拟机中，对象(普通java对象)的创建会经过如下步骤： 虚拟机遇到一条new指令时，首先检查这个指令的参数能否在常量池中定位到一个类的符号引用 检查这个符号引用代表的类是否已被加载、解析和初始化过。如果没有，那必须先执行相应的类加载过程 类加载检查通过后，虚拟机将为新生对象分配内存（对象所需内存的大小在类加载完成后便可完全确定） 修改内存指针，并发下会出现线程安全，虚拟机采用了CAS或TLAB(本地线程分配缓冲)来解决 虚拟机对对象进行必要的设置，例如这个对象是哪个类的实例、如何找到类的元数据信息、对象的哈希码、对象的GC分代年龄、是否启用偏向锁等信息，这些信息都是存放在对象头中 完成上面的工作，从虚拟机的视觉来看，一个新的对象已经产生了，但是从Java程序的视觉来看，还需要执行方法来完成对象的初始化，这样一个真正可用的对象才算完全产生出来 对象的内存布局 对象头（Header） 存储自身的运行数据：如哈希码（HashCode）、GC分代年龄、锁状态标志、线程持有的锁、偏向线程ID、偏向时间戳等 类型指针，即对象指向它的类元数据的指针 实例数据（Instance Data） 对象真正存储的有效信息，也是在程序代码中定义的各种类型的字段内容 对齐填充（Padding） 不是必然存在，也没有特别的含义，仅仅起着占位符的作用 由于HotSpot VM的自动内存管理系统要求对象起始地址必须是8字节的整数倍，也就是对象的大小必须是8字节的整数倍，而对象头部分刚好是8字节的整数倍，因此，当对象实例数据部分没有对齐时，就需要通过对齐填充来补全 对象的访问定位 Java程序是通过栈上的reference数据来操作堆上的具体对象，由于reference类型在Java虚拟机规范中只规定了一个指向对象的引用，并没有定义这个引用应该通过何种方式去定位、访问堆中的对象的具体位置，所以对象访问方式也是取决于虚拟机实现而定的。 句柄访问 直接指针 两种对象访问各有优缺点，虚拟机Sun HotSpot使用的是第二种方式进行对象访问的]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[读《深入理解Java虚拟机》-高效并发]]></title>
      <url>%2F2016%2F06%2F02%2Fjvm-note-concurrent%2F</url>
      <content type="text"><![CDATA[读书笔记 java内存模型与线程 硬件的效率与一致性 处理器为了更快速的读写内存，引入了高速缓存；为了缓存一致性问题，各处理器访问缓存时需要遵循一些协议（MSI、MESI、MOSI、Synapse、Firefly、Dragon Protocol） 内存模型：在特定的操作协议下，对特定的内存或高速缓存进行读写访问的过程抽象 乱序执行优化：程序语句的计算先后顺序与输入代码的顺序可能不一致，但是结果是一致的。这样做是为了使得处理效率更高 Java内存模型 JMM：(Java Memory Model)来屏蔽各种硬件和操作系统的内存访问差异，让java程序在各种平台下都能达到一致的内存访问效果。 1、线程对变量的所有操作都必须在工作内存中进行，不能直接读写主内存中的变量 2、线程之间不能互相访问各自的工作内存，需要通过主内存来完成变量值的传递 内存间交互操作：关于主内存和工作内存之间具体的交互协议，JMM定义了8种操作（lock、unlock、read、load、use、assign、store、write）来完成，每一种操作都是原子的、不可再分的（对于double和long类型的变量来说，有例外，可以不用考虑例外） volatile关键字： 具备可见性和一致性，但是基于volatile变量的运算在并发下可能存在不安全的问题，仍然需要通过加锁（synchronized或java.util.concurrent中的原子类）来保证原子性。 禁止指令重排序优化，JVM默认会对指令进行重排序优化，但是指令重排序优化会对程序的并发执行造成干扰，使用volatile可以禁止指令重排序优化 与其他并发工具的比较: 在某些情况下，volatile的同步机制的性能要优于锁（synchronized或java.util.concurrent包里面的锁），但是由于虚拟机对锁实现了许多的消除和优化，使得很难量化的认为volatile就会比synchronized快多少。 volatile变量的读操作的性能消耗与普通变量几乎没有什么差别，但是写操作可能会慢些，因为需要在本地代码中插入许多内存屏障指令来保证处理器不发生乱序执行。 volatile与锁之间选择的唯一依据是volatile的语义能否满足使用场景的需求 原子性 1、由Java内存模型来直接保证的原子性变量操作包括read、load、assign、use、store和write，我们大致可以认为基础数据类型的访问读写是具备原子性的（long和double的例外可以不用考虑） 2、应用场景需要更大范围的原子性保证，可以使用synchronized关键字。 可见性 1、一个线程修改了共享变量的值，其他线程能立即得知这个修改。 2、volatile、synchronized和final都可以保证共享变量的可见性 有序性 1、volatile、synchronized来保证线程之间操作的有序性 先行发生原则 Java与线程 java线程调度：协同式线程调度、抢占式线程调度（Java线程默认） 状态转换： 新建(New)：创建后未启动的线程 运行(Runable)：线程正在运行或可能正在等待CPU为它分配执行时间 无限期等待(Waiting)：不会被分配CPU执行时间，要等待被其他线程显式唤醒，以下方法会让线程处于无限期的等待状态： 没有设置Timeout参数的Object.wait()方法。 没有设置Timeout参数的Thread.join()方法 LockSupport.park()方法 限期等待(Timed Waiting)：不会被分配CPU执行时间，不需要等待被其他线程显式唤醒，在一定时间之后它们会由系统自动唤醒，以下方法会让线程处于限期的等待状态： Thread.sleep()方法 设置了Timeout参数的Object.wait()方法 设置了Timeout参数的Thread.join()方法 LockSupport.parkNanos()方法 LockSupport.parkUntil()方法 阻塞(Blocked)：线程被阻塞了，在等待获取一个排它锁。例如线程A和B在执行同步方法C时，线程A先拿到排它锁，那么线程B的状态就是阻塞状态，等待线程B释放排它锁 结束(Terminated)：线程执行完毕 线程安全与锁优化 线程安全 Java语言中的线程安全: 不可变：final定义 绝对线程安全：例如Vector是一个线程安全的容器，他的add()、get()和size()方法都被synchronized修饰，但是在多线程环境下(两个线程同时分别调用add、get方法)，如果不在方法调用端做额外的同步措施的话，可以说使用还是会存在线程不安全。 相对线程安全：大部分线程安全类都属于这种类型，例如Vector、HashTable、Collections的synchronizedCollection()方法包装的集合 线程兼容：指对象本身并不是线程安全的，但是可以通过在调用端正确的使用同步手段来保证对象在并发环境中可以安全的使用，我们平常说一个类不是线程安全，绝大多数指这种情况 线程对立：指无论调用端是否采取同步措施，都无法在多线程环境中并发使用的代码 线程安全实现的方法: 互斥同步：临界区、互斥量和信号量都是主要的互斥实现方法；互斥是因，同步是果；互斥是方法，同步是目的； synchronized：java中实现互斥同步的重要手段；是一个重量级的操作，会将用户态转换到核心态中，这种转换很耗费处理器时间。有可能状态转换消耗的时间比用户代码执行的时间还要长。虚拟机本身也进行了一些优化，例如在通知操作系统阻塞线程之前加入一段自旋等待过程，避免频繁的切入到核心态之中。 ReentrantLock：同synchronized功能类似，相比前者，ReentrantLock增加了一些高级功能：等待可中断、可实现公平锁、锁可以绑定多个条件 非阻塞同步：基于冲突检测的乐观并发策略-CAS java.util.concurrent包里面的整数原子类，其中的compareAndSet()和getAndIncrement()等方法都使用了Unsafe类的CAS操作。 锁优化 自旋锁与自适应自旋：避免用户态到内核态的切换 锁消除：对代码上要求同步，但是被检测到不可能存在共享数据竞争的锁进行消除 锁粗化：锁同步范围扩展。例如：如果在循环里对同一个对象加锁，虚拟机会默认将锁同步的范围扩展（粗化）至循环体外部，这样就只需要加锁一次。 轻量级锁：在无竞争的情况下使用CAS操作去消除同步使用的互斥量 偏向锁：在无竞争的情况下把整个同步都消除掉]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Oracle之登录安全]]></title>
      <url>%2F2016%2F05%2F31%2Foracle-login-security-01%2F</url>
      <content type="text"><![CDATA[在安装完oracle数据库后，打开终端输入：sqlplus / as sysdba; 可以在不输入密码的情况下登录到sys用户。这种登录方式是采用操作系统认证； 这样要是谁混进了我们的数据库服务器都可以这种方式登录。这种默认配置使得数据库存在安全隐患； 可以通过修改如下配置使其必须通过密码验证方式登录1、找到文件：%ORACLE_HOME%\NETWORK\ADMIN\sqlnet.ora2、修改文件内容：SQLNET.AUTHENTICATION_SERVICES= (none) 修改完成后要重启实例；shutdown immediate;// shutdown abort;startup;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[修改Android Studio工程目录结构]]></title>
      <url>%2F2016%2F05%2F16%2Fandroidstudio-modify-workstruct-01%2F</url>
      <content type="text"><![CDATA[接上一篇，我们已将Eclipse中的Android项目导入到Android Studio2.0中，并能成功运行起来。 细心的可以发现，Android Studio为我们添加了些新的文件和文件夹：settings.gradle、build.gradle、gradle、app … 其中app中包含了Android项目源代码，这是AS将所有代码按照既定格式复制过去了，这样就存在两处源代码。这当然不是我们想要的结果，我们想要的是依旧使用Eclipse目录结构来进行开发。 针对上面的问题，接下来，我们做下简单的配置，以便于在Eclipse和Android Studio中都能很好的进行协同开发。 找到工程(TV)下面的build.gradle配置文件。 步骤：step1：将app目录下build.gradle内容复制到工程(TV)下的build.gradle里面。step2：关键的一步，在Android闭包中增加如下代码 sourceSets { main { manifest.srcFile &#39;AndroidManifest.xml&#39; assets.srcDirs = [&#39;assets&#39;] res.srcDirs = [&#39;res&#39;] resources.srcDirs = [&#39;src&#39;] java.srcDirs = [&#39;src&#39;] } } step3：Rebuild Project 通过上面的步骤，就可以将AndroidStudio目录结构同Eclipse一样了。 最后，可以将多余的文件进行删除：app]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[利用Android Studio2.0导入Eclipse项目]]></title>
      <url>%2F2016%2F05%2F12%2Fandroid-import-as2-01%2F</url>
      <content type="text"><![CDATA[Android Studio2.0以及能够很友好的支持Eclipse项目导入。当选择Import Project，Android Studio2.0会自动添加Gradle相关支持，我们要做的是对相关的SDK、BuildTools、JDK版本做下适当配置即可。 不过，如果选择Project from Version Control从版本控制中导入项目时，AS不会添加Gradle相关支持。所以这里可以先从版本库中将代码Check Out到本地，然后利用Import Project导入即可。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[webpack入门教程]]></title>
      <url>%2F2016%2F04%2F13%2Fwebpack-tutorials-01%2F</url>
      <content type="text"><![CDATA[本篇是webpack的入门教程，通过本教程来引导大家完成一些小例子。 目录 安装webpack 使用webpack 使用loaders 使用developement server 安装webpack前提是需要已经安装了node.js npm install webpack -g 进行全局安装，这样webpack命令就可以正常使用了 使用webpack先创建一个空目录在目录下创建如下文件：add entry.js document.write(&quot;hello world&quot;); add index.html &lt;html&gt; &lt;head&gt; &lt;meta charset=&quot;utf-8&quot;&gt; &lt;/head&gt; &lt;body&gt; &lt;script type=&quot;text/javascript&quot; src=&quot;bundle.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt; &lt;/body&gt; &lt;/html&gt; 接下来运行程序: webpack ./entry.js bundle.js 程序会完成编译并创建一个bundle.js文件.如果程序运行成功你就能看到如下显示： Hash: ac9248475027b987a559 Version: webpack 1.12.15 Time: 39ms Asset Size Chunks Chunk Names bundle.js 1.42 kB 0 [emitted] main [0] ./entry.js 30 bytes {0} [built] 在浏览器中打开index.html，页面会显示 hello world 接下来，我们将一部分代码移到外部文件中.add content.js module.exports = &quot;hello world from content.js&quot;; update entry.js - document.write(&quot;hello world&quot;); + document.write(require(&quot;./content.js&quot;)); 接着重新编译： webpack ./entry.js bundle.js 刷新浏览器你应该能看到： hello world from content.js 使用loaders接下来我们想添加一个css文件到我们的程序中。 webpack默认只能处理JavaScript文件，所以我们需要使用css-loader和style-loader来处理css文件。 运行npm install css-loader style-loader进行安装加载器。 接下来我们做如下操作：add style.css body{ background:#FF0000; } update entry.js + require(&quot;!style!css!./style.css&quot;); document.write(require(&quot;./content.js&quot;)); 重新运行编译并刷新浏览器，你应该能看到浏览器输出hello world from content.js并且背景是红色; 在上面entry.js文件中require(&quot;!style!css!./style.css&quot;);表示使用style和css加载器来加载style.css文件,如果我们不想在文件中指定加载器，可以这样做： update entry.js - require(&quot;!style!css!./style.css&quot;); + require(&quot;./style.css&quot;); document.write(require(&quot;./content.js&quot;)); 运行编译： webpack ./entry.js bundle.js --module-bind &quot;css=style!css&quot; 注意上面必须是双引号 运行的结果和之前是一样的 接下来我们将配置项移到一个配置文件中：add webpack.config.js module.exports = { entry: &quot;./entry.js&quot;, output: { path: __dirname, filename: &quot;bundle.js&quot; }, module: { loaders: [ { test: /\.css$/, loader: &quot;style!css&quot; } ] } }; 现在我们运行编译： webpack 编译输出： Hash: ac9248475027b987a559 Version: webpack 1.12.15 Time: 39ms Asset Size Chunks Chunk Names bundle.js 1.42 kB 0 [emitted] main [0] ./entry.js 30 bytes {0} [built] ... webpack命令会尝试在当前目录加载webpack.config.js文件 输出设置如果项目编译是时间比较长，我们想显示进度条，可以通过如下配置： webpack --progress --colors 监视模式我们不想当文件发生改变每次都要重新进行编译。可以通过如下配置： webpack --progress --colors --watch 使用developement server先安装 npm install webpack-dev-server -g 然后运行 webpack-dev-server --progress --colors 通过http://localhost:8080/webpack-dev-server/bundle 来访问； 服务以监控模式在运行。 参考webpack.github.io]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[webpack 是什么？]]></title>
      <url>%2F2016%2F04%2F13%2Fwebpack-what-01%2F</url>
      <content type="text"><![CDATA[webpack是一个模块打包工具。 为什么业界已经存在很多模块打包工具,为什么又要做一个出来？ 业界存在的模块打包工具都不适合于大型项目（大型单页面应用）. 急欲推出这个模块打包工具是因为它包含了Code Splitting(模块按需加载)和将所有静态资源整合的功能。 作者尝试了去扩展已存在的模块打包工具，但是都不能实现所有目标。 目标 将依赖树分割成按需加载 保存较短的初始化加载时间 所有的静态资源都是一个模块 具备集成第三方库的能力 具备可定制化的功能 适合于大型项目 webpack有什么不同Code Splittingwebpack依赖有同步和异步两种模式，异步依赖会通过一个新chunk来作为分割点，然后循环chunk按需加载。 Loaderswebpack默认只能处理JavaScript文件，但是它提供了很多加载器来将其他静态资源转换成JavaScript文件，通过这样做，每个静态资源都是一个模块。 Clever parsingwebpack具有一个非常灵活的解析器，能处理差不多每一个第三方库.在依赖中它允许的表达式如：require(&quot;./templates/&quot;+name+&quot;.jade&quot;).它能处理大部分公共模块样式：CommonJS和AMD Plugin systemwebpack具有丰富的插件系统，很多内部特性都是基于这个插件系统。允许自定义插件 参考webpack.github.io]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[使用gulp来压缩hexo中的静态资源文件]]></title>
      <url>%2F2016%2F03%2F25%2Fgulp-compress-hexo-01%2F</url>
      <content type="text"><![CDATA[标题取的有点模糊不清，主要是想说下如何通过gulp来压缩hexo生成的html、js、css、png内容 前言gulp：基于nodejs流的自动化构建工具关于gulp的介绍与安装请自行参考官网描述，本章不做阐述 步骤Step1：hexo根目录新增gulpfile.js文件var gulp = require(&#39;gulp&#39;); //html压缩 var htmlmin = require(&#39;gulp-htmlmin&#39;); //js压缩 var jsmin = require(&#39;gulp-jsmin&#39;); //文件重命名 var rename = require(&#39;gulp-rename&#39;); //图片压缩png/jpg/gif var imagemin = require(&#39;gulp-imagemin&#39;); //png压缩 var pngquant = require(&#39;imagemin-pngquant&#39;); //css压缩 var csso = require(&#39;gulp-csso&#39;); var root = &quot;./public&quot;; var buildDir = root; var datas={ html:[root+&quot;/**/*.html&quot;], image:[root+&quot;/**/*.png&quot;], css:[root+&quot;/**/*.css&quot;], js:[root+&quot;/**/*.js&quot;,&#39;!*min.js&#39;] } // 压缩html gulp.task(&quot;htmlmin&quot;,function(){ gulp.src(datas.html) .pipe(htmlmin({collapseWhitespace:true,minifyJS:true,minifyCSS:true,removeComments:true})) .pipe(gulp.dest(buildDir)); }); // png图片压缩 gulp.task(&quot;imagemin&quot;,function(){ gulp.src(datas.image) .pipe(imagemin({ progressive:true, svgoPlugins:[{removeViewBox:false}], use:[pngquant()] //压缩率64% })) .pipe(gulp.dest(buildDir)); }); // js压缩 gulp.task(&quot;jsmin&quot;,function(){ gulp.src(datas.js) .pipe(jsmin()) //.pipe(rename({suffix:&#39;.min&#39;})) .pipe(gulp.dest(buildDir)); }); // css压缩 gulp.task(&quot;cssmin&quot;,function(){ gulp.src(datas.css) .pipe(csso()) .pipe(gulp.dest(buildDir)); }); gulp.task(&quot;default&quot;,[&quot;htmlmin&quot;,&quot;imagemin&quot;,&quot;jsmin&quot;,&quot;cssmin&quot;]); Step2：执行命令hexo clean hexo ge gulp hexo d 最后gulp提供了相当多的插件，大家可以自行去了解使用，还是挺好使的 参考gulp官网gulp中文]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[系统集成项目管理相关的标准规范]]></title>
      <url>%2F2016%2F03%2F18%2Fsi-pme-gb-01%2F</url>
      <content type="text"><![CDATA[本篇记录基于《系统集成项目管理工程师教程》”第21.6.2 标准”章节。自己在网上把相关的标准搜罗了一番，该教程上面的部分标准已经废弃，本篇已经做了更新，截至目前下面所列的标准都是最新的并提供了下载。便于自己随时查阅也方便有需要的伙伴下载。 基础标准1、GB/T 11457-2006 软件工程术语 下载本标准定义软件工程领域中通用的术语，适用于软件开发、使用维护、科研、教学和出版 2、GB/T 1526-1989 信息处理数据流程图、程序流程图、系统流程图、程序网络图和系统资源图的文件编制符号及约定 下载本标准规范了常用的图形符号的画法，增强了相关流程图的可读性，也方便人员之间的交流和对同一事务的共同理解。 3、GB/T 14085-1993 信息处理系统 计算机系统配置图符号及约定 下载本标准规定了计算机系统配置图中所使用的图形符号及其约定。 开发标准1、GB/T 8566-2007 软件生存周期过程 下载本标准给出了软件完整生存周期中所涉及的各个过程的一个完整集合，并可以根据自己项目的实际对这些过程进行裁剪 2、GB/T 15853-1995 软件支持环境 下载本标准规定了软件支持环境的基本要求，软件开发支持环境的内容及实现方法，以及对软件生存期支持部门软件支持能力的具体要求。 3、GB/T 14079-1993 软件维护指南 下载本标准描述软件维护的内容和类型、维护过程及维护的控制和改进 文档标准1、GB/T 16680-1996 软件文档管理指南 下载本标准描述了如何关于如何编制文档，文档编制有哪些编制和指南，如何制定文档编制计划，如何确定文档管理的各个过程，文档管理需要哪些资源 2、GB/T 8567-2006 计算机软件文档编制规范 下载本标准给出了软件项目开发过程中相关的25种文件的编制指导。 3、GB/T 9385-2008 计算机软件需求说明编制指南 下载本标准给出了软件项目开发过程中编制软件需求说明书的详细指导。 管理标准1、GB/T 12505-1990 计算机软件配置管理计划规范 下载本标准规定了在制定软件配置管理计划时应该遵循的统一的基本要求。 2、GB/T 16260-2006 软件工程产品质量规范 下载本标准描述了如何使用质量特性来评价软件质量，分4部分：质量模型、外部度量、内部度量、使用质量的度量 3、GB/T 12504-1990 计算机软件质量保证计划规范 下载本标准规定了在制定软件质量保证计划时应该遵循的统一的基本要求。 4、GB/T 14394-2008 计算机软件可靠性和可维护性管理 下载本标准规定了软件产品在其生存周期内如何选择适当的软件可靠性和可维护性管理要素，并指导软件可靠性和可维护性大纲的制定与实施。 参考 标准分享网 中国国家标准化管理委员会]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[记录-公司官网开发]]></title>
      <url>%2F2016%2F03%2F17%2Fjx-website%2F</url>
      <content type="text"><![CDATA[这段时间一直在协同美工对公司官网做改版，应该说是重新设计开发。忙活了一段时间，今天终于收工了。官网做的比较小，一些基本的信息展示和简单的表单提交，个人对美工给的这个效果图表示有点小失望，设计的没有想象中的高端大气。这个版本是针对pc端，没有做响应式设计，计划是后期单独为移动端做页面。前端使用了简单的html+css+js，后端使用的是asp.net mvc框架。下面发几张效果图特此记录该里程： 首页 产品服务 产品明细 营业网点 新闻中心 加入我们]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[从GitCafe迁移到Coding]]></title>
      <url>%2F2016%2F03%2F07%2Fgitcafe-to-coding-of-pages%2F</url>
      <content type="text"><![CDATA[在上周，Coding宣布收购Gitcafe，且Gitcafe平台将在5月31日后关闭服务。因为我的博客是部署在Gitcafe上的，所以不得已需要将其迁移到Coding平台上去。整个修改步骤也比较容易。 项目迁移我们可以直接将Gitcafe上面的库迁移到Coding上来，也可以重新在Coding上新建库都是可以的。如果要迁移，官网也提供了一键迁移的操作页面，这里就不描述了。 Coding平台新建一个分支：coding-pages 开启Pages服务并绑定自定义域名 _config.yml在全局_config.yml中deploy新增coding节点 deploy: type: git repo: coding: https://git.coding.net/hunterlin/hunterlin.git,coding-pages]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[读《深入理解Java虚拟机》-内存分配]]></title>
      <url>%2F2016%2F03%2F04%2Fjvm-note-memory-allocation%2F</url>
      <content type="text"><![CDATA[读到第3.6节，跟着文中作者的介绍与描述做了相关内容的测试，特做此记录。 前言本篇参考3.6节中的三小节分别来理解和测试相关内容： 对象优先在Eden分配 大对象直接进入老年代 长期存活的对象将进入老年代 对象优先在Eden分配大多数情况，对象在新生代Eden区中分配内存，当Eden区没有足够的空间进行分配时，虚拟机将发起一次Minor GC。 下面我们通过具体代码来分析对象在新生代中的分配情况： /** * VM Args: * -Xms20M -Xmx20M -Xmn10M #Java堆大小为20m，不可扩展，其中10m分配给年轻代，剩下10m分配给老年代 * -XX:SurvivorRatio=8 #设置为8,则两个Survivor区与一个Eden区的比值为2:8,一个Survivor区占整个年轻代的1/10，Eden区占8/10 * -XX:+PrintGCDetails #打印GC日志 * -XX:+UseSerialGC #使用Serial+Serial Old的收集器组合进行内存回收 */ public class TestMemoryAlloc { private static final int _1MB = 1024*1024; public static void main(String[] args) { byte[] allocation1,allocation2,allocation3,allocation4; allocation1 = new byte[2*_1MB]; allocation2 = new byte[2*_1MB]; allocation3 = new byte[2*_1MB]; allocation4 = new byte[4*_1MB];//发生第一次Minor GC } } 根据虚拟机参数初始新生代的内存是这样： main方法中分配了3个2MB大小和1个4MB大小的对象，当在进行allocation4分配的时候会触发第一次MinorGC操作。 因为allocation4对象需要分配4MB的内存空间，此时Eden已经被前面3个2MB的对象占用了共6MB的大小，Eden还剩余2MB的大小(总Eden空间大小是8192K)，所以在进行allocation4分配的时候由于Eden空间不足会触发第一次MinorGC操作。 MinorGC操作(采用“复制算法”)会将Eden区的3个2MB对象复制到Survivor区域，由于Survivor区域总大小只有1024K，分配不下3个2MB大小的对象，所以只好通过分配担保机制提前将3个2MB的对象转移到年老代中过去。 最后MinorGC操作完成后，Eden分配着4MB的allocation4对象，Survivor区空闲，年老代分配了总共6MB(allocation1,allocation2,allocation3)的对象，下面我们通过GC日志来验证这点。 [GC[DefNew: 7146K-&gt;484K(9216K), 0.0047529 secs] 7146K-&gt;6628K(19456K), 0.0047906 secs] [Times: user=0.00 sys=0.00, real=0.01 secs] Heap def new generation total 9216K, used 4746K [0x00000000f9a00000, 0x00000000fa400000, 0x00000000fa400000) eden space 8192K, 52% used [0x00000000f9a00000, 0x00000000f9e297b0, 0x00000000fa200000) from space 1024K, 47% used [0x00000000fa300000, 0x00000000fa3791a8, 0x00000000fa400000) to space 1024K, 0% used [0x00000000fa200000, 0x00000000fa200000, 0x00000000fa300000) tenured generation total 10240K, used 6144K [0x00000000fa400000, 0x00000000fae00000, 0x00000000fae00000) the space 10240K, 60% used [0x00000000fa400000, 0x00000000faa00030, 0x00000000faa00200, 0x00000000fae00000) compacting perm gen total 21248K, used 2582K [0x00000000fae00000, 0x00000000fc2c0000, 0x0000000100000000) the space 21248K, 12% used [0x00000000fae00000, 0x00000000fb085a70, 0x00000000fb085c00, 0x00000000fc2c0000) No shared spaces configured. [GC[DefNew: 7146K-&gt;484K(9216K), 0.0047529 secs] 7146K-&gt;6628K(19456K), 0.0047906 secs]可以看到新生代总内存9216K，由GC前占用的7146K回收到了484K，Java堆内存从7146K到6628K几乎没有怎么变化，因为GC回收时四个对象仍然是可用的(存在Eden和老年代中)。 def new generation total 9216K, used 4746K新生代总内存9216K，已经使用了4746K，被占用的区域就是Eden区 eden space 8192K, 52% used新生代中Eden的内存为8192K，已经被使用了52%，就是被allocation4对象占用着 to space 1024K, 0%Survivor to区总大小1024k，空闲 tenured generation total 10240K, used 6144K年老代总内存10240K，已经被allocation1,allocation2,allocation3三个对象占用了6144K。 通过GC日志的分析已经证明了我们上面提到的内存分配规则。 大对象直接进入老年代大对象是指需要大量连续内存空间的Java对象，写程序的时候要尽量避免大对象，经常出现大对象容易导致内存还有不少空间时候就提前触发垃圾收集以获取足够的内存空间来安放这些大对象。 下面我们还是通过代码来分析下，将上面代码中allocation4对象的大小改为8MB： /** * VM Args: * -Xms20M -Xmx20M -Xmn10M #Java堆大小为20m，不可扩展，其中10m分配给年轻代，剩下10m分配给老年代 * -XX:SurvivorRatio=8 #设置为8,则两个Survivor区与一个Eden区的比值为2:8,一个Survivor区占整个年轻代的1/10，Eden区占8/10 * -XX:+PrintGCDetails #打印GC日志 * -XX:+UseSerialGC #使用Serial+Serial Old的收集器组合进行内存回收 */ public class TestMemoryAlloc { private static final int _1MB = 1024*1024; public static void main(String[] args) { byte[] allocation1,allocation2,allocation3,allocation4; allocation1 = new byte[2*_1MB]; allocation2 = new byte[2*_1MB]; allocation3 = new byte[2*_1MB]; allocation4 = new byte[8*_1MB]; } } 我们看下运行之后的GC日志： Heap def new generation total 9216K, used 7310K [0x00000000f9a00000, 0x00000000fa400000, 0x00000000fa400000) eden space 8192K, 89% used [0x00000000f9a00000, 0x00000000fa123978, 0x00000000fa200000) from space 1024K, 0% used [0x00000000fa200000, 0x00000000fa200000, 0x00000000fa300000) to space 1024K, 0% used [0x00000000fa300000, 0x00000000fa300000, 0x00000000fa400000) tenured generation total 10240K, used 8192K [0x00000000fa400000, 0x00000000fae00000, 0x00000000fae00000) the space 10240K, 80% used [0x00000000fa400000, 0x00000000fac00010, 0x00000000fac00200, 0x00000000fae00000) compacting perm gen total 21248K, used 2582K [0x00000000fae00000, 0x00000000fc2c0000, 0x0000000100000000) the space 21248K, 12% used [0x00000000fae00000, 0x00000000fb085a70, 0x00000000fb085c00, 0x00000000fc2c0000) No shared spaces configured. 通过日志发现在分配allocation4对象内存的时候并没有触发GC操作，而是将allocation4对象直接分配到了老年代中。 另外虚拟机提供了-XX:PretenureSizeThreshold参数(默认是0)，令大于这个设置值的对象直接在老年代分配。这样做的目的是避免在Eden区和两个Survior区之间发生大量的内存复制(复制算法收集内存)操作。 PS:PretenureSizeThreshold参数只对Serial和ParNew两款收集器有效 长期存活的对象将进入老年代虚拟机采用分代收集的思想来管理内存，那么内存回收时如何识别哪些对象应该在新生代，哪些对象应该在老年代中。为了做到这点，虚拟机给每个对象定义了一个对象年龄计数器。即对象在Eden中出生并经过第一次Minor GC后仍然存活的且能被Survivor容纳的，将被移动到Survivor空间中，并且对象年龄设为1。对象在Survivor空间每熬过一次Minor GC，年龄就增加1，当它的年龄增加到一定程度（默认是15），就将会被迁移到老年代中。对象迁移老年代的年龄阈值可以通过参数-XX:+MaxTenuringThreshold设置。 下面我们分别通过参数-XX:+MaxTenuringThreshold=1和-XX:+MaxTenuringThreshold=15设置对象的年龄为1和15来验证下： -XX:+MaxTenuringThreshold=1 /** VM Args: -Xms20m -Xmx20m -Xmn10m -XX:+PrintGCDetails -XX:SurvivorRatio=8 -XX:MaxTenuringThreshold=1 -XX:+UseSerialGC -XX:+PrintTenuringDistribution **/ public class TestMaxTenuringThreshold { private static final int _1MB = 1024*1024; public static void main(String[] args) { //什么时候进入老年代取决于XX:MaxTenuringThreshold设置 byte[]allocation1,allocation2,allocation3; allocation1 = new byte[_1MB / 4]; allocation2 = new byte[4 * _1MB]; allocation3 = new byte[4 * _1MB];// 第一次触发Minor GC allocation3 = null; allocation3 = new byte[4 * _1MB];// 第二次触发Minor GC } } GC日志： [GC[DefNew: 5190K-&gt;740K(9216K), 0.0029755 secs] 5190K-&gt;4836K(19456K), 0.0030150 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] [GC[DefNew: 4836K-&gt;0K(9216K), 0.0012083 secs] 8932K-&gt;4836K(19456K), 0.0012270 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] Heap def new generation total 9216K, used 4259K [0x00000000f9a00000, 0x00000000fa400000, 0x00000000fa400000) eden space 8192K, 52% used [0x00000000f9a00000, 0x00000000f9e28fd0, 0x00000000fa200000) from space 1024K, 0% used [0x00000000fa200000, 0x00000000fa200000, 0x00000000fa300000) to space 1024K, 0% used [0x00000000fa300000, 0x00000000fa300000, 0x00000000fa400000) tenured generation total 10240K, used 4836K [0x00000000fa400000, 0x00000000fae00000, 0x00000000fae00000) the space 10240K, 47% used [0x00000000fa400000, 0x00000000fa8b9218, 0x00000000fa8b9400, 0x00000000fae00000) compacting perm gen total 21248K, used 2582K [0x00000000fae00000, 0x00000000fc2c0000, 0x0000000100000000) the space 21248K, 12% used [0x00000000fae00000, 0x00000000fb085a60, 0x00000000fb085c00, 0x00000000fc2c0000) No shared spaces configured. 通过日志可以看到一共触发了2次Minor GC操作，分别代码第11行和13行；下面我们具体分析下： 在进行第一次GC的时候，Eden区域已经被allocation1和allocation2两个对象占用了4352K的内存空间，当再分配allocation3的内存空间的时候（由于Eden总空间只有8M）会触发第一次MinorGC操作，会将allocation1和allocation2两个对象迁移到Survivor区域，然后将allocation3对象分配在Eden区共占用4M内存大小。 [DefNew: 5190K-&gt;740K(9216K), 0.0029755 secs] 5190K-&gt;4836K(19456K), 0.0030150 secs]可以看到GC发生时，新生代由5190K回收到了740k；Java Heap几乎没有怎么变化；因为此时对象仍然可用。 接下来将allocation3对象失效；然后再分配allocation3对象内存空间，由于Eden空间已经被之前的allocation3老对象占用着，剩余空间不足以分配新的allocation3对象内存，所以会触发第二次Minor GC操作； 由于allocation3老对象已经被设置为失效(内存中的allocation3老对象已经没有引用指向它)，所以会在第二次GC的时候将其在Eden中占用的内存回收掉；由于MaxTenuringThreshold参数设置为1，那么在Survivor区域的allocation1和allocation2两个对象会被迁移到老年代；最后新的allocation3对象会被分配到Eden区域； [DefNew: 4836K-&gt;0K(9216K), 0.0012083 secs] 8932K-&gt;4836K(19456K), 0.0012270 secs]可以看到新生代由4836K回收到了0k，Java Heap由8932K回收到了4836K，回收掉的就是allocation3老对象占用的内存 最后通过日志可以看到def new generation total 9216K, used 4259K,年轻代占用了4259k的内存（eden区的allocation3新对象），tenured generation total 10240K, used 4836K老年代占用了4836K的内存(allocation1和allocation2两个对象) -XX:+MaxTenuringThreshold=15GC日志： [GC [DefNew Desired survivor size 524288 bytes, new threshold 15 (max 15) - age 1: 445680 bytes, 445680 total : 4703K-&gt;435K(9216K), 0.0025569 secs] 4703K-&gt;4531K(19456K), 0.0025839 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] [GC [DefNew Desired survivor size 524288 bytes, new threshold 15 (max 15) - age 2: 445680 bytes, 445680 total : 4531K-&gt;435K(9216K), 0.0004236 secs] 8627K-&gt;4531K(19456K), 0.0004367 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] Heap def new generation total 9216K, used 4859K [0x00000000f9a00000, 0x00000000fa400000, 0x00000000fa400000) eden space 8192K, 54% used [0x00000000f9a00000, 0x00000000f9e51f98, 0x00000000fa200000) from space 1024K, 42% used [0x00000000fa200000, 0x00000000fa26ccf0, 0x00000000fa300000) to space 1024K, 0% used [0x00000000fa300000, 0x00000000fa300000, 0x00000000fa400000) tenured generation total 10240K, used 4096K [0x00000000fa400000, 0x00000000fae00000, 0x00000000fae00000) the space 10240K, 40% used [0x00000000fa400000, 0x00000000fa800010, 0x00000000fa800200, 0x00000000fae00000) compacting perm gen total 21248K, used 3045K [0x00000000fae00000, 0x00000000fc2c0000, 0x0000000100000000) the space 21248K, 14% used [0x00000000fae00000, 0x00000000fb0f9740, 0x00000000fb0f9800, 0x00000000fc2c0000) No shared spaces configured. 从GC日志可以分析： 第一次GC操作之前：新生代Eden区有allocation1对象（256KB）和allocation2对象（4MB）。GC操作之后：将Eden区域的两个对象进行迁移（采用复制算法），由于Survivor区(1024K)无法容纳allocation2对象(4MB)，所以将allocation1对象迁移到了老年代中，而allocation1对象（256K）则迁移到了Survivor区，所以此时新生代内存占有总容量只有Survivor区域的allocation1对象。这就是GC操作内存变换的缘由4703K-&gt;435K(9216K) 第二次GC之前：新生代Eden区域有老的allocation3对象(4MB),Survivor区域的allocation1对象(256KB)。GC操作之后：由于老的allocation3对象已经是无效对象，所以其占用的内存会被清理掉；而Survivor区的allocation1对象则在Survivor区域来回倒腾下(to-from)还停留在Survivor区域，只是年龄加1(原因是我们配置了MaxTenuringThreshold=15)。所以此时新生代内存占有总容量还是只有Survivor区域的allocation1对象。这就是GC操作内存变换的缘由4531K-&gt;435K(9216K) 所以最后新生代占用内存4859K（eden区allocation3对象的4MB，Survivor区的allocation1对象）；老年代占用内存4096K（allocation2对象的4MB） 说明在测试MaxTenuringThreshold=15的过程中，发现在JDK1.7上运行该参数无效，设置与否都是1；切换到JDK1.6上运行该参数就有效； JDK1.6版本： java version &quot;1.6.0_45&quot; Java(TM) SE Runtime Environment (build 1.6.0_45-b06) Java HotSpot(TM) 64-Bit Server VM (build 20.45-b01, mixed mode) JDK1.7版本： java version &quot;1.7.0_79&quot; Java(TM) SE Runtime Environment (build 1.7.0_79-b15) Java HotSpot(TM) 64-Bit Server VM (build 24.79-b02, mixed mode) PS：大家可以留言分享下。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[读《深入理解Java虚拟机》-理解GC日志]]></title>
      <url>%2F2016%2F03%2F03%2Fjvm-note-gclog%2F</url>
      <content type="text"><![CDATA[读到第3.5.8节，按照文章描述跟着作者的步伐一起测试了下，特做下日志分析记录。 前言本篇以Serial+Serial Old组合收集器日志为例来分析下GC日志(-XX:+UseSerialGC) GC日志[GC[DefNew: 7146K-&gt;484K(9216K), 0.0034871 secs] 7146K-&gt;6628K(19456K), 0.0035216 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] Heap def new generation total 9216K, used 4746K [0x00000000f9a00000, 0x00000000fa400000, 0x00000000fa400000) eden space 8192K, 52% used [0x00000000f9a00000, 0x00000000f9e297b0, 0x00000000fa200000) from space 1024K, 47% used [0x00000000fa300000, 0x00000000fa3791a8, 0x00000000fa400000) to space 1024K, 0% used [0x00000000fa200000, 0x00000000fa200000, 0x00000000fa300000) tenured generation total 10240K, used 6144K [0x00000000fa400000, 0x00000000fae00000, 0x00000000fae00000) the space 10240K, 60% used [0x00000000fa400000, 0x00000000faa00030, 0x00000000faa00200, 0x00000000fae00000) compacting perm gen total 21248K, used 2582K [0x00000000fae00000, 0x00000000fc2c0000, 0x0000000100000000) the space 21248K, 12% used [0x00000000fae00000, 0x00000000fb085a70, 0x00000000fb085c00, 0x00000000fc2c0000) No shared spaces configured. GC日志说明1、“[GC”和“[Full GC”说明了这次垃圾收集的停顿类型，如果有“Full”则说明这次GC是发生了Stop-The-World的(就是在垃圾收集的时候停止了所有用户进程)。如果是调用System.gc()所触发的收集，那么就显示“[Full GC(System)” 2、“[DefNew”、“[Tenured”、“[Perm”表示GC发生的区域，这里显示的区域名称和使用的GC收集器是有关系的。例如：Serial收集器：新生代名为“Default New Generation”，所以显示“[DefNew”ParNew收集器，新生代名为“Parallel New Generation”，所以显示“[ParNew”Parallel Scavenge收集器，新生代名为“PSYoungGen”老年代和永久代同理，名称也是由收集器决定的。 3、“7146K-&gt;484K(9216K)”表示“GC前该内存区域(新生代)已使用容量-&gt;GC后该内存区域已使用容量(该内存区域总容量)” 4、“0.0034871 secs”表示该内存区域GC所占用的时间，单位是秒 5、“7146K-&gt;6628K(19456K)”表示“GC前Java堆已使用容量-&gt;GC后Java堆已使用容量(Java堆总容量)” 6、“Times: user=0.00 sys=0.00, real=0.00 secs”分别代表用户态消耗的CPU时间、内核态消耗的CPU时间和操作从开始到结束所经过的墙钟时间。（CPU时间与墙钟时间的区别是，墙钟时间包括各种非运算的等待耗时，例如等待磁盘I/O、等待线程阻塞，而CPU时间不包括这些耗时，但当系统有多CPU或者多核的话，多线程操作会叠加这些CPU时间，所以当看到user或sys时间超过real时间是完全正常的） 其他收集器日志使用ParNew+Serial Old收集器组合日志(-XX:+UseParNewGC): [GC[ParNew: 7146K-&gt;508K(9216K), 0.0023849 secs] 7146K-&gt;6652K(19456K), 0.0024203 secs] [Times: user=0.00 sys=0.00, real=0.02 secs] Heap par new generation total 9216K, used 4770K [0x00000000f9a00000, 0x00000000fa400000, 0x00000000fa400000) eden space 8192K, 52% used [0x00000000f9a00000, 0x00000000f9e297b0, 0x00000000fa200000) from space 1024K, 49% used [0x00000000fa300000, 0x00000000fa37f1b8, 0x00000000fa400000) to space 1024K, 0% used [0x00000000fa200000, 0x00000000fa200000, 0x00000000fa300000) tenured generation total 10240K, used 6144K [0x00000000fa400000, 0x00000000fae00000, 0x00000000fae00000) the space 10240K, 60% used [0x00000000fa400000, 0x00000000faa00030, 0x00000000faa00200, 0x00000000fae00000) compacting perm gen total 21248K, used 2582K [0x00000000fae00000, 0x00000000fc2c0000, 0x0000000100000000) the space 21248K, 12% used [0x00000000fae00000, 0x00000000fb085a70, 0x00000000fb085c00, 0x00000000fc2c0000) No shared spaces configured. 使用Parallel Scavenge+Parallel Old收集器组合(-XX:+UseParallelOldGC): Heap PSYoungGen total 9216K, used 7310K [0x00000000ff600000, 0x0000000100000000, 0x0000000100000000) eden space 8192K, 89% used [0x00000000ff600000,0x00000000ffd23978,0x00000000ffe00000) from space 1024K, 0% used [0x00000000fff00000,0x00000000fff00000,0x0000000100000000) to space 1024K, 0% used [0x00000000ffe00000,0x00000000ffe00000,0x00000000fff00000) ParOldGen total 10240K, used 4096K [0x00000000fec00000, 0x00000000ff600000, 0x00000000ff600000) object space 10240K, 40% used [0x00000000fec00000,0x00000000ff000010,0x00000000ff600000) PSPermGen total 21504K, used 2582K [0x00000000f9a00000, 0x00000000faf00000, 0x00000000fec00000) object space 21504K, 12% used [0x00000000f9a00000,0x00000000f9c85a70,0x00000000faf00000)]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[测试JVM运行时常量池溢出]]></title>
      <url>%2F2016%2F03%2F02%2Fjvm-runtimeconstantpool-oom%2F</url>
      <content type="text"><![CDATA[运行时常量池属于方法区(俗称永久代)，如果要使运行时常量池溢出其实就是使方法区溢出，可以通过调整方法区的大小并配合String.intern方法来实现。 Java代码/** * VM Args: -XX:PermSize=10m -XX:MaxPermSize=10m */ public class RuntimeConstantPoolOOM { public static void main(String[] args) { List&lt;String&gt; list = new ArrayList&lt;String&gt;(); int i =1; while(true){ list.add(String.valueOf(i++).intern()); } } } 上面代码设置方法区的初始内存和最大内存为10m，并通过intern方法不停往方法区写入数据。 最后运行的结果如自己所预料的那样，出现方法区溢出 不过，大家请仔细看，上面是基于jdk1.6运行的结果，我们切换到jdk1.7运行再看看，发现不会出现方法区溢出，这是为什么呢？ 查看jdk1.7发布notes发现： Area: HotSpotSynopsis: In JDK 7, interned strings are no longer allocated in the permanent generation of the Java heap, but are instead allocated in the main part of the Java heap (known as the young and old generations), along with the other objects created by the application. This change will result in more data residing in the main Java heap, and less data in the permanent generation, and thus may require heap sizes to be adjusted. Most applications will see only relatively small differences in heap usage due to this change, but larger applications that load many classes or make heavy use of the String.intern() method will see more significant differences.RFE: 6962931 在JDK7中，常量池已经从方法区中迁移到了java堆中。 为了验证这个问题，我们调整VM的堆内存大小-Xms10m -Xmx10m再运行，结果如下]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[关于String.intern方法在JDK1.6、1.7中的表现]]></title>
      <url>%2F2016%2F03%2F02%2Fstring-intern-jdk6-jdk7-01%2F</url>
      <content type="text"><![CDATA[在读《深入理解Java虚拟机》第2.4.3节的时候，作者讨论了String.intern方法在jdk6、7中的不同表现，当时看到觉得挺有意思，自己也下来实验了一把，确实如同作者提到的那样，在JDK1.6、1.7中intern方法执行的结果不一样。 实例代码public class RuntimeConstantPoolOOM { public static void main(String[] args) { String str1 = new StringBuffer(&quot;计算机&quot;).append(&quot;软件&quot;).toString(); System.out.println(str1.intern() == str1); } } 以上代码在JDK1.6中运行结果是false，在JDK1.7中运行结果是true。作者的解释是在JDK1.6中intern方法会把首次遇到的字符串实例复制到永久代中，返回的也是永久代中的这个字符串实例的引用，而JDK1.7中intern方法实现不会再复制实例，只是在常量池中记录首次出现的实例引用。 我们再看下官网api关于intern方法的介绍;; 两个版本关于intern的描述居然都是一样的： 当intern方法被执行后，如果常量池中存在该字符串(通过equals判断)，那么就将该字符串从常量池中返回，否则，将该字符串对象添加到常量池中并将指向该对象的引用返回。 明明intern方法在这两个版本中的表现不一样，文档这里为什么没有一点点体现呢？ 总结JDK1.6调用intern方法如果常量池中包含该字符串则返回该字符串引用地址，如果不包括则将该字符串添加到常量池中再返回新的引用地址。所以当调用str1.intern方法时，”计算机软件”在常量池中是不存在的，所以会将该字符串添加到常量池中并返回新的引用地址，所以结果为false。 JDK1.7调用intern方法只是在常量池中记录该字符串的实例引用地址，如果该字符串在常量池中存在，则返回该实例引用地址，不存在则记录实例引用后返回地址。所以当调用str1.intern方法时，“计算机软件”在常量池中不存在，所以常量池中会记录该字符串实例引用并返回引用地址，所以返回的引用地址和str1是同一个实例引用，最后结果为true。 说明最后需要说明一点的是，常量池中会有一些已经存在的字符串常量，看下面的例子： public class RuntimeConstantPoolOOM { public static void main(String[] args) { String str1 = new StringBuffer(&quot;ma&quot;).append(&quot;in&quot;).toString(); System.out.println(str1.intern() == str1); } } 上面代码在JDK7中执行的结果为false，因为在调用intern方法的时候，常量池中已经存在main，所以返回的是main的引用地址，和str1是不同的实例对象，所以结果为false。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[JVM字节码之简单解读01]]></title>
      <url>%2F2016%2F02%2F26%2Fjvm-class-read-01%2F</url>
      <content type="text"><![CDATA[本篇通过一段简单的代码来分析下字节码的执行，认识认识几个常见的字节码指令 Java源代码public static void main(String[] args) { int i = 100; int j = 200 + i - 100; int z = j++; System.out.println(z+i); } 上面源码执行之后的结果是300，下面我们就通过分析class来看看结果是怎么得来的。 Class字节码public static void main(java.lang.String[]); Code: Stack=3, Locals=4, Args_size=1 0: bipush 100 2: istore_1 3: sipush 200 6: iload_1 7: iadd 8: bipush 100 10: isub 11: istore_2 12: iload_2 13: iinc 2, 1 16: istore_3 17: getstatic #2; //Field java/lang/System.out:Ljava/io/PrintStream; 20: iload_3 21: iload_1 22: iadd 23: invokevirtual #3; //Method java/io/PrintStream.println:(I)V 26: return } 下面我们就来分析下字节码的执行：Stack=3, Locals=4, Args_size=1,这段说明栈中元素有3个，局部变量表中有元素4个，参数1个 0: bipush 100 # 将常量100压入栈中2: istore_1 # 从栈中取出常量100存储到局部变量表中，下标索引为1 3: sipush 200 # 将常量200压入栈中6: iload_1 # 将下标索引为1的常量从局部变量表中压入栈中。 7: iadd # 从栈中取出两个整型常量相加并将结果存储到栈中 8: bipush 100 # 将常量100压入栈中 10: isub # 从栈中取出两个整型常量做相减并将结果存储到栈中 11: istore_2 # 从栈中取出常量存储到局部变量表中，下标索引为2 12: iload_2 # 将下标索引为2的常量从局部变量表中压入栈中13: iinc 2, 1 # 将局部变量表中下标索引为2的变量自增。 16: istore_3 # 从栈中取出常量存储到局部变量表中，下标索引为3 17: getstatic #2; //Field java/lang/System.out:Ljava/io/PrintStream;20: iload_3 # 将下标索引为3的常量从局部变量表中压入栈中21: iload_1 # 将下标索引为1的常量从局部变量表中压入栈中 22: iadd # 从栈中取出两个整型常量相加并将结果存储到栈中 23: invokevirtual #3; //Method java/io/PrintStream.println:(I)V26: return 所以最后执行结果是300 大家可能注意到了，在字节码第三行Stack=3, Locals=4, Args_size=1，显示的是栈中有3个元素，为什么我们这里只有两个？其实栈中还有一个this元素，由于this不在本篇介绍范围之类，所以例图就省略了，特此说明下。大家可能疑惑这个this是什么时候入栈的，通过下面的代码相信大家就明白了 public test.Test(); Code: Stack=1, Locals=1, Args_size=1 0: aload_0 1: invokespecial #1; //Method java/lang/Object.&quot;&lt;init&gt;&quot;:()V 4: return LineNumberTable: line 3: 0 参考Java字节码指令列表]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[JVM字节码之整型入栈指令(iconst、bipush、sipush、ldc)]]></title>
      <url>%2F2016%2F02%2F25%2Fjvm-int-pushstack-01%2F</url>
      <content type="text"><![CDATA[本篇主要分享下在JVM中int类型数值采用何种指令入栈的，根据int值范围JVM入栈字节码指令就分为4类，下面分别介绍下这四类指令。 前言当int取值-1~5采用iconst指令，取值-128~127采用bipush指令，取值-32768~32767采用sipush指令，取值-2147483648~2147483647采用 ldc 指令。 iconst当int取值-1~5时，JVM采用iconst指令将常量压入栈中。定义Test.java文件 public static void main(String[] args) { int i = 5; int j = -1; } 查看class文件 public static void main(java.lang.String[]); Code: 0: iconst_5 1: istore_1 2: iconst_m1 3: istore_2 4: return } 分析class文件，int取值0~5时JVM采用iconst_0、iconst_1、iconst_2、iconst_3、iconst_4、iconst_5指令将常量压入栈中，取值-1时采用iconst_m1指令将常量压入栈中。 bipush当int取值-128~127时，JVM采用bipush指令将常量压入栈中。定义Test.java文件 public static void main(String[] args) { int i = 127; } 查看class文件 public static void main(java.lang.String[]); Code: 0: bipush 127 2: istore_1 3: return } 可以看到上面代码第三行是采用bipush指令将常量127压入栈中。 sipush当int取值-32768~32767时，JVM采用sipush指令将常量压入栈中。定义Test.java文件 public static void main(String[] args) { int i = 32767; } 查看class文件 public static void main(java.lang.String[]); Code: 0: sipush 32767 3: istore_1 4: return } 可以看到上面代码第三行是采用sipush指令将常量32767压入栈中。 ldc当int取值-2147483648~2147483647时，JVM采用ldc指令将常量压入栈中。定义Test.java文件 public static void main(String[] args) { int i = Integer.MAX_VALUE; } 查看class文件 public static void main(java.lang.String[]); Code: 0: ldc #2; //int 2147483647 2: istore_1 3: return } 可以看到上面代码第三行是采用ldc指令将2147483647常量压入栈中，需要注意的是ldc指令是从常量池中获取值的，也就是说在这段范围（-2147483648~2147483647）内的int值是存储在常量池中的。 参考JVM规范]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Github之SSH连接配置]]></title>
      <url>%2F2016%2F02%2F24%2Fgithub-config-ssh%2F</url>
      <content type="text"><![CDATA[虽然github推荐使用https方式进行连接，但是ssh方式咱们也得会，官网上也都有详细的文档介绍，步骤比较简单，记录这篇的目的是给初入门的小伙伴多一个学习的门径，同时也方便日后自己查看。 前言在没有配置ssh的情况下使用ssh连接操作github库的时候会出现如下异常： $ git clone git@github.com:linmuxi/test-git.git Cloning into &#39;test-git&#39;... Warning: Permanently added the RSA host key for IP address &#39;192.30.252.129&#39; to the list of known hosts. Permission denied (publickey). fatal: Could not read from remote repository. Please make sure you have the correct access rights and the repository exists. ~ 步骤 前提是我们已经新建好了一个库test-git,ssh路径是：git@github.com:linmuxi/test-git.git 1、检查ssh keys是否存在$ ls -al ~/.ssh 如果目录下面没有id_rsa、id_rsa.pub则表示key不存在 2、生成ssh key$ ssh-keygen -t rsa -b 4096 -C &quot;your_email@example.com&quot; Generating public/private rsa key pair. Enter file in which to save the key (/c/Users/Hunter/.ssh/id_rsa): Enter passphrase (empty for no passphrase): Enter same passphrase again: Your identification has been saved in /c/Users/Hunter/.ssh/id_rsa. Your public key has been saved in /c/Users/Hunter/.ssh/id_rsa.pub. The key fingerprint is: SHA256:7KwlOZ4yljBZE2ZJ7dr8QGIyQeiPk49L+01fnC0hAZY your_email@example.com The key&#39;s randomart image is: +---[RSA 4096]----+ | o...=. | |. . *Eo | |. + o . | | .o = o.. | | +* B .S. | | ++.. ++o + | | .+o o+o+= . | |....B..*o . | | ooo ++. | +----[SHA256]-----+ 3、将ssh key添加到ssh-agent先确认ssh-agent是可用的 $ eval $(ssh-agent -s) Agent pid 20632 将ssh key添加到ssh-agent $ ssh-add ~/.ssh/id_rsa Identity added: /c/Users/Hunter/.ssh/id_rsa (/c/Users/Hunter/.ssh/id_rsa) 4、将ssh key配置到github复制key内容 $ clip &lt; ~/.ssh/id_rsa.pub 配置key到github登录github-&gt;选择Settings-&gt;SSH keys-&gt;New SSH key 测试ssh key的配置情况 $ ssh -t git@github.com Warning: Permanently added the RSA host key for IP address &#39;192.30.252.128&#39; to the list of known hosts. PTY allocation request failed on channel 0 到这里就配置好了 再次执行clone操作： $ git clone git@github.com:linmuxi/test-git.git Cloning into &#39;test-git&#39;... remote: Counting objects: 56, done. remote: Compressing objects: 100% (34/34), done. remote: Total 56 (delta 4), reused 0 (delta 0), pack-reused 8 Receiving objects: 100% (56/56), 5.42 KiB | 0 bytes/s, done. Resolving deltas: 100% (4/4), done. Checking connectivity... done.]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[你真的了解try{ return }finally{}中的return？]]></title>
      <url>%2F2016%2F02%2F23%2Fjava-try-finally-return-01%2F</url>
      <content type="text"><![CDATA[你真的了解try{ return }finally{}中的return？不妨点进来看看，说不定会有一定的小收获呢。今天去逛论坛 时发现了一个很有趣的问题： 谁能给我我解释一下这段程序的结果为什么是：2.而不是：3 代码如下： class Test { public int aaa() { int x = 1; try { return ++x; } catch (Exception e) { } finally { ++x; } return x; } public static void main(String[] args) { Test t = new Test(); int y = t.aaa(); System.out.println(y); } } 看了问题后，得出了以下几个问题： 如果在 try 语句块里使用 return 语句，那么 finally 语句块还会执行吗？（如果你的答案是不会执行，请务必要看下去 ^_^） 如果执行，那么是怎样实现既执行 return 又执行 finally 的呢？（如果你的答案是不知道，请继续看下去！！） 上面的程序输出为什么是2？（ 如果不知道，继续看下去~~） 在网上看到还有人还问“是先执行return还是先执行finally？”的（个人觉得，如果知道finally会执行就可以得出是，先执行finally再执行return的。因为，如果先执行return，那么整个函数都跳出了，那么还怎么执行finally？^_^） 刚看到这个问题后。突然发现基础不够扎实，居然来第一个都答不出来。。。（不知道还有木有和我也一样也回答不出以上的问题的？ 如果有请在评论里告诉我一声，让我知道，我并不孤独~~） 根据已有的知识知道： return 是可以当作终止语句来用的，我们经常用它来跳出当前方法，并返回一个值给调用方法。然后该方法就结束了，不会执行return下面的语句。finally ：无论try语句发生了什么，无论抛出异常还是正常执行。finally语句都会执行。那么问题来了。。。。在try语句里使用return后，finally是否还会执行？finally一定会执行的说法是否还成立？如果成立，那么先执行return还是先执行finally？ 验证 finally 语句是否会执行，以及 return 和 finally的执行顺序在求知欲的驱动下，我继续进行更深的探索，果断打开了Oracle的主页，翻阅了java 官方教程的finally语句。发现了官方教程对这个特殊情况有说明： The finally block always executes when the try block exits. This ensures that the finally block is executed even if an unexpected exception occurs. But finally is useful for more than just exception handling — it allows the programmer to avoid having cleanup code accidentally bypassed by a return, continue, or break. Putting cleanup code in a finally block is always a good practice, even when no exceptions are anticipated. Note: If the JVM exits while the try or catch code is being executed, then the finally block may not execute. Likewise, if the thread executing the try or catch code is interrupted or killed, the finally block may not execute even though the application as a whole continues. 个人简单翻译： 当try语句退出时肯定会执行finally语句。这确保了即使发了一个意想不到的异常也会执行finally语句块。但是finally的用处不仅是用来处理异常——它可以让程序员不会因为return、continue、或者break语句而忽略了清理代码。把清理代码放在finally语句块里是一个很好的做法，即便可能不会有异常发生也要这样做。 注意，当try或者catch的代码在运行的时候，JVM退出了。那么finally语句块就不会执行。同样，如果线程在运行try或者catch的代码时被中断了或者被杀死了(killed)，那么finally语句可能也不会执行了，即使整个运用还会继续执行。 从上面的官方说明，我们知道无论try里执行了return语句、break语句、还是continue语句，finally语句块还会继续执行。同时，在stackoverflow里也找到了一个答案，我们可以调用System.exit()来终止它： finally will be called.The only time finally won’t be called is: if you call System.exit(), another thread interrupts current one, or if the JVM crashes first 另外，在java的语言规范有讲到，如果在try语句里有return语句，finally语句还是会执行。它会在把控制权转移到该方法的调用者或者构造器前执行finally语句。也就是说，使用return语句把控制权转移给其他的方法前会执行finally语句。 个人验证我们依然使用上面的代码作为例子。首先，分别在以下三行代码前加上断点： int x = 1; return ++x; ++x; 然后以debug模式运行代码。 刚开始时，效果如下图：;按一下F6，我们可以发现，程序已经执行到 return ++x;,但还没执行该语句，此刻x=1;继续按一下F6，程序执行到 ++x;,但还没执行该语句，因此此时的x=2（刚执行完return ++x语句的++x，但没执行return）;继续按一下F6，此时，我们发现程序又跳回到 return +xx 这一行，此刻x=3(执行了finally语句里的++x); 从上面过程中可以看到， 在 try 里 使用 return 还是会执行finally语句的（我们用debug的模式看到了程序会条件 finally语句里执行） 执行完finally语句才执行 return。为什么?从上面的图可以合理推理出return ++x是分开来执行的，先执行++x，再执行finally，最后才执行return跳出函数。因为程序调两次跳到了 return +xx; 语句上。（其实要验证 return ++x 是分开两部分执行的方法很简单，把变量x变成static变量并在main函数里输出，会发现x的值还是3，即使两次跳到 return ++x 也只是第一次执行了加1操作，第二次只是执行了return而没有执行++x。这里是合理推理，后面有真凭实据~~） 看到这，我们可能会再次纠结起来了。从上面的验证可以看出，finally语句执行了，而且x的值也确实加到3了，那么为什么y是2呢？ 验证为什么是2不是3翻看官方的jvm规范就会把一切的谜团解开了： If the try clause executes a return, the compiled code does the following: Saves the return value (if any) in a local variable. Executes a jsr to the code for the finally clause. Upon return from the finally clause, returns the value saved in the local variable. 简单翻译下： 如果try语句里有return，那么代码的行为如下： 如果有返回值，就把返回值保存到局部变量中 执行jsr指令跳到finally语句里执行 执行完finally语句后，返回之前保存在局部变量表里的值 根据上面的说明就可以轻易地解释为什么是2了。当执行到return ++x;时，jvm在执行完++x后会在局部变量表里另外分配一个空间来保存当前x的值。注意，现在还没把值返回给y，而是继续执行finally语句里的语句。等执行完后再把之前保存的值（是2不是x）返回给y。所以就有了y是2不是3的情况。 其实这里还有一点要注意的是，如果你在finally里也用了return语句，比如return +xx。那么y会是3。因为规范规定了，当try和finally里都有return时，会忽略try的return，而使用finally的return。 查看Test.class的字节码我们同样也可以很轻松地知道为什么是2而不是3：; 大概讲讲指令操作顺序：iconst_1： 把常数1进栈 —&gt; istore_1： 栈顶元素出栈并把元素保存在本地变量表的第二个位置里（下标为1的位置里） —&gt; iinc 1, 1 ： 本地变量表的第二个元素自增1 —&gt;iload_1：第二个元素进栈 —&gt; istore_2：栈顶元素出栈并把元素保存在本地变量表的第2个位置里 —&gt; iinc 1, 1 ： 本地变量表的第二个元素自增1 —&gt; iload_2：第二个元素进栈 （注意，此时栈顶元素为2）—&gt; ireturn：返回栈顶元素。 后面的指令是要在2-7行出现异常时在跳到12行的，这个例子没出现异常，不用关注。 上面流程栈和本地变量表的情况如下图：; 总结 再次发现帮助别人解决问题的好处，不仅能帮人还能完善自己 字节码的知识还是挺实用的，有空要深入研究下 再次证明官方教程和资料真的很有用 参考资料：Java虚拟机规范java 官方教程的finally语句IBM的Java字节码教程深入理解Java虚拟机（第2版） 本文转摘自：http://www.cnblogs.com/averey/p/4379646.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Oracle单向高级流复制的使用]]></title>
      <url>%2F2016%2F02%2F22%2Foracle-stream-01%2F</url>
      <content type="text"><![CDATA[本篇分享下Oracle中流复制的使用。 场景需求：需要将A地采集到的数据发送到B地数据库中。环境：网络环境是A到B是单项通讯 暂且称A为主库，B为从库 A一、在主库配置到从库的tns连接~ tnsping boyuupq_10_19 二、修改数据库域名(注意修改完后要重启数据库)查看数据库域名select * from global_name; //boyuupq.REGRESS.RDBMS.DEV.US.ORACLE.COM 修改数据库域名alter database rename global_name to boyuupq_10_18; 执行完这步之后，查询发现数据库域名还是上面的结果，新建dblink名称后面也会自动拼接上这后缀。这时可以执行：update global_name set global_name = boyuupq_10_18; 三、新建流管理员strmadmin(使用sysdba帐号) SQL&gt;conn /as sysdba SQL&gt; create user strmadmin identified by strmadmin default tablespace users temporary tablespace temp; SQL&gt; execute dbms_defer_sys.register_propagator(&#39;strmadmin&#39;); SQL&gt; grant execute any procedure to strmadmin; SQL&gt; execute dbms_repcat_admin.grant_admin_any_repgroup(&#39;strmadmin&#39;); SQL&gt; execute dbms_repcat_admin.grant_admin_any_schema(username =&gt; &#39;strmadmin&#39;); SQL&gt; grant comment any table to strmadmin; SQL&gt; grant lock any table to strmadmin; SQL&gt; grant select any dictionary to strmadmin; 四、用流管理员strmadmin新增到从库的dblink SQL&gt; conn strmadmin/strmadmin SQL&gt; create database link &quot;boyuupq_10_19&quot; connect to strmadmin identified by strmadmin using &#39;boyuupq_10_19&#39;; 五、查询dblink SQL&gt; select owner,db_link,host from all_db_links; OWNER DB_LINK HOST STRMADMIN boyuupq_10_19 boyuupq_10_19 B一、修改数据库域名(注意修改完后要重启数据库)查看数据库域名select * from global_name; //boyuupq.REGRESS.RDBMS.DEV.US.ORACLE.COM 修改数据库域名alter database rename global_name to boyuupq_10_19; 执行完这步之后，查询发现数据库域名还是上面的结果，新建dblink名称后面也会自动拼接上这后缀。这时可以执行：update global_name set global_name = boyuupq_10_19; 二、新建流管理员strmadmin(使用sysdba帐号) SQL&gt;conn /as sysdba SQL&gt; create user strmadmin identified by strmadmin default tablespace users temporary tablespace temp; SQL&gt; execute dbms_defer_sys.register_propagator(&#39;strmadmin&#39;); SQL&gt; grant execute any procedure to strmadmin; SQL&gt; execute dbms_repcat_admin.grant_admin_any_repgroup(&#39;strmadmin&#39;); SQL&gt; execute dbms_repcat_admin.grant_admin_any_schema(username =&gt; &#39;strmadmin&#39;); SQL&gt; grant comment any table to strmadmin; SQL&gt; grant lock any table to strmadmin; SQL&gt; grant select any dictionary to strmadmin; 上面的操作主要是配置数据库名称、流管理员、dblink，下面将要进行流队列、捕获进程、传播进程、应用进程的配置 创建流队列主库： connect strmadmin/strmadmin; begin dbms_streams_adm.set_up_queue( queue_table =&gt; &#39;boyuupq_10_18_queue_table&#39;, queue_name =&gt; &#39;boyuupq_10_18_queue&#39;); end; / 从库： connect strmadmin/strmadmin; begin dbms_streams_adm.set_up_queue( queue_table =&gt; &#39;boyuupq_10_19_queue_table&#39;, queue_name =&gt; &#39;boyuupq_10_19_queue&#39;); end; / 创建捕获进程(主库)connect strmadmin/strmadmin; begin dbms_streams_adm.add_schema_rules( schema_name =&gt; &#39;sa&#39;, streams_type =&gt; &#39;capture&#39;, streams_name =&gt; &#39;capture_boyuupq_10_18&#39;, queue_name =&gt; &#39;strmadmin.boyuupq_10_18_queue&#39;, include_dml =&gt; true, include_ddl =&gt; true, include_tagged_lcr =&gt; false, source_database =&gt; null, inclusion_rule =&gt; true); end; / 创建传播进程(主库)connect strmadmin/strmadmin; begin dbms_streams_adm.add_schema_propagation_rules( schema_name =&gt; &#39;sa&#39;, streams_name =&gt; &#39;boyuupq18_to_boyuupq19&#39;, source_queue_name =&gt; &#39;strmadmin.boyuupq_10_18_queue&#39;, destination_queue_name =&gt; &#39;strmadmin.boyuupq_10_19_queue@book&#39;, include_dml =&gt; true, include_ddl =&gt; true, include_tagged_lcr =&gt; false, source_database =&gt; &#39;boyuupq_10_18&#39;, //主库数据库名称，注意这里的配置是否正确 inclusion_rule =&gt; true); end; / 修改propagation休眠时间为0，表示实时传播LCRbegin dbms_aqadm.alter_propagation_schedule( queue_name =&gt; &#39;boyuupq_10_18_queue&#39;, destination =&gt; &#39;boyuupq_10_19&#39;, //到从库的dblink名称 latency =&gt; 0); end; / 创建应用进程(从库)connect strmadmin/strmadmin; begin dbms_streams_adm.add_schema_rules( schema_name =&gt; &#39;sa&#39;, streams_type =&gt; &#39;apply&#39;, streams_name =&gt; &#39;apply_boyuupq_10_19&#39;, queue_name =&gt; &#39;strmadmin.boyuupq_10_19_queue&#39;, include_dml =&gt; true, include_ddl =&gt; true, include_tagged_lcr =&gt; false, source_database =&gt; &#39;boyuupq_10_18&#39;, //主库数据库名称 inclusion_rule =&gt; true); end; / 启动应用进程(从库,先应用、后捕获，传播自动启动)connect strmadmin/strmadmin; #启动Apply进程 begin dbms_apply_adm.start_apply( apply_name =&gt; &#39;apply_boyuupq_10_19&#39;); end; / 启动捕获进程(主库)connect strmadmin/strmadmin; #启动Capture进程 begin dbms_capture_adm.start_capture( capture_name =&gt; &#39;capture_boyuupq_10_18&#39;); end; / 到这里流配置就完成了，可以通过下面的sql语句进行运行状况的查询 查询stream运行状况主库： --捕获进程信息 SELECT * FROM dba_capture; --传播进程信息 SELECT * FROM dba_propagation; --已经捕获到的表对象 SELECT * FROM DBA_CAPTURE_PREPARED_TABLES order by SCN; --已经捕获到的schema对象 SELECT * from dba_capture_prepared_schemas; 从库： --应用进程信息 select * from dba_apply; --应用进程错误详细信息 select * from dba_apply_error; --当前已经实例化的schema对象 select * from dba_apply_instantiated_schemas; --当前已经实例化并同步过来的对象(表) select * from dba_apply_instantiated_objects; 下面提供了停止相应流进程的操作 停止捕获进程(主库)connect strmadmin/strmadmin; #停止Capture进程 begin dbms_capture_adm.stop_capture( capture_name =&gt; &#39;capture_boyuupq_10_18&#39;); end; / 停止应用进程(从库)connect strmadmin/strmadmin; #停止Apply进程 begin dbms_apply_adm.stop_apply( apply_name =&gt; &#39;apply_boyuupq_10_19&#39;); end; / 删除传播进程、应用进程exec dbms_capture_adm.drop_capture(&quot;capture_boyuupq_10_18&quot;); exec dbms_apply_adm.drop_apply(&#39;apply_boyuupq_10_19&#39;); 删除所有流配置信息exec dbms_streams_adm.remove_streams_configuration();]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Undo与Redo的介绍]]></title>
      <url>%2F2016%2F02%2F22%2Foracle-undo-redo%2F</url>
      <content type="text"><![CDATA[本篇主要分享下Oracle中Undo与Redo的介绍 undoundo: 回滚段，分为系统存储段、非系统存储段,基于表空间数据存储,存储旧数据根据undo_management参数来判断是基于UNDOTBS1表空间还是system表空间存储回滚段(只要数据未提交、回滚段未写满或者回滚段未超时的情况下，旧数据都能被回滚回来。) redoredo：重做日志，分为在线、离线，基于日志文件存储，存储新旧数据如果开启数据库归档，则归档日志文件为离线重做日志文件 演示执行场景：id = 100,age = 100; 用户session1执行修改操作：update scott.emp set age = 10 where id = 100; 此时还未commit，实际已经做了如下操作：1、在SGA区(数据缓冲区)产生回滚段记录UNDO块包含旧数据2、在SGA区(数据缓冲区)将id=100对应的数据给修改为103、在SGA区中重做日志缓冲区中生成了重做记录(条目)包含修改前后的数据4、得到所需的所有锁 PS：如果此时用户session2来查询id=100的数据，结果是age=100，这个结果是从回滚段记录undo中获取的 当commit的时候，做的操作如下：1、为事务产生一个SCN(system change number)2、LGWR把重做日志缓冲区条目写到磁盘(重做日志文件),并在联机重做日志中记录SCN.3、释放锁4、对缓冲区中的数据块进行块清理（刷新数据文件）]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[ORA-01555：快照过旧，回滚段号10(名称为“_SYSSMU10$”)过小]]></title>
      <url>%2F2016%2F02%2F22%2Foracle-flashback-err-02%2F</url>
      <content type="text"><![CDATA[前篇介绍了利用闪回查询可以将误删的数据恢复，但该操作并不能100%进行数据恢复。本篇就该问题进行分享下。 前言该异常的原因是UNDO表空间(System表空间或UNDOTBS1表空间)的数据已经被覆盖或是保留时间过期。因为闪回查询是基于UNDO数据来执行的。 分析有两种方式可以解决该问题1、增大UNDO表空间大小2、或者修改undo_retention的时间 通过show parameter undo 查询UNDO的信息; sql&gt; show parameter undo undo_management string AUTO undo_retention integer 86400 (默认为分钟) undo_tablespace string UNDOTBS1 说明undo表空间用于存放undo数据，当执行DML操作（insert、update、delete）时，oracle会将这些操作的旧数据写入到undo段。 ora-01555快照过旧就是因为undo空间不够大，其中一部分undo数据被覆盖了，用户无法获得修改前的数据或是保留时间过期。 undo数据分为三种：活动的undo：未提交事务的undo数据，这些undo数据永远不能覆盖，用于回滚rollback事务。过期的undo：已提交事务的undo数据，这些undo数据可以覆盖。未过期的undo：事务已提交，但事务提交前，有些查询正在进行，它要读取的是提交前的数据，这部分数据就是未过期数据。如果这部分undo数据被覆盖了，就会发生ora-01555错误。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Oracle恢复被误删的数据]]></title>
      <url>%2F2016%2F02%2F22%2Foracle-recover-del-data%2F</url>
      <content type="text"><![CDATA[这篇分享下如何恢复被Delete掉的数据。 下面一共介绍三种恢复数据的方法： 利用闪回// 开启行移动功能 ALTER TABLE my_test ENABLE ROW MOVEMENT; // 闪回表到指定时间点(需要开启行移动功能) FLASHBACK TABLE my_test TO TIMESTAMP to_timestamp(&#39;2013-10-17 17:05:00&#39;,&#39;yyyy-mm-dd hh24:mi:ss&#39;) 利用Oracle的快照进行某个时间点的数据查询// 查询在当前时间之前的8分钟时候的数据 SELECT * FROM my_test AS OF TIMESTAMP (SYSDATE - INTERVAL &#39;8&#39; MINUTE) // 查询指定时间点的数据 SELECT * FROM my_test AS OF TIMESTAMP to_timestamp(&#39;2013-10-17 17:05:00&#39;,&#39;yyyy-mm-dd hh24:mi:ss&#39;); 基于SCN// 查询指定时间点的SCN SELECT timestamp_to_scn(to_timestamp(&#39;2013-10-17 17:05:00&#39;,&#39;yyyy-mm-dd hh24:mi:ss&#39;)) FROM dual; // 查询指定SCN点的数据 select * FROM my_test AS OF SCN 10305758694685 PS:如果是在被删除的第一时间进行数据恢复，则可能性很大，否则可能性会大大减小。因为回滚段可能会被后来的数据覆盖掉(进行快照查询会出现：ORA-01555:快照过旧)。当然，也可以通过增大回滚表空间(UNDOTBS1)的大小来提高回滚数据存放的时间]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Oracle回收站(Recycle Bin)的使用]]></title>
      <url>%2F2016%2F02%2F22%2Foracle-recycle-bin%2F</url>
      <content type="text"><![CDATA[我们Drop掉的表还能被找回来吗？答案是必须的。就该问题本篇分享下Oracle中Recycle Bin的使用。 前言回收站(Recycle Bin）从原理上来说就是一个数据字典表，放置用户删除（drop）掉的数据库对象信息。用户进行删除操作的对象并没有被数据库删除，仍然会占用空间。除非是由于用户手工进行Purge或者因为存储空间不够而被数据库清掉。 除非拥有sysdba权限，每个用户只能看到属于自己的对象。所以，对于用户来说，好像每个人都拥有自己的回收站。即使用户有删除其它schema对象的权限，也只能在recyclebin中看到属于自己的对象 操作启动和关闭SELECT Value FROM V$parameter WHERE Name = &#39;recyclebin&#39;;或show parameter recyclebin;如果返回值为“on”表明回收站是启动的，“off”表明是关闭的。 当然，你可以启动或者关闭回收站里的每个会话（session）和系统（system），代码如下： ALTER SYSTEM SET recyclebin = ON; ALTER SESSION SET recyclebin = ON; ALTER SYSTEM SET recyclebin = OFF; ALTER SESSION SET recyclebin = OFF; 获取回收站里的内容 SELECT * FROM RECYCLEBIN; SELECT * FROM USER_RECYCLEBIN; SELECT * FROM DBA_RECYCLEBIN; 还原被Drop的表flashback table &lt;droped_table_name&gt; to before drop [rename &lt;new_table_name&gt;] 利用flashback将删除的表闪回，不过这个flashback并不是100%将删除的表还原，具体下篇再介绍。 清空回收站a.清空一个特定的表：purge table b.清空一个特定的索引：purge index c.清空与该表空间有关联的对象：purge tablespace d.清空一个特定用户的表空间对象：purge tablespace user e.清空回收站：purge recyclebinf.当一个表被删除（drop）时就直接从回收站中清空:drop table purge; 注意：以下几种drop不会将相关对象放进RecycleBin：drop tablespace：会将RecycleBin中所有属于该tablespace的对象清除drop user：会将RecycleBin中所有属于该用户的对象清除drop cluster：会将RecycleBin中所有属于该cluster的成员对象清除drop type：会将RecycleBin中所有依赖该type的对象清除 PS：如果大家使用PlSql developer工具，该工具提供了RecycleBin窗口可视化操作。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[更改ORACLE归档路径及归档模式]]></title>
      <url>%2F2016%2F02%2F22%2Foracle_change_archive_mode%2F</url>
      <content type="text"><![CDATA[本篇分享下如何更改ORACLE归档路径及归档模式 前言在ORACLE10g和11g版本，ORACLE默认的日志归档路径为闪回恢复区 （$ORACLE_BASE/flash_recovery_area）。对于这个路径，ORACLE有一个限制，就是默认只有2G的空间，而且不只是归 档日志的默认路径，也是备份文件和闪回日志的默认地址，这样的话归档日志锁使用的空间就达不到2G，在没有设置好这个路径大小的情况下，很多系统都遇到过 归档日志满而无法归档导致数据库夯住的问题。 操作可以使用下面的SQL语句去查看归档信息。 SQL&gt; archive log list 数据库日志模式 非存档模式 自动存档 禁用 存档终点 USE_DB_RECOVERY_FILE_DEST 最早的联机日志序列 321 当前日志序列 326。 上面的存档终点USE_DB_RECOVERY_FILE_DEST默认就是闪回恢复区（$ORACLE_BASE/flash_recovery_area），可以通过下面的SQL查看闪回恢复区的信息。 SQL&gt; show parameter db_recover NAME TYPE VALUE -------------------------- ----------- ---------------------------- db_recovery_file_dest string D:\oracle\flash_recovery_area db_recovery_file_dest_size big integer 2G 通过上面的SQL结果可以看到，闪回恢复区为D:\oracle\flash_recovery_area，大小为2G，也可以通过查询v$recovery_file_dest视图查看闪回恢复的限制信息。 SQL&gt; select name,SPACE_LIMIT,SPACE_USED from v$recovery_file_dest; NAME SPACE_LIMIT SPACE_USED ------------------------------ ----------- ---------- D:\oracle\flash_recovery_area 2147483648 21225472 默认情况下，归档日志会存放到闪回恢复区（D:\oracle\flash_recovery_area）内，如果闪回恢复区已经使用到2G，归档日志就有可能无法继续归档，数据库夯住，通常的解决方法是增大闪回恢复区，可以用以下SQL实现。 SQL&gt; alter system set db_recovery_file_dest_size=3G; 系统已更改。 即使用这种方法解决的当前燃眉之急，但是如果备份策略不是很完善，数据库非常繁忙的情况下，还有可能遇到这种情况，通常需要修改归档日志的路径，将归档日志放到其他不受限制的路径下来解决这个问题，可通过下面的SQL来修改归档日志的存放路径。 SQL&gt; alter system set log_archive_dest_1=&#39;location=D:\arch&#39;; 系统已更改。 然后将数据库启动到MOUNT状态，将数据库修改为归档模式后建数据库启动到OPEN状态。 SQL&gt; shutdown immediate 数据库已经关闭。 已经卸载数据库。 ORACLE 例程已经关闭。 SQL&gt; startup mount ORACLE 例程已经启动。 数据库装载完毕。 SQL&gt; alter database archivelog; 数据库已更改。 SQL&gt; alter database open; 数据库已更改。 再次查看数据库的归档情况。 SQL&gt; archive log list 数据库日志模式 存档模式 自动存档 启用 存档终点 D:\arch 最早的联机日志序列 321 下一个存档日志序列 326 当前日志序列 326 可以通过切换日志，查看归档路径下是否有归档日志产生来验证归档路径设置是否正确，可以通过下面的命令切换日志。 SQL&gt; alter system switch logfile; 系统已更改。 查看归档路径（D:\arch）下是否有归档路径产生。 D:\arch&gt;dir/b ARC0000000326_0764368160.0001 可以看到在D:\arch路径下已经产生了归档日志，归档日志的名字受log_archive_format参数限制，可以通过下面的命令查看。 SQL&gt; show parameter log_archive_format NAME TYPE VALUE ---------------------- ------------ ------------ log_archive_format string ARC%S_%R.%T 上面产生的归档文件名字为ARC0000000326_0764368160.0001，%S也就是0000000326是日志切换号，也就是上文archive log list中的当前日志序列，%R是场景号，%T是线程号，可以理解成是节点号，如果不是RAC环境，%T都是1，还可以在log_archive_format参数值中加上%D，%D是16进制标识的DBID，如下演示： SQL&gt; alter system set log_archive_format=&#39;ARC%S_%R.%T_%D.log&#39; scope=spfile; 系统已更改。 SQL&gt; shutdown immediate 数据库已经关闭。 已经卸载数据库。 ORACLE 例程已经关闭。 SQL&gt; startup ORACLE 例程已经启动。 数据库装载完毕。 数据库已经打开。 SQL&gt; alter system switch logfile; 系统已更改。 查看归档日志的名字，5AA14A62就是16进制的DBID。 D:\arch&gt;dir/b ARC0000000326_0764368160.0001 ARC0000000327_0764368160.0001_5AA14A62.LOG]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[问题：ORA-00257: 归档程序错误。在释放之前仅限于内部连接]]></title>
      <url>%2F2016%2F02%2F22%2Foracle-archive-err-01%2F</url>
      <content type="text"><![CDATA[本篇分享下Oracle异常问题的处理方法 前言前段时间发现测试环境Oracle数据库连接不上了，到后台看日志输出：’问题：ORA-00257: 归档程序错误。在释放之前仅限于内部连接’，经分析是归档日志文件占满FLASH_RECOVERY_AREA的空间，下面就该问题分析下具体的解决方法。 解决方法1、查询FLASH_RECOVERY_AREA空间大小//查看恢复区各文件占用百分比情况 select * from v$flash_recovery_area_usage; //查看恢复区总大小 show parameter db_recovery_file_dest; 2、扩大FLASH_RECOVERY_AREA的空间或删除归档日志A.扩大FLASH_RECOVERY_AREA的空间执行alter system set db_recovery_file_dest_size=扩容大小 scope=both; B.删除归档日志 先手动删除归档日志物理文件(PS:没有完全删除，控制文件中还有记录，所以实际占用的容量并没有调整，此时应该是无效的归档日志文件) 利用RMAN删除无效归档日志文件 rman target/@edmp （使用sysdba登录，rman target sys/pwd@orcl） crosscheck archivelog all;（检查控制文件和实际物理文件的差别）ps：出现验证失败的，表示该归档日志文件已经被物理删除 list expired archivelog all;（查看所有过期归档日志文件列表,PS:要使用crosscheck archivelog all进行同步之后才能正确显示过期归档日志列表） delete expired archivelog all;（删除所有过期归档文件） list archivelog all;（查看所有归档日志文件列表）到这里，归档文件就已经被正确删除了。 删除归档日志（做好备份） DELETE ARCHIVELOG ALL COMPLETED BEFORE ‘SYSDATE-7’;（删除7天前的备份） DELETE ARCHIVELOG FROM TIME ‘SYSDATE-7’;（删除从7天前到现在的全部日志）]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[对Oracle数据做批量更新的两种方法]]></title>
      <url>%2F2016%2F02%2F22%2Foracle-update-01%2F</url>
      <content type="text"><![CDATA[同时对多条(w)数据做update操作，我用到了下面的两种方法 前言其实对表数据做更新一个update操作的事情，为啥还要整出下面的两种方法，之前在工作中测试数据，需要批量对数据做更新，都是在plsql中执行update，有一会遇到数据量稍微大点的，基本就“卡死”在update了。所以对数据量大点的操作基本不推荐直接update，根据测试结果我更偏向第二种方式。 1. Bulk CollectDECLARE TYPE rowid_list IS TABLE OF UROWID INDEX BY BINARY_INTEGER; rowid_infos rowid_list; i NUMBER; CURSOR c_rowids IS SELECT ROWID FROM t_target; BEGIN OPEN c_rowids; LOOP FETCH c_rowids BULK COLLECT INTO rowid_infos LIMIT 2000; FORALL i IN 1..rowid_infos.count UPDATE t_target SET DEVICE_MODE = to_char(LENGTH(DEVICE_MODE)+1) WHERE ROWID = rowid_infos(i) AND 1 = 1; EXIT WHEN ROWid_infos.count &lt; 2000; END LOOP; END; 2. insert append--创建临时表(不产生undo) CREATE TABLE T_TARGET_TEMP NOLOGGING AS SELECT * FROM T_TARGET WHERE 1=0; --写入数据的同时做出更新操作(以不产生undo的方式写入数据) INSERT /*+append*/INTO T_TARGET_TEMP SELECT UUID, ASSET_NO, FACTORY, to_char(LENGTH(DEVICE_MODE)+1),/** 做出修改 */ RUN_STATUS FROM t_target; --提交 COMMIT; --删除原表 DROP TABLE T_TARGET PURGE; --更名临时表为源表名 RENAME T_TARGET_TEMP TO T_TARGET; --修改表结构为归档模式,参数undo ALTER TABLE T_TARGET LOGGING; --创建索引 create index IDX_COMM_ADDRESS on T_TARGET (COMM_ADDRESS) tablespace EDMP pctfree 10 initrans 2 maxtrans 255 storage ( initial 4M minextents 1 maxextents unlimited ); ....]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[发布Node.js应用到NPM]]></title>
      <url>%2F2016%2F02%2F19%2Fnode-js-publish-to-npm%2F</url>
      <content type="text"><![CDATA[本篇主要分享下如何将Node.js应用发布到NPM 前言前提NPM和Node.js环境已经安装完成。 发布到Npm首页你得有一个NPM账户，没有大家可以自行到NPM官网上去注册。 1、通过npm初始化package.json文件 hunter@hunter-ubuntu:~/hello-hunter$ npm init ... Press ^C at any time to quit. name: (hello-hunter) version: (1.0.0) description: this is node demo entry point: (index.js) test command: git repository: keywords: test author: hunter license: (ISC) MIT About to write to /home/hunter/hello-hunter/package.json: { &quot;name&quot;: &quot;hello-hunter&quot;, &quot;version&quot;: &quot;1.0.0&quot;, &quot;description&quot;: &quot;this is node demo&quot;, &quot;main&quot;: &quot;index.js&quot;, &quot;scripts&quot;: { &quot;test&quot;: &quot;echo \&quot;Error: no test specified\&quot; &amp;&amp; exit 1&quot; }, &quot;keywords&quot;: [ &quot;test&quot; ], &quot;author&quot;: &quot;hunter&quot;, &quot;license&quot;: &quot;MIT&quot; } Is this ok? (yes) yes 2、在目录下面新增index.js文件，内容如下： module.exports = function(){ console.log(&quot;hello hunter&quot;); } 3、登录npm hunter@hunter-ubuntu:~/hello-hunter$ npm login Username: hunterlin Password: Email: (this IS public) *** Logged in as hunterlin on https://registry.npmjs.org/. 注意：创建的账户要到邮箱中激活才可以使用。 4、发布应用到npm hunter@hunter-ubuntu:~/hello-hunter$ npm publish + hello-hunter@3.0.0 到这里我们的node应用就发布到npm上面去了，我们可以在官网查询到我们发布的应用 5、从npm下载应用构建如下目录结构： hello-nodejs index.js package.json index.js文件内容如下： &#39;use strict&#39;; // 引入hello-hunter模块并调用 require(&#39;hello-hunter&#39;)(); package.json文件内容通过npm init来生成。 通过npm下载hello-hunter模块 hunter@hunter-ubuntu:~/test-nodejs$ npm install hello-hunter --save test-nodejs@1.0.0 /home/hunter/test-nodejs └── hello-hunter@1.0.0 运行node程序 hunter@hunter-ubuntu:~/test-nodejs$ node index.js hello hunter]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[如何编写Hexo插件]]></title>
      <url>%2F2016%2F02%2F19%2Fhexo-custom-plugin-01%2F</url>
      <content type="text"><![CDATA[本篇主要分享下如何在Hexo中自定义插件。前言我们现在编写一个插件，功能很简单，就是将文章中的所有超链接的打开方式换成在tab或新窗口中打开。 实现步骤 在node_modules目录下面新增插件目录hexo-test(注意hexo规定自定义插件目录名称必须是hexo-开头的) 在hexo-test目录下面新增以下文件： hexo-test(插件目录) index.js package.json README.md LICENSE lib filter.js 开始编写插件：在_config.yml中配置插件选项：test: _target: true index.js文件内容：&#39;use strict&#39;; if(hexo.config.test &amp;&amp; hexo.config.test._target){ hexo.extend.filter.register(&quot;after_render:html&quot;,require(&#39;./lib/filter&#39;)); } lib\filter.js文件内容：&#39;use strict&#39;; var cheerio = require(&#39;cheerio&#39;); module.exports = function(source){ var $ = cheerio.load(source); $(&quot;a&quot;).each(function(index,element){ $(this).attr(&quot;target&quot;,&quot;_blank&quot;); }); return $.html(); } package.json文件内容：{ &quot;name&quot;: &quot;hexo-test&quot;, &quot;version&quot;: &quot;1.0.0&quot; } 到这里，我们的自定义插件就完成了。 大家可以参考官网关于自定义插件文档介绍：https://hexo.io/docs/plugins.html另外官网上也介绍了如何将自定义插件发布到hexo站点供其他小伙伴使用。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[CommonJS,AMD,CMD及UMD规范介绍]]></title>
      <url>%2F2016%2F02%2F18%2FcommonJS-amd-cmd-umd-intro%2F</url>
      <content type="text"><![CDATA[本篇分享下关于前端模块规范CommonJS、AMD、CMD及UMD的介绍。 前言为什么要制定这些前端模块规范？由于JavaScript的崛起，很多基于js编写的应用组件给予了我们很大的便利，但是不可以避免会出现一个问题就是很多组件并不能愉快的在一起协同工作，例如会出现命名冲突、文件依赖等问题,参考下前端模块化开发的价值为了解决这些问题，一些牛人们就制定出了前端模块化规范，他们规定开发者们都采用一种约定好的模式来进行代码编写，以避免对整个生态圈的污染。 他们的异同CommonJS是运行在服务端的模块规范，Node.js实现了这种规范AMD、CMD、UMD是运行在浏览器端的模块规范，常用到的库有seajs，requirejs CommonJS据CommonJS规范，一个单独的文件就是一个模块，每一个模块都是一个单独的作用域。加载模块使用require方法，该方法读取一个文件并执行，最后返回文件内部的exports对象，CommonJS以同步方式加载模块。 模块定义 //MyUtil.js &#39;use strict&#39;; function util(args){ this.show = function(){ console.log(&quot;hello &quot;+args.name); } } module.exports = util; 模块加载 //index.js &#39;use strict&#39;; //require以同步方式加载模块 //加载jquery模块 var jquery = require(&#39;jquery&#39;); //加载自定义模块.js var MyUtil = require(&#39;./MyUtil&#39;); //加载common目录下面的index.js //var common = require(&#39;./common&#39;); var util = new MyUtil({name:&quot;hunter&quot;}); util.show(); 执行Node.js应用 node index.js AMD全称”Asynchronous Module Definition”(异步模块加载规范) , requirejs库实现了该规范。 模块定义 define(function(){ return {}; }) 模块加载 &#39;use strict&#39;; //加载jquery模块和sub模块 requirejs([&#39;lib/jquery&#39;,&#39;app/sub&#39;],function($,sub){ }) 关于requirejs库的详细使用可以参考：http://requirejs.org CMD全称”Common Module Definition”(通用模块加载规范)，seajs库实现了该规范。 模块定义及加载 // 所有模块都通过 define 来定义 define(function(require, exports, module) { // 通过 require 引入依赖 var $ = require(&#39;jquery&#39;); var Spinning = require(&#39;./spinning&#39;); // 通过 exports 对外提供接口 exports.doSomething = ... // 或者通过 module.exports 提供整个接口 module.exports = ... }); 关于seajs库的详细使用可以参考：http://seajs.org UMD全称”Universal Module Definition”(通用模块规范)UMD是AMD和CommonJS的糅合,因为AMD、CommonJS规范是两种不一致的规范，虽然他们应用的场景也不太一致，但是人们仍然是期望有一种统一的规范来支持这两种规范,于是UMD规范诞生了。 采用UMD规范编写的组件： // app.js (function (root, factory) { if (typeof define === &#39;function&#39; &amp;&amp; define.amd) { // AMD define([&#39;jquery&#39;], factory); } else if (typeof exports === &#39;object&#39;) { // Node, CommonJS-like module.exports = factory(require(&#39;jquery&#39;)); } else { // Browser globals (root is window) root.returnExports = factory(root.jQuery); } }(this, function ($) { // methods function myFunc(){ console.log(&quot;Jquery:&quot;+$); }; // exposed public method return myFunc; })); RequireJS调用 //加载require.js文件 &lt;script src=&quot;require.js&quot;&gt;&lt;/script&gt; &lt;script&gt; //加载app模块 requirejs([&#39;app&#39;],function(app){ app(); }) &lt;/script&gt; Node.js调用 &#39;use strict&#39;; require(&#39;./app&#39;)(); 原生调用 &lt;script src=&quot;jquery.js&quot;&gt;&lt;/script&gt; &lt;script src=&quot;app.js&quot;&gt;&lt;/script&gt; &lt;script&gt; this.returnExports(); &lt;/script&gt; 上面三种调用方式输出的结果是一样的，如果想让编写的组件支持AMD和CommonJS规范，那么就采用UMD来包装下吧。jQuery就采用这个方式包装了下让其可以支持AMD和CommonJS规范。 if ( typeof module === &quot;object&quot; &amp;&amp; module &amp;&amp; typeof module.exports === &quot;object&quot; ) { // Expose jQuery as module.exports in loaders that implement the Node // module pattern (including browserify). Do not create the global, since // the user will be storing it themselves locally, and globals are frowned // upon in the Node module world. module.exports = jQuery; } else { // Otherwise expose jQuery to the global object as usual window.jQuery = window.$ = jQuery; // Register as a named AMD module, since jQuery can be concatenated with other // files that may use define, but not via a proper concatenation script that // understands anonymous AMD modules. A named AMD is safest and most robust // way to register. Lowercase jquery is used because AMD module names are // derived from file names, and jQuery is normally delivered in a lowercase // file name. Do this after creating the global so that if an AMD module wants // to call noConflict to hide this version of jQuery, it will work. if ( typeof define === &quot;function&quot; &amp;&amp; define.amd ) { define( &quot;jquery&quot;, [], function () { return jQuery; } ); } }]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Node.js事件对象EventEmitter]]></title>
      <url>%2F2016%2F02%2F17%2Fnode-js-eventobj-EventEmitter%2F</url>
      <content type="text"><![CDATA[这篇主要分享下Node.js事件对象EventEmiiter的介绍和使用 前言Node.js 所有的异步 I/O 操作在完成时都会发送一个事件到事件队列。Node.js里面的许多对象都会分发事件：一个net.Server对象会在每次有新连接时分发一个事件， 一个fs.readStream对象会在文件被打开的时候发出一个事件。 所有这些产生事件的对象都是 events.EventEmitter 的实例。大多数时候我们不会直接使用 EventEmitter，而是在对象中继承它。包括 fs、net、 http 在内的，只要是支持事件响应的核心模块都是 EventEmitter 的子类。 EventEmitter类events模块只提供了一个对象：EventEmitter。EventEmitter的核心就是事件触发与事件监听器功能的封装。可以通过require(“events”)来访问该模块。 use &#39;strict&#39; // 引入 events 模块 var events = require(&#39;events&#39;); // 创建 eventEmitter 对象 var eventEmitter = new events.EventEmitter(); //注册test_event事件的监听器 eventEmitter.on(&#39;test_event&#39;, function() { console.log(&#39;test_event 事件触发&#39;); }); //1秒后向eventEmitter对象发送事件test_event,此时会调用test_event的监听器 setTimeout(function() { eventEmitter.emit(&#39;test_event&#39;); }, 1000); EventEmitter类信息 Events Class: events.EventEmitter Inheriting from ‘EventEmitter’ Class Method: EventEmitter.listenerCount(emitter, event) Event: ‘newListener’ Event: ‘removeListener’ EventEmitter.defaultMaxListeners emitter.addListener(event, listener) emitter.emit(event[, arg1][, arg2][, …]) emitter.getMaxListeners() emitter.listenerCount(type) emitter.listeners(event) emitter.on(event, listener) emitter.once(event, listener) emitter.removeAllListeners([event]) emitter.removeListener(event, listener) emitter.setMaxListeners(n) 用法参考：http://nodejs.cn/doc/node/events.html 继承EventEmitter &#39;use strict&#39; var util = require(&#39;util&#39;); var EventEmitter = require(&#39;events&#39;).EventEmitter; function MyObject() { EventEmitter.call(this); } // 通过util提供的方法使MyObject继承EventEmitter的方法 util.inherits(MyObject,EventEmitter); var obj = new MyObject(); obj.on(&quot;data&quot;,function(arg1,arg2) { console.log(&quot;接受事件：&quot;+arg1+&quot; &quot;+arg2); }); setTimeout(function() { obj.emit(&quot;data&quot;,&quot;hello&quot;,&quot;world&quot;); },1000); 通过继承EventEmitter，obj拥有了事件注册和触发等功能，很多node.js核心模块中的事件响应都是基于这种方法来实现的。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Hexo生成静态文件异常分析]]></title>
      <url>%2F2016%2F02%2F17%2Fhexo-generate-staticfile-error-analy%2F</url>
      <content type="text"><![CDATA[关闭Hexo默认highlight代码高亮，执行hexo g生成静态文件，出现异常：FATAL Template render error: tag name expected 前言想利用Google Code Prettify代码高亮来取代Hexo默认的highlight代码高亮，在修改全局配置文件_config.yml的highlight为false之后运行hexo g生成静态文件,结果出现异常：FATAL Template render error: tag name expected 原因在文章内容中出现了下面两种情况：# } #和}之间没有空格导致 { % {和%之间没有空格导致]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[读Hexo源码第二节]]></title>
      <url>%2F2016%2F02%2F17%2Fhexo-source-analy-02%2F</url>
      <content type="text"><![CDATA[在上一篇中已经介绍了Hexo-cli是如何加载到Hexo模块的，这篇着重分析下Hexo模块代码。 hexo-cli/lib/index.jsloadHexoModule方法主要是加载Hexo模块并实例化Hexo对象 function loadHexoModule(path, args) { var modulePath = pathFn.join(path, &#39;node_modules&#39;, &#39;hexo&#39;); try { //加载Hexo模块(\hexo\lib\hexo\index.js),关于这里是如何加载到的，上一篇文章“读Hexo源码第一节”已经做了说明 var Hexo = require(modulePath); //Hexo模块构造函数下面有介绍 var hexo = new Hexo(path, args); log = hexo.log; return runHexoCommand(hexo, args); } catch (_) { log.error(&#39;Local hexo not found in %s&#39;, chalk.magenta(tildify(path))); log.error(&#39;Try running: \&#39;npm install hexo --save\&#39;&#39;); process.exit(2); } } runHexoCommand方法主要是调用init方法进行初始化以及调用call方法去处理输入的命令 function runHexoCommand(hexo, args) { //调用hexo模块的init方法,init内容在下面介绍 return hexo.init().then(function() { var cmd = args._.shift(); if (cmd) { var c = hexo.extend.console.get(cmd); if (!c) cmd = &#39;help&#39;; } else if (args.v || args.version) { cmd = &#39;version&#39;; } else if (args.consoleList) { return console.log(Object.keys(hexo.extend.console.list()).join(&#39;\n&#39;)); } else if (args.completion) { return completion(args); } else { cmd = &#39;help&#39;; } watchSignal(hexo); //调用hexo模块的call方法，具体内容在下面介绍 return hexo.call(cmd, args).then(function() { return hexo.exit(); }).catch(function(err) { return hexo.exit(err).then(function() { handleError(err); }); }); }); } hexo/lib/hexo/index.js关于hexo模块，着重看下构造函数、init、call方法 Hexo构造函数 function Hexo(base, args) { //获取当前路径 E:\demo\hexo\source_analy base = base || process.cwd(); args = args || {}; //Hexo继承EventEmitter,使其拥有事件绑定和触发的能力。配合构造函数下面的代码require(&#39;util&#39;).inherits(Hexo, EventEmitter); EventEmitter.call(this); //设置目录名称 this.base_dir = base + sep; this.public_dir = pathFn.join(base, &#39;public&#39;) + sep; this.source_dir = pathFn.join(base, &#39;source&#39;) + sep; this.plugin_dir = pathFn.join(base, &#39;node_modules&#39;) + sep; this.script_dir = pathFn.join(base, &#39;scripts&#39;) + sep; this.scaffold_dir = pathFn.join(base, &#39;scaffolds&#39;) + sep; this.theme_dir = pathFn.join(base, &#39;themes&#39;, defaultConfig.theme) + sep; this.theme_script_dir = pathFn.join(this.theme_dir, &#39;scripts&#39;) + sep; this.env = { args: args, debug: Boolean(args.debug), safe: Boolean(args.safe), silent: Boolean(args.silent), env: process.env.NODE_ENV || &#39;development&#39;, version: pkg.version, init: false }; //全局配置文件_config.yml路径 this.config_path = args.config ? pathFn.resolve(base, args.config) : pathFn.join(base, &#39;_config.yml&#39;); //下面的模块都提供了register方法，在hexo的init方法中会将nodejs模块注册到下面对应的模块中去 this.extend = { console: new extend.Console(), deployer: new extend.Deployer(), // 过滤器链，提供了注册、异步和同步执行方法，可以将我们自定义的nodejs应用注册进去，可以参考nodejs模块：hexo-server filter: new extend.Filter(), generator: new extend.Generator(), helper: new extend.Helper(), migrator: new extend.Migrator(), processor: new extend.Processor(), renderer: new extend.Renderer(), //采用Nunjucks渲染标签 tag: new extend.Tag() }; //设置全局配置文件_config.yml this.config = _.clone(defaultConfig); this.log = createLogger(this.env); //提供render方法渲染数据或文件，具体内部还是调用this.extend.renderer注册的相关对象 this.render = new Render(this); //提供format方法处理url请求地址，在生成静态文件(hexo/lib/plugins/console/generate.js)的时候会调用里面的方法 this.route = new Router(); //提供create、render、publish方法，主要用于文章的创建和渲染以及将草稿文章发布成正式文章,具体内部还是调用了this.extend.renderer、this.extend.filter、this.extend.tag注册的相关对象 this.post = new Post(this); this.scaffold = new Scaffold(this); //默认db.json未加载 this._dbLoaded = false; //默认静态文件未生成 this._isGenerating = false; this.database = new Database({ version: dbVersion, path: pathFn.join(base, &#39;db.json&#39;) }); //初始化Schema模型并存储到database中 registerModels(this); this.source = new Source(this); this.theme = new Theme(this); this.locals = new Locals(this); this._bindLocals(); } init方法 Hexo.prototype.init = function(){ var self = this; this.log.debug(&#39;Hexo version: %s&#39;, chalk.magenta(this.version)); this.log.debug(&#39;Working directory: %s&#39;, chalk.magenta(tildify(this.base_dir))); // Load internal plugins //注册Hexo控制台命令到this.extend.console模块中，例如我们用到的hexo clean &amp; hexo g &amp; hexo d ... require(&#39;../plugins/console&#39;)(this); //注册到this.extend.filter模块中,具体功能下面分析 require(&#39;../plugins/filter&#39;)(this); require(&#39;../plugins/generator&#39;)(this); //注册到this.extend.helper模块中，提供了我们可以使用到的帮助标签，例如：link_to、image_tag、tagcloud等等，详情见：hexo/lib/plugins/helper/index.js require(&#39;../plugins/helper&#39;)(this); require(&#39;../plugins/processor&#39;)(this); //注册到this.extend.renderer模块中,提供了对html、css、js、json、swig、yml等语法的解析方法 require(&#39;../plugins/renderer&#39;)(this); //注册到this.extend.tag模块中，提供对&quot;{ % % }&quot;语法的解析，详情见：hexo/lib/plugins/tag/index.js require(&#39;../plugins/tag&#39;)(this); // Load config return Promise.each([ &#39;update_package&#39;, // Update package.json &#39;load_config&#39;, // Load config &#39;load_plugins&#39; // Load external plugins &amp; scripts ], function(name){ return require(&#39;./&#39; + name)(self); }).then(function(){ return self.execFilter(&#39;after_init&#39;, null, {context: self}); }).then(function(){ // Ready to go! self.emit(&#39;ready&#39;); }); }; call方法 Hexo.prototype.call = function(name, args, callback){ if (!callback &amp;&amp; typeof args === &#39;function&#39;){ callback = args; args = {}; } var self = this; return new Promise(function(resolve, reject){ //根据控制台输入的参数到Hexo.extend.console中获取到对应的js模块 var c = self.extend.console.get(name); if (c){ //调用对应参数的js模块 c.call(self, args).then(resolve, reject); } else { reject(new Error(&#39;Console `&#39; + name + &#39;` has not been registered yet!&#39;)); } }).nodeify(callback); }; hexo/lib/plugins/filter模块 module.exports = function(ctx){ var filter = ctx.extend.filter; //对文章中的摘要进行处理，即&lt;!--more--&gt; require(&#39;./after_post_render&#39;)(ctx); //处理代码高亮和将标题首字母转大写 require(&#39;./before_post_render&#39;)(ctx); //保存database中的数据到db.json require(&#39;./before_exit&#39;)(ctx); //渲染文章内容 require(&#39;./before_generate&#39;)(ctx); //模版本地化(i18n) require(&#39;./template_locals&#39;)(ctx); filter.register(&#39;new_post_path&#39;, require(&#39;./new_post_path&#39;)); filter.register(&#39;post_permalink&#39;, require(&#39;./post_permalink&#39;)); };]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[读Hexo源码第一节]]></title>
      <url>%2F2016%2F02%2F16%2Fhexo-source-analy-01%2F</url>
      <content type="text"><![CDATA[Hexo使用已经有段时间了，昨天想利用Google-Code-Prettify取代Hexo默认的高亮配置，修改了_config.yml的highlight为false，结果在生成静态文件的时候报错，由于对Hexo内部运转不是太清楚，为了解决这个问题，我不得不深入研究下Hexo的源码来了解其运行过程。hexo-cli安装完成后，需要进行环境变量配置，这样我们才能在dos中使用hexo命令。我这里的nodejs是安装在E:\opensource\nodejs目录下面,那么需要把E:\opensource\nodejs配置到path变量中。 我们在dos中执行：hexo help，其实是调用E:\opensource\nodejs目录下面的hexo.cmd批处理文件。 hexo.cmd rem 先判断当前目录下是否存在node.exe @IF EXIST &quot;%~dp0\node.exe&quot; ( rem 存在则调用当前目录下面的node_modules\hexo-cli\bin\hexo 模块 &quot;%~dp0\node.exe&quot; &quot;%~dp0\node_modules\hexo-cli\bin\hexo&quot; %* ) ELSE ( @SETLOCAL @SET PATHEXT=%PATHEXT:;.JS;=;% node &quot;%~dp0\node_modules\hexo-cli\bin\hexo&quot; %* ) hexo模块 #!/usr/bin/env node &#39;use strict&#39;; //调用上一层目录lib(执行下面的index.js文件) require(&#39;../lib&#39;)(); lib目录结构： lib index.js find_pkg.js completion.js logger.js goodbye.js console index.js init.js version.js help.js lib/index.js文件主要是调用find_pkg模块进行package.json的查找 exports = module.exports = function() { //调用find_pkg模块进行包查找 return findPkg(cwd, args).then(function(path) { //如果当前目录不存在则调用hexo-cli命令输出 if (!path) return runCLICommand(args); //如果找到了package.json，则加载Hexo模块 return loadHexoModule(path, args); }).catch(handleError); }; lib/find_pkg.js主要是查找当前目录下的package.json文件 function findPkg(path) { //查找当前目录下面的package.json,例如：E:\demo\hexo\source_analy\pakcage.json var pkgPath = pathFn.join(path, &#39;package.json&#39;); return fs.exists(pkgPath).then(function(exist) { //如果找到了package.json则检查是否是hexo包声明 return exist ? checkPkg(pkgPath) : false; }).then(function(exist) { if (exist) return path; //如果没有找到，则往上一目录进行查找 var parent = pathFn.dirname(path); if (parent === path) return; return findPkg(parent); }); } 假设我们的hexo环境已经初始化好(hexo init)，通过find_pkg模块已经查找到了package.json，接着会加载Hexo模块 function loadHexoModule(path, args) { var modulePath = pathFn.join(path, &#39;node_modules&#39;, &#39;hexo&#39;); try { //请求当前目录下面的/node_modules/hexo模块,这里我的全路径是：E:\demo\hexo\source_analy\node_modules\hexo var Hexo = require(modulePath); if(1==1){return;} var hexo = new Hexo(path, args); log = hexo.log; //处理hexo命令 return runHexoCommand(hexo, args); } catch (_) { log.error(&#39;Local hexo not found in %s&#39;, chalk.magenta(tildify(path))); log.error(&#39;Try running: \&#39;npm install hexo --save\&#39;&#39;); process.exit(2); } } 上面代码中require(modulePath)中modulePath是一个目录地址，不是js文件，下面没有index.js文件，这里是如何识别他是一个nodejs模块的呢。这就要看该目录下面的package.json文件了,在大概116行，其实是通过这里的main指定了node模块的。 &quot;main&quot;: &quot;lib/hexo&quot; 到这里基本就很清楚Hexo模块是如何加载进来的，下一节着重分析下Hexo模块代码。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Bat语法总结]]></title>
      <url>%2F2016%2F02%2F16%2Fbat-syntax%2F</url>
      <content type="text"><![CDATA[这篇主要分享下Window下Bat相关语法的介绍和使用 echo和@@ 关闭当前行回显echo off 从下一行开始关闭回显@echo off 从本行开始关闭回显，一般批处理第一行都是这个echo on 从下一行开始打开回显echo 显示当前echo是关闭还是打开状态echo hello 屏幕打印hello字符串 errorlevelecho %errorlevel%每个命令运行结束，可以用这个命令行查看返回码，默认值为0，命令执行出错会设errorlevel为1 dir显示目录下的所有文件dir d:temp3 显示temp3下的所有文件，不包括隐藏、系统、只读文件、子目录文件dir /s/a d:temp3 显示temp3下的所有文件，包括隐藏、系统、只读文件、子目录文件dir /a d:temp3 显示temp3下的所有文件和子目录包括隐藏和系统文件dir /a:d d:temp3 显示temp3下的所有目录dir /a:-d d:temp3 显示temp3下的所有文件dir /b/p d:temp3 分页显示temp3下的所有文件的文件名dir /s d:temp3\*.txt 显示temp3目录及其子目录下面的所有txt文件 md创建目录md d:mydir 在d盘创建目录md d:&quot;one/&quot;two 在d盘创建目录one/two rd删除目录rd abc 删除空目录abcrd /s/q d:&quot;temp 删除d盘temp文件夹及其子文件夹和文件 del删除文件del d:&quot;test.txt 删除指定文件，不能是隐藏、系统、只读文件del /q/a/f d:&quot;temp\*.* 删除d:temp文件夹下面的所有文件、包括隐藏、只读、系统文件、不包括子目录del /q/a/f/s d:&quot;temp2\*.*删除d:temp2文件夹及其子文件夹下面的所有文件、包括隐藏、只读、系统文件、不包括子目录 ren重命名ren d:&quot;temp&quot; temp2 将d盘目录下面的temp重命名为temp2 type文件内容查看type d:temp\child\aa.txt 查看文件内容 copy文件复制copy d:&quot;temp&quot;\&quot;child&quot;\&quot;aa.txt&quot; d:&quot;temp&quot;\&quot;AA.txt&quot; 复制文件并重命名copy con d:temp\&quot;hello world.txt&quot; 从屏幕上等待输入，将输入数据拷贝到指定目录，按Ctrl+Z 回车结束输入copy 1.txt+2.txt 3.txt 合并1.txt和2.txt的内容拷贝到3.txt文件,如果不指定3.txt 则保存到1.txt con：屏幕；prn：打印机；nul：空设备 titletitle hello 设置cmd窗口标题为hello verver 显示系统版本 pausepause 暂停命令 rem和::注释命令rem 这里是注释，不会被执行:: 也是注释,不会回显 date和time日期和时间date 显示日期并提示输入新的日期time 显示时间并提示输入新的时间date/t 只显示日期不提示输入新日期 goto和: 跳转命令:label 行首为：表示该行是标签行,标签行不执行操作goto label 跳转到指定的标签行 find查找文件内容find &quot;hello&quot; d:temp\AA.txt 在AA.txt文件中查找含有hello字符串的行find /i &quot;hello&quot; d:temp\AA.txt 查找含有hello的行，忽略大小写find /c &quot;hello&quot; d:temp\AA.txt 显示含有hello的行的总行数 more 逐屏显示more &quot;d:temp/AA.txt&quot; tree显示目录结构tree d:temp 以树形结构显示temp目录下的所有文件 &amp;按顺序执行多条命令，不管命令是否执行成功hexo clean &amp; hexo g &amp; hexo d &amp;&amp;顺序执行多条命令，当碰到执行出错的命令将不执行后面的命令find &quot;hello&quot; d:temp\AA.txt &amp;&amp; echo 找到你了 ||顺序执行多条命令，当碰到执行正确的命令将不执行后面的命令find &quot;hello&quot; d:temp\AA.txt || echo 没有找到 |管道命令dir d:temp3 /s/a | find /c &quot;.txt&quot;先执行dir命令，对其输出的结果执行后面的find命令，该命令的结果是：输出当前文件夹及其所有子文件夹里面的.txt文件的个数 &gt;和&gt;&gt;输出重定向命令&gt; 清除文件内容再写入&gt;&gt; 不清除文件内容，直接追加内容到文件末尾 type d:temp3\AA.txt &gt; prn将AA.txt文件内容转向输出到打印机，不在屏幕上显示 echo hello world &gt; con在屏幕上显示hello world,实际上所有的输出都是默认 &gt; con 的 echo ^^1^&gt;2 &gt; d:temp3\test.txt生成内容为：^1&gt;2^和&gt;是控制命令，要将他们输出，则必须在前面加^符号 &lt;从文件中获取输入信息 @echo off echo 2026-02-16 &gt; d:temp\date.txt date &lt; d:temp\date.txt del d:temp\date.txt %0 %1 %2 %3 %*命令行传递给批处理的参数%0 批处理文件本身%1 第一个参数%3 第二个参数%* 第n个参数 用法：test.bat 第一个参数 第二个参数 批参数的替代已被增强，语法如下：%~d1 将%1扩充到一个驱动器号%~f1 将%1扩充到一个全路径名%~p1 将%1扩充到一个相对路径%~n1 将%1扩充到一个文件名 if判断命令if %1 == server echo 第一个参数是server运行test.bat server if /i %1 equ server echo 第一个参数是server忽略大小写 ==与equ是一样的效果,其他运算符参见：if/? if exist d:temp\AA.txt echo 存在AA.txt文件 if exist D:temp\AA.txt ( echo 存在AA文件 ) else ( echo 不存在AA文件 ) 注意：if、else和括号之间有空格 for循环命令for %%i in (1,2,3 a b c) do echo %%i循环小括号里面的字符串,然后执行do后面的命令字符串分隔符可以是,空格 for %%i in (D:temp3\*.txt) do find &quot;hello&quot; %%i循环temp3目录下的所有txt文件并执行find查找包含hello的字符串行 for /r %%i in (D:temp3\*.txt) do find &quot;hello&quot; %%i循环temp3目录及其子目录下面的所有txt文件，并搜索包含hello的字符串行 start批处理中调用外部程序的命令 call批处理中调用另外一个批处理的命令 xcopy文件夹拷贝xcopy d:temp d:temp2 /s/e/i/y将temp文件夹、所有子文件夹和文件复制到指定目录，覆盖已有的文件参数/i表示如果指定目标目录不存在则自动创建，否则会询问注意：隐藏的文件不会复制过去 subst映射磁盘subst Q: \\10.0.88.10\公共盘 #这样就将指定的公共盘符映射到本地了，可以通过Q:来访问了subst Q: /d #取消该映射subst #查看所有的映射 查看网络驱动器的ip地址regedit&gt;HKEY_CURRENT_USER&gt;Network 查看命令帮助命令 /?例如：dir /?]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Node.js的模块系统]]></title>
      <url>%2F2016%2F02%2F15%2Fnode-js-module%2F</url>
      <content type="text"><![CDATA[这篇主要分享下如何自定义模块以及服务端模块的加载规则目录： exports和require 自定义模块 服务端模块 前言 为了让Node.js之间可以相互调用，Node.js提供了一个简单的模块系统。模块是Node.js应用程序的基本组成部分，一个Node.js文件就是一个模块，文件内容可以是JavaScript代码、JSON或者是编译过的C/C++扩展。 exports和require exports ：作为模块内部返回的对象require ：用于从外部获取一个模块接口，即所获取模块的 exports 对象 require方法接受以下几种参数的传递： http、fs、path等，原生模块。 ./mod或../mod，相对路径的文件模块。 /pathtomodule/mod，绝对路径的文件模块。 mod，非原生模块的文件模块。 自定义模块 首先，我们创建一个文件命名为：hello.js，内容如下： exports.hello = function(){ console.log(&quot;hello&quot;); } /** module.exports.hello = function(){ console.log(&quot;hello&quot;); } **/ hello.js返回exports对象，即：{hello:Function} 接下来我们创建另外一个文件：main.js,内容如下： require(&quot;./hello&quot;)(); 在main.js文件中，代码require(“./hello”)引入了当前目录下的hello.js文件(默认.js后缀),即引入了我们定义的hello模块。 注意：require(“./hello”) 是引入当前目录下面的hello.js,也可以是引入当前目录下的hello目录(hello目录中有index.js文件)，这两种方法效果一样，hexo的启动方式就是采用第二种方式进行的。目录结构如下： demo main.js lib index.js index.js文件内容如下： &#39;use strict&#39; module.exports = function(){ console.log(&quot;hello world&quot;); } main.js文件内容如下： &#39;use strict&#39; require(&#39;./lib&#39;)(); 即：require(‘./lib/index.js’) == require(‘./lib’); 服务端模块 Node.js提供了很多内置的服务端模块供我们使用，大大的提高了我们的开发效率。例如：使用提供的http模块 var http = require(&quot;http&quot;); ... http.createServer(...); 关于服务端内置模块的查找规则如下： 在Node.js中模块分为2类：原生模块和文件模块 其中文件模块分为3类模块，通过后缀来区分，Node.js会根据后缀来决定加载方法。 .js 通过fs模块同步读取js文件并编译执行。 .node 通过C/C++进行编写的Addon,通过dlopen方法进行加载。 .json 调用JSON.parse解析加载。 在Node.js中模块分为4类(原生模块和3种文件模块)，通过require很容易就加载到需要的模块了，但是其内部的加载流程却是不简单的，整个加载流程如下图所示：]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Git中fetch和merge的使用]]></title>
      <url>%2F2016%2F02%2F14%2Fgit-fetch-merge%2F</url>
      <content type="text"><![CDATA[这篇主要分享下Git中fetch和merge命令的使用，使用过svn的同学应该都知道，如果远程版本库有更新，我们要同步本地代码与版本库保持一致可以使用update操作。git上是通过fetch和merge命令来从远程库中获取最新的版本并合并到本地版本中去的。目录 fetch命令 merge命令 fetch命令 命令：git fetch origin master 从远程origin的master分支下载最新的版本到本地master分支命令：git log -p master..origin/master 比较本地的master分支和远程origin/master分支的日志差异命令：git log -1 master..origin/master 只显示一行日志差异 merge命令 命令：git merge origin/master 合并master分支版本 查看origin指向 命令：git remote -v]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Git分支的基础使用]]></title>
      <url>%2F2016%2F02%2F14%2Fgit-branch-basic-intro%2F</url>
      <content type="text"><![CDATA[这篇主要分享下Git分支的基本操作，关于具体的概念大家可以去百度搜索了解，本篇不做介绍目录 查看分支 创建分支 切换分支 修改分支名称 分支合并 删除分支 前提 在上一篇Git最最最基础命令入门中，我已经创建了一个版本库：https://github.com/linmuxi/test-git.git下面的演示就基于这个版本库来操作。 第一步先将版本库clone到本地，具体操作步骤可以参考上一篇文章 ，这里就不做具体介绍 查看分支 查看远程分支：git branch -r查看本地分支：git branch -l 或 git branch查看所有分支：git branch -a可以看到目前只有一个master主分支，这个master分支也是git默认的分支 创建分支 输入命令：git branch myBranch01再次查看分支，输入命令：git branch -l可以看到myBranch01分支已经创建成功注意：该分支只是在本地创建了，在远程库中并不存在，大家可以登录到Github上去确认下，也可以通过命令：git branch -r来确认 接下来就是将刚才创建的myBranch01分支同步到远程库中去输入命令：git push origin myBranch01在输入账户和密码之后，创建的分支就已经同步到远程库中去了，可以登录Github进行确认，也可以通过命令：git branch -r来确认 切换分支 输入命令：git checkout myBranch01接着查看所有分支：git branch -l可以看到当前分支已经切换到myBranch01上面去了 修改分支名称 输入命令：git branch -m myBranch01 myBranch001接着查看分支名称修改情况：本地的已经修改过来，远程的还未同步修改执行同步修改命令：git push origin myBranch001最后删除修改前的myBranch01分支：git push origin :myBranch01到这里分支名称就修改完成，觉得这样的操作很麻烦。 分支合并 合并操作前先查看master和myBranch001分支下面文件的内容 接下来切换当前分支到想要合并到的分支下（本例中要将myBranch001分支合并到master分支中，则切换当前分支到master下面），然后执行分支合并命令：git merge myBranch001 删除分支 输入命令：git branch -d myBranch01注意：假如当前分支是myBranch01，则这里是不允许删除的，需要切换到别的分支才能将其删除 到这里，本地的分支已经被删除了，但是远程库中的还没有被删除。输入命令：git push origin :myBranch01这样远程库中的myBranch01分支就被同步删除了。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[解决DBLink带有后缀的问题]]></title>
      <url>%2F2016%2F02%2F01%2Foracle-deal-02-dblink%2F</url>
      <content type="text"><![CDATA[这篇主要分享在默认配置下创建DBLink带有后缀的问题。新建DBLink默认情况下DBLink名称是带有后缀的，此后缀来自global_name;一般生成的DBLink名称是这样的：myDBLink.REGRESS.RDBMS.DEV.US.ORACLE.COM 查看全局名称:select * from GLOBAL_NAME;//ORCL.REGRESS.RDBMS.DEV.US.ORACLE.COM 可以通过如下修改，屏蔽生成后缀 使用sys账户执行以下语句：update global_name set global_name = &#39;hunter&#39;;//不为空 再次创建DBLink，发现名称不再带有后缀了]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[使用PLSQL Developer连接64位Oracle11g数据库]]></title>
      <url>%2F2016%2F02%2F01%2Fplsql-developer-connect-oracle11g-64bit%2F</url>
      <content type="text"><![CDATA[这篇主要分享如何使用PLSQL Developer连接64位Oracle数据库。第一步：安装Oracle 11g 64位 第二步：安装32位的Oracle客户端（ instantclient-basic-win32-11.2.0.1.0） 注意：Oracle客户端一定得是32位的，不要下错了版本，Oracle官网有下载 第三步：将其解压至Oracle安装目录的Product下：D:\Oracle\app\hunter\product\instantclient_11_2 第四步：拷贝数据库安装根目录下的NETWORK目录到Oracle客户端目录的instantclient_11_2目录下面。NETWORK目录的绝对路径：D:\Oracle\app\hunter\product\11.2.0\dbhome_1\NETWORKinstantclient_11_2目录的绝对路径：D:\Oracle\app\hunter\product\instantclient_11_2 第五步：安装PL/SQL Developer安装 PL/SQL Developer，在perference-&gt;Connection里面设置OCI Library和Oracle_Home，例如本机设置为：Oracle Home ：D:\Oracle\app\hunter\product\instantclient_11_2OCI Library ：D:\Oracle\app\hunter\product\instantclient_11_2\oci.dll 第六步：设置环境变量(修改PATH和TNS_ADMIN环境变量)对于NLS_LANG环境变量, 最好设置成和数据库端一致, 首先从数据库端查询字符集信息: SQL&gt; select userenv(&#39;language&#39;) nls_lang from dual; NLS_LANG ---------------------------------------------------- SIMPLIFIED CHINESE_CHINA.ZHS16GBK 右击”我的电脑” - “属性” - “高级” - “环境变量” - “系统环境变量”:1&gt;.选择”Path” - 点击”编辑”, 把 “D:\Oracle\app\hunter\product\instantclient_11_2;” 加入;2&gt;.点击”新建”, 变量名设置为”TNS_ADMIN”, 变量值设置为”D:\Oracle\app\hunter\product\instantclient_11_2;”, 点击”确定”;3&gt;.点击”新建”, 变量名设置为”NLS_LANG”, 变量值设置为”SIMPLIFIED CHINESE_CHINA.ZHS16GBK”, 点击”确定”; 最后，启动 PL/SQL Developer ，运行无问题。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Oracle小数点转字符丢失0的处理方法]]></title>
      <url>%2F2016%2F02%2F01%2Foracle-deal-01%2F</url>
      <content type="text"><![CDATA[Oracle中将含有小数点的数值进行字符串转换，会出现0丢失的情况，大家是怎么处理这种情况的？我是这样做的： SELECT to_char(0.123,&#39;fm99999999999999990.00&#39;) FROM dual;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[[推荐]报表设计工具iReport]]></title>
      <url>%2F2016%2F02%2F01%2Frecommend-tool-ireport%2F</url>
      <content type="text"><![CDATA[这篇主要分享一款报表设计工具iReport，因为在项目中实际应用过，觉得好用，推荐给大家。本篇不做详细介绍，感兴趣和有需求的可以自行查阅相关资料进行了解，也可以留言进行交流其提供的可视化报表设计工具挺好用的，而且提供API供编程使用，可支持导出多种格式，例如PDF、HTML、EXCEL等。 下面是可视化报表设计工具的工作台截图： 下面是在项目中设计的报表模版： 利用提供的API导出报表到PDF // 可视化工具设计的模版文件 String filePath = &quot;E:\\demo\\iReport\\myReport.jasper&quot;; // 通过模版文件实例化报表对象 JasperReport report = (JasperReport) JRLoader.loadObjectFromFile(filePath); report.setWhenNoDataType(WhenNoDataTypeEnum.ALL_SECTIONS_NO_DETAIL); // 下面是封装的数据实体对象 Map&lt;String, Object&gt; params = new HashMap&lt;String, Object&gt;(); // list集合对象 params.put(&quot;repaymentDetailDS&quot;, new JRBeanCollectionDataSource(getRepaymentDetailList())); // 实体VO对象,可以直接在报表模版中通过vo对象来调用 params.put(&quot;vo&quot;, getParams()); // 利用提供的数据填充报表对象 JasperPrint print4 = JasperFillManager.fillReport(report, params,new JREmptyDataSource()); List&lt;JasperPrint&gt; printList = new ArrayList&lt;JasperPrint&gt;(); printList.add(print4); // 设置导出格式为PDF JRPdfExporter pdfExporter = new JRPdfExporter(); // 导入源 pdfExporter.setExporterInput(SimpleExporterInput.getInstance(printList)); // 导出源 pdfExporter.setExporterOutput(new SimpleOutputStreamExporterOutput(&quot;E:/myReport.pdf&quot;)); // 可以进行PDF参数配置 SimplePdfExporterConfiguration spec = new SimplePdfExporterConfiguration(); /*spec.setEncrypted(true); spec.setUserPassword(&quot;123456&quot;);*/ pdfExporter.setConfiguration(spec); // 导出PDF对象 pdfExporter.exportReport();]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[使用Flex4接受Red5服务器上的实时流数据]]></title>
      <url>%2F2016%2F02%2F01%2Fflex4-receive-stream-from-read5%2F</url>
      <content type="text"><![CDATA[这篇主要分享如何使用Flex4从Red5服务器上接受实时流数据。关于Flex环境搭建和Red5服务器的部署和操作，不在本篇介绍范围内。 具体操作代码比较简单，关键点都有中文注释，Flex代码如下： &lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt; &lt;s:Application xmlns:fx=&quot;http://ns.adobe.com/mxml/2009&quot; xmlns:s=&quot;library://ns.adobe.com/flex/spark&quot; xmlns:mx=&quot;library://ns.adobe.com/flex/mx&quot; minWidth=&quot;955&quot; minHeight=&quot;600&quot;&gt; &lt;fx:Declarations&gt; &lt;!-- 将非可视元素（例如服务、值对象）放在此处 --&gt; &lt;/fx:Declarations&gt; &lt;fx:Script&gt; &lt;![CDATA[ var rtmpURL:String = &quot;rtmp://192.168.1.103/mystream&quot;; var conn:NetConnection = new NetConnection(); var netstream:NetStream; var video:Video; function connServer(e:MouseEvent):void{ conn.connect(rtmpURL); conn.addEventListener(NetStatusEvent.NET_STATUS,netStatusHandler); } function netStatusHandler(e:NetStatusEvent):void{ switch(e.info.code){ case &quot;NetConnection.Connect.Success&quot;:{ connStream(); } case &quot;NetStream.Play.StreamNotFound&quot;:{ } } } function connStream():void{ netstream = new NetStream(conn); netstream.play(&quot;hunter&quot;);//如果是实时流这里文件后缀不要 video = new Video(300,200); video.attachNetStream(netstream); vd.addChild(video); } ]]&gt; &lt;/fx:Script&gt; &lt;s:Button label=&quot;查看视频&quot; x=&quot;20&quot; y=&quot;30&quot; click=&quot;this.connServer(event)&quot; /&gt; &lt;!-- &lt;s:VideoPlayer x=&quot;21&quot; y=&quot;59&quot; id=&quot;vp&quot;&gt;&lt;/s:VideoPlayer&gt; --&gt; &lt;s:VideoDisplay x=&quot;21&quot; y=&quot;59&quot; id=&quot;vd&quot;&gt; &lt;/s:VideoDisplay&gt; &lt;/s:Application&gt;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[使用Flex4进行视频流采集并发布到Red5服务器上]]></title>
      <url>%2F2016%2F02%2F01%2Fflex4-gather-stream-publish-read5%2F</url>
      <content type="text"><![CDATA[这篇主要分享如何通过Flex4进行本地视频流采集并实时发布到Red5服务器上去。关于Flex环境搭建和Red5服务器的部署和操作，不在本篇介绍范围内。 具体操作代码比较简单，关键点都有中文注释，Flex代码如下： &lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt; &lt;s:Application xmlns:fx=&quot;http://ns.adobe.com/mxml/2009&quot; xmlns:s=&quot;library://ns.adobe.com/flex/spark&quot; xmlns:mx=&quot;library://ns.adobe.com/flex/mx&quot; minWidth=&quot;955&quot; minHeight=&quot;600&quot;&gt; &lt;fx:Declarations&gt; &lt;!-- 将非可视元素（例如服务、值对象）放在此处 --&gt; &lt;/fx:Declarations&gt; &lt;fx:Script&gt; &lt;![CDATA[ var con:NetConnection = new NetConnection(); //Red5服务器流地址 var rtmpURL:String = &quot;rtmp://192.168.1.103/mystream&quot;; var netStream:NetStream; var video:Video = new Video(); //以实时流形式发布视频流到red5上去 private function netStatus(e:NetStatusEvent):void{ if(e.info.code == &#39;NetConnection.Connect.Success&#39;){ //通过netconnection构建netstream netStream = new NetStream(con); //附加视频和音频数据到netstream中 netStream.attachCamera(Camera.getCamera()); netStream.attachAudio(Microphone.getMicrophone()); //以记录方式发布名称为hunter的实时流到Red5流媒体服务器上 netStream.publish(&quot;hunter&quot;,&quot;live&quot;); //发布之后red5下mystream/streams/下面就会生成hunter.flv文件 } } //打开本地摄像头 private function openVideo(e:MouseEvent):void{ //获取本地摄像头数据并附加在video对象上 video.attachCamera(Camera.getCamera()); video.width = 300; video.height = 200; //video附加在videoDisplay上显示 vd.addChild(video); } private function publishRed5Server(e:MouseEvent):void{ //连接到Red5服务器上 con.connect(rtmpURL); //监听连接状态 con.addEventListener(NetStatusEvent.NET_STATUS,netStatus); } //进行录像 private function recordVideo(e:MouseEvent):void{ //先停止以前实时流模式，重启发布记录流模式 netStream.close(); netStream.publish(&quot;hunter&quot;,&quot;record&quot;); } private function stopPublish(e:MouseEvent):void{ netStream.close(); } ]]&gt; &lt;/fx:Script&gt; &lt;s:Button x=&quot;11&quot; y=&quot;10&quot; label=&quot;打开视频&quot; click=&quot;this.openVideo(event)&quot; /&gt; &lt;s:Button x=&quot;89&quot; y=&quot;10&quot; label=&quot;发布视频&quot; click=&quot;this.publishRed5Server(event)&quot;/&gt; &lt;s:Button x=&quot;167&quot; y=&quot;10&quot; label=&quot;录制视频&quot; click=&quot;this.recordVideo(event)&quot;/&gt; &lt;s:Button x=&quot;254&quot; y=&quot;10&quot; label=&quot;停止发布&quot; click=&quot;this.stopPublish(event)&quot; /&gt; &lt;s:VideoDisplay id=&quot;vd&quot; x=&quot;11&quot; y=&quot;52&quot; width=&quot;300&quot; height=&quot;200&quot; /&gt; &lt;!-- &lt;mx:UIComponent id=&quot;videoCan&quot; x=&quot;10&quot; y=&quot;258&quot; width=&quot;300&quot; height=&quot;200&quot;&gt; &lt;/mx:UIComponent&gt; --&gt; &lt;/s:Application&gt;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[智能配电房Android应用]]></title>
      <url>%2F2016%2F02%2F01%2Fandroid-demo-01-pdf%2F</url>
      <content type="text"><![CDATA[&nbsp;&nbsp;&nbsp;&nbsp;之前部门为了做移动转型，组织了一个移动开发大赛，找几位同事一起参加做了这款应用，算是第一次做Android应用，因为要求是业余时间来完成，周期上又比较赶，恰巧又赶上项目组外出封闭开发，所以整个项目做下来比较粗糙，有很多功能都还未能实现。加上基本上都是晚上下班回家熬夜边自学边开发的一个状态，身体在那段时间也累的够呛。不过那段时间也算是过的比较充裕，感觉每分每秒都是在学习当中。上两张图留个记录示例代码已经放到GitHub上]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Tomcat配置SSL,支持HTTPS访问]]></title>
      <url>%2F2016%2F02%2F01%2Ftomcat-config-ssl%2F</url>
      <content type="text"><![CDATA[这篇主要分享在Tomcat上配置SSL，开启HTTPS访问。第一步：通过keytools生成秘钥输入命令：keytool -genkey -alias hunter -keyalg RSA会在用户目录下面创建一个.keystore的文件 第二步：修改tomcat\config\server.xml文件 &lt;Connector port=&quot;8443&quot; protocol=&quot;org.apache.coyote.http11.Http11Protocol&quot; maxThreads=&quot;150&quot; SSLEnabled=&quot;true&quot; scheme=&quot;https&quot; secure=&quot;true&quot; clientAuth=&quot;false&quot; sslProtocol=&quot;TLS&quot; keystorePass=&quot;这里是第一步配置的是keystore密码&quot; /&gt; 到这里，就可以通过https://localhost:8443/ 进行访问了，当然也还是可以通过http://localhost:8080/ 进行访问,不过通过后者访问就不是基于https协议了。 通过下面的配置，能让http访问自动转换到https协议上去进行访问:修改应用服务web.xml文件 &lt;security-constraint&gt; &lt;web-resource-collection&gt; &lt;web-resource-name&gt;securedapp&lt;/web-resource-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/web-resource-collection&gt; &lt;user-data-constraint&gt; &lt;transport-guarantee&gt;CONFIDENTIAL&lt;/transport-guarantee&gt; &lt;/user-data-constraint&gt; &lt;/security-constraint&gt; 将 URL 映射设为 /* ，这样整个应用都要求是 HTTPS 访问，而 transport-guarantee 标签设置为 CONFIDENTIAL 以便使应用支持 SSL。如果你希望关闭 SSL ，只需要将 CONFIDENTIAL 改为 NONE 即可。 最后，让http访问自动转换到https协议，据说还有一种配置服务器响应strict-transport-security报文，还未测试，可以参考说明]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[使用Fusionchart导出图表并写入Excel中]]></title>
      <url>%2F2016%2F02%2F01%2Ffusionchart-export-chart-to-excel%2F</url>
      <content type="text"><![CDATA[本篇主要分享下如何将Fusionchart图表导出到Excel中，导出到Excel中的仅仅为一张图形图片，并不具备Excel图表编辑功能第一步：将fcexporter.jar、fcexporthandler.jar导入lib下 第二步：在classs下新建导出配置文件fusioncharts_export.properties #Please specify the path to a folder with write permissions relative to web application root SAVEPATH=./images/ #This constant HTTP_URI stores the HTTP reference to #the folder where exported charts will be saved. #Please enter the HTTP representation of that folder #in this constant e.g., http://www.yourdomain.com/images/ HTTP_URI=http://www.yourdomain.com/images/ #OVERWRITEFILE sets whether the export handler will overwrite an existing file #the newly created exported file. If it is set to false the export handler will #not overwrite. In this case if INTELLIGENTFILENAMING is set to true the handler #will add a suffix to the new file name. The suffix is a randomly generated UUID. #Additionally, you can add a timestamp or random number as additional prefix. OVERWRITEFILE=false INTELLIGENTFILENAMING=true FILESUFFIXFORMAT=TIMESTAMP 第三步：修改web.xml &lt;servlet&gt; &lt;display-name&gt;FCExporter&lt;/display-name&gt; &lt;servlet-name&gt;FCExporter&lt;/servlet-name&gt; &lt;servlet-class&gt;com.fusioncharts.exporter.servlet.FCExporter&lt;/servlet-class&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;FCExporter&lt;/servlet-name&gt; &lt;url-pattern&gt;/JSP/ExportExample/FCExporter&lt;/url-pattern&gt; &lt;!-- 这里配置根据自己应用需求来(请求jsp所在的文件目录) --&gt; &lt;/servlet-mapping&gt; 第四步：编辑报表属性 &lt;chart exportEnabled=&quot;1&quot; exportAction=&quot;save&quot; exportAtClient=&quot;0&quot; exportFileName=&quot;fileName&quot; exporthandler=&quot;FCExporter&quot;&gt; 第五步：调用JS函数 var chartObject = getChartFromId(&#39;myChart&#39;); if( chartObject.hasRendered()) chartObject.exportChart(); 第六步：将图片写入Excel中 ByteArrayOutputStream allOutputStream = new ByteArrayOutputStream(); ByteArrayOutputStream outputStream = new ByteArrayOutputStream(); Workbook book = WorkbookFactory.create(fileTransfer.getInputStream()); File file = new File(FusionChartsExportHelper.SAVEPATH+imageName+&quot;.jpg&quot;); BufferedImage bufferImg = ImageIO.read(file); ImageIO.write(bufferImg, &quot;jpg&quot;, outputStream); HSSFSheet sheet1 = (HSSFSheet) book.getSheetAt(0); HSSFPatriarch patriarch = sheet1.createDrawingPatriarch(); HSSFClientAnchor anchor = new HSSFClientAnchor(0, 0, 500, 255,(short) 0, 9, (short) 9, 23); patriarch.createPicture(anchor, book.addPicture(outputStream.toByteArray(),HSSFWorkbook.PICTURE_TYPE_JPEG)); book.write(allOutputStream); return new FileTransfer(new String(&quot;Excel标题.xls&quot;.getBytes(&quot;GBK&quot;), &quot;iso8859-1&quot;), &quot;application/xls&quot;, allOutputStream.toByteArray());]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[图形报表使用建议及思维指南]]></title>
      <url>%2F2016%2F02%2F01%2Fchart-advise-thought-intro%2F</url>
      <content type="text"><![CDATA[业界关于图表的软件琳琅满目，例如我常用的echarts、fusionchart，基本上能够满足工作需求，而且自定义功能也很健全。每一款图形报表软件基本都覆盖了折线图、条状图、饼状图、雷达图等等。 这么多种图表,我们该如何选择合适业务场景的图形呢。我也遇到过，设计师给的UI效果图，上面的图形效果真的很美观，但是实际开发出来的效果却和UI效果图相差甚远。其中有很大一部分原因是，真实的生产数据套用在UI给的图表时才发现选择的图形并不适用于当前业务场景，当然也就达不到想要的效果，以至于后来客户不得不经常抱怨说，怎么开发出来的东西和效果图差这么远，怎么拿的出手。后来又找设计师重新针对实际数据进行图形的选择。 关于图形的选择，转载了这么一张图，有需要的大家可以参考下。 最后，图形只是外表，数据才是灵魂，图形只是数据的一种辅助手段。找到了合适的图形，才能达到真正数据可视化的效果。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Linux下部署Nginx服务]]></title>
      <url>%2F2016%2F02%2F01%2FLinux-deploy-nginx%2F</url>
      <content type="text"><![CDATA[这篇主要分享下如何在Linux下部署Nginx服务。Linux环境使用的Ubuntu15.10,使用的Root账户进行安装的。 安装说明：Nginx需要依赖pcre和zlib模块，请大家自行安装，没有安装也没有关系，下面会介绍到如何进行安装的。 1.下载Nginx到Nginx官网下载Nginx软件，我下载的版本是1.9.10 2.切换到root账户，输入命令：sudo su，接着根据提示输入当前账户密码回车 3.解压Nginx输入命令：tar -zxvf nginx-1.9.10.tar.gz 3。进入nginx解压目录输入命令：cd nginx-1.9.10 4.进行Nginx配置输入命令：./configure 注意：Ng是需要依赖PCRE模块和zlib模块的，如果没有安装，这里会配置失败。 出现下面的信息，则表示缺少pcre模块: 我们现在需要下载PCRE库,这里我下载的版本是8.38 解压PCRE库,输入命令:tar -jxvf pcre-8.38.tar.bz2进入到pcre解压目录,输入命令：cd pcre-8.38进行PCRE配置，输入命令：./configure进行PCRE编译，输入命令：make进行PCRE安装，输入命令：make install到这里PCRE就安装完成了。 出现下面的信息，则表示缺少zlib模块: 我们现在需要下载zlib库,这里我下载的版本是1.2.8 解压zlib库,输入命令:tar -zxvf zlib-1.2.8.tar.gz进入到zlib解压目录,输入命令：cd zlib-1.2.8进行zlib配置，输入命令：./configure进行zlib编译，输入命令：make进行zlib安装，输入命令：make install到这里zlib就安装完成了。 接着，我们重新切换到nginx解压目录，执行./configure, 出现下面截图就表示配置成功 5.执行编译输入命令：make 6.执行安装输入命令：make install 到这里我们Ng就安装成功了 7.启动Ng进入到Ng的安装目录,输入命令:cd /usr/local/nginx/sbin启动Ng，输入命令：./nginx 8.重启Ng输入命令：./nginx -s reload 9.验证配置文件是否正确输入命令：./nginx -t 10.关闭ng查询ng进程号,输入命令：ps -ef | grep nginx正常停止： kill -quit 进程号快速停止：kill -term 进程号强制停止：kill -9 进程号 示例 我们利用Ng为两台应用服务器配置负载均衡,两台服务器的访问地址分别是：http://192.168.100.101:8080http://192.168.100.101:8081 第一步：进行nginx.conf文件配置。1、在#gzip on下面新增 upstream local_ng_01{ server 192.168.100.101:8080; server 192.168.100.102:8080; } 2、修改Server的配置 server { listen 80; server_name 192.168.100.88; location / { root html; index index.html index.htm; proxy_pass http://local_ng_01; } } 这样我们在访问192.168.100.88的时候，请求会被均衡到101和102两台服务器上去了 完整nginx.conf配置： #user nobody; worker_processes 4; #error_log logs/error.log; #error_log logs/error.log notice; #error_log logs/error.log info; #pid logs/nginx.pid; events { worker_connections 2048; } http { include mime.types; default_type application/octet-stream; #log_format main &#39;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#39; # &#39;$status $body_bytes_sent &quot;$http_referer&quot; &#39; # &#39;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&#39;; access_log logs/access.log; client_header_timeout 3m; client_body_timeout 3m; send_timeout 3m; client_header_buffer_size 1k; sendfile on; tcp_nopush on; tcp_nodelay on; #keepalive_timeout 0; #keepalive_timeout 65; #gzip on; upstream local_ng_01{ server 192.168.100.101:8080; server 192.168.100.102:8080; } server { listen 80; server_name 192.168.100.88; #charset koi8-r; #access_log logs/host.access.log main; location / { root html; index index.html index.htm; proxy_pass http://local_ng_01; } #error_page 404 /404.html; # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; location = /50x.html { root html; } # proxy the PHP scripts to Apache listening on 127.0.0.1:80 # #location ~ \.php$ { # proxy_pass http://127.0.0.1; # } # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000 # #location ~ \.php$ { # root html; # fastcgi_pass 127.0.0.1:9000; # fastcgi_index index.php; # fastcgi_param SCRIPT_FILENAME /scripts$fastcgi_script_name; # include fastcgi_params; # } # deny access to .htaccess files, if Apache&#39;s document root # concurs with nginx&#39;s one # #location ~ /\.ht { # deny all; # } } # another virtual host using mix of IP-, name-, and port-based configuration # #server { # listen 8000; # listen somename:8080; # server_name somename alias another.alias; # location / { # root html; # index index.html index.htm; # } # } # HTTPS server # #server { # listen 443 ssl; # server_name localhost; # ssl_certificate cert.pem; # ssl_certificate_key cert.key; # ssl_session_cache shared:SSL:1m; # ssl_session_timeout 5m; # ssl_ciphers HIGH:!aNULL:!MD5; # ssl_prefer_server_ciphers on; # location / { # root html; # index index.html index.htm; # } # } } 最后，一开始我将Nginx是部署在Windows上的，测试的时候，性能反而比直接访问应用服务器还要慢，不明白为何还要弄个windows版本的ng出来，所以还是让ng静静的运行在linux上吧]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[使用SQLLDR将CSV数据导入到Oracle数据库]]></title>
      <url>%2F2016%2F02%2F01%2Fuse-sqlldr-csv-to-oracle%2F</url>
      <content type="text"><![CDATA[这篇分享下使用SQLLDR工具将CSV表中的数据导入到Oracle数据库中。SQLLDR是Oracle下提供的一款数据导入工具，使用简单方便，推荐有需要的使用. 命令如下：sqlldr 用户名/密码@SID control=SQLLDR语法文件(例如：control.ctl) control.ctl文件内容： LOAD DATA INFILE &#39;D:\data\inputData.csv&#39; --要导入到数据库中的数据文件 INFILE &#39;D:\data\inputData2.csv&#39; --可以导入多个文件 BADFILE &#39;D:\data\error\bad.bad&#39; --导入失败后要写入的文件 DISCARDFILE &#39;D:\data\dsc\datadsc.dsc&#39; DISCARDMAX 1000 append --表示向表中追加数据(其他选项请参考下面变量说明) INTO TABLE top_excel_import_data --插入的数据库表名 FIELDS TERMINATED BY &#39;,&#39; --以&quot;,&quot;号分隔 TRAILING NULLCOLS --允许插入空值 ( id , --数据库字段名 name , age ) 变量说明：append：向表中追加数据insert：向表中插入值，但要求表开始时为空replace：delete表中的数据，然后插入新值truncate：trunctate表，然后插入新值]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[UML类图符号变量介绍]]></title>
      <url>%2F2016%2F02%2F01%2Fuml-class-symbol-intro%2F</url>
      <content type="text"><![CDATA[这篇主要分享UML类图符号变量的介绍，画图工具使用的是PowerDeisgner15 1.类（Class）： 使用三层矩形框表示。 第一层显示类的名称，如果是抽象类，则就用斜体显示。 第二层是字段和属性。 第三层是类的方法。注意前面的符号，+表示public，-表示private，#表示protected。 2.接口：使用两层矩形框表示，与类图的区别主要是顶端有interface显示。 第一层是接口名称。 第二层是接口方法。 3.继承类（extends）：用空心三角形+实线来表示。 4.实现接口（implements）：用空心三角形+虚线来表示 5.关联（Association）：用实线箭头来表示，例如：燕子与气候 6.聚合（Aggregation）：用空心的菱形+实线箭头来表示。 表示一种拥有关系，体现的是A对象可以包含B对象，但B对象不是A对象的一部分，例如：公司和员工 7.组合（Composition）：用实心的菱形+实线箭头来表示。 部分和整体的关系，并且生命周期是相同的。例如：人与手。 8.依赖（Dependency）：用虚线箭头来表示，例如：动物与氧气。 9.基数：连线两端的数字表明这一端的类可以有几个实例，比如：一个鸟应该有两只翅膀。如果一个类可能有无数个实例，则就用n来表示。关联、聚合、组合]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Data Files的使用]]></title>
      <url>%2F2016%2F02%2F01%2Fnode-js-dataFiles%2F</url>
      <content type="text"><![CDATA[这篇主要分享Hexo中DataFiles的使用,记录这篇的原因是，官网提供的DataFiles Doc介绍在我本地没有运行出效果来。下面是官网的Doc：步骤很简单第一步：在source下面新建_data目录，目录下面就是定义的数据文件。可支持yml格式文件。第二步：在模版文件(ejs、swig)中使用for标签进行迭代输出。但是，实际运行的效果是页面不解析这种for标签写法,直接将标签源码输出查看本地hexo版本： 修改后的for标签写法： &lt;% if (site.data.menu) { %&gt; &lt;% for (item in site.data.menu) { %&gt; &lt;li&gt;&lt;%= item %&gt; &lt;%= site.data.menu[item] %&gt;&lt;/li&gt; &lt;% } %&gt; &lt;% } %&gt; 到这里，数据就能正常输出到页面了。 参考：http://ammonsonline.com/using-hexo-data-files/]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Git最最最基础命令入门]]></title>
      <url>%2F2016%2F01%2F29%2Fgit-basic-cmd-intro%2F</url>
      <content type="text"><![CDATA[这篇只是和大家分享下Git的最简单的基础命令入门目录 创建版本库 从版本库下载文件到本地 提交文件到版本库 创建版本库 直接登录github网站创建一个reps,这里就不具体描述了，我创建的resp就命名为test-git，地址为：https://github.com/linmuxi/test-git.git 从版本库下载文件到本地 输入命令：git clone http://github.com/linmuxi/test-git.git E:\demo\git&gt;git clone http://github.com/linmuxi/test-git.git Cloning into &#39;test-git&#39;... remote: Counting objects: 3, done. remote: Total 3 (delta 0), reused 0 (delta 0), pack-reused 0 Unpacking objects: 100% (3/3), done. Checking connectivity... done. 这样就把我们刚才创建的test-git下载到本地了,对应我本地目录就是：E\demo\git\test-git 提交文件到版本库 假如，我在test-git目录下面增加了一个hello-world.txt文件，那么如何把它提交到版本库上去呢。这里我们描述细致点。路径切换到包含.git的目录也就是test-git目录下面来先输入命令查看工作树状态:git status E:\demo\git\test-git&gt;git status On branch master Your branch is up-to-date with &#39;origin/master&#39;. Untracked files: (use &quot;git add &lt;file&gt;...&quot; to include in what will be committed) hello-world.txt nothing added to commit but untracked files present (use &quot;git add&quot; to track) 可以看到系统提示hello-world.txt文件在本地工作树中找不到踪迹，并提示我们使用’git add’来进行操作。 接着输入命令：git add hello-world.txt到这一步,文件hello-world.txt就被添加到索引中了 然后再次查看工作树状态：git status E:\demo\git\test-git&gt;git status On branch master Your branch is up-to-date with &#39;origin/master&#39;. Changes to be committed: (use &quot;git reset HEAD &lt;file&gt;...&quot; to unstage) new file: hello-world.txt 系统提示检测到了一个新的文件，并提示我们使用’git reset head’来进行操作，我们的目的是要将文件提交到版本库，这里就不能使用这个命令了。 我们改输入命令：git commit -m &quot;new file helloworld.txt&quot; E:\demo\git\test-git&gt;git commit -m &quot;new file helloworld.txt&quot; [master 2d620a7] new file helloworld.txt 1 file changed, 0 insertions(+), 0 deletions(-) create mode 100644 hello-world.txt 到这一步，文件hello-world.txt就被添加到本地库了，此时还没有提交到github远程库中去。 再次查看工作树状态：git status E:\demo\git\test-git&gt;git status On branch master Your branch is ahead of &#39;origin/master&#39; by 1 commit. (use &quot;git push&quot; to publish your local commits) nothing to commit, working directory clean 系统提示没有任何可以提交的文件，工作目录是干净的。 接下来，我们就要把提交到本地库中的hello-world.txt文件同步到github运程库中去了使用命令:git push -u origin master E:\demo\git\test-git&gt;git push -u origin master error: cannot spawn sh: No such file or directory Username for &#39;https://github.com&#39;: linmuxi Password for &#39;https://linmuxi@github.com&#39;: error: cannot spawn sh: No such file or directory Counting objects: 3, done. Delta compression using up to 4 threads. Compressing objects: 100% (2/2), done. Writing objects: 100% (3/3), 285 bytes | 0 bytes/s, done. Total 3 (delta 0), reused 0 (delta 0) To http://github.com/linmuxi/test-git.git 24c6ae3..2d620a7 master -&gt; master Branch master set up to track remote branch master from origin. 在输入github账户和密码之后，文件hello-world.txt就被同步到github上去了 会用到基础命令： git --help #查看git命令帮助 git log #查看所有提交的日志记录 git log -2 #查看最近2次提交的日志记录 git status #查看本地工作树的状态 git add . #添加所有文件到索引 git add newFile.txt #添加newFile.txt文件到索引 git commit -m &quot;你好&quot; #将索引中的文件提交到本地库中 git clone giturl #从版本库下载代码 git rm newFile.txt --cached #将newFile.txt从索引中移出 git checkout newFile.txt #撤销newFile.txt的修改]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Hexo其他辅助功能分享]]></title>
      <url>%2F2016%2F01%2F29%2Fhexo-other-assist-func%2F</url>
      <content type="text"><![CDATA[这是关于Hexo的第三篇文章了，这里主要分享下Hexo上一些辅助功能项。目录： fancybox使用 取消默认hexo处理文件 文章摘要 自定义目录 草稿文章的处理 百度统计 自定义挂件 配置404页面 图床 博客访问量统计 fancybox使用 fancybox效果使用，就是在文章头部增加可以切换显示的图片效果，具体效果如下： 具体配置是在文章头部添加photos配置项： --- photos: - http://7xqlat.com1.z0.glb.clouddn.com/gaoqing1.jpg - http://7xqlat.com1.z0.glb.clouddn.com/gaoqing2.jpg --- 取消默认hexo处理文件 如果不想让hexo默认处理文章，可以在文章头部定义：layout: false --- layout: false --- 文章摘要 在首页只显示more以上的内容，余文需要点击【&gt; Read More】连接打开全文才能显示，效果如下：具体配置是使用&lt;!-more–&gt;: --- # layout: false title: Hexo其他辅助功能分享 date: 2016-01-29 09:09:50 tags: [第一次] categories: [日志,生活] photos: - http://7xqlat.com1.z0.glb.clouddn.com/gaoqing1.jpg - http://7xqlat.com1.z0.glb.clouddn.com/gaoqing2.jpg --- 上面都是在首页显示的摘要信息 &lt;!--more--&gt; 这里是正文信息，只有点击首页的more连接才会显示 自定义目录 使用命令：hexo new page about在source下面会创建一个about目录，里面有个index.md文件将自定义目录挂接到博客首页菜单上去，需要在全局配置文件_config.yml中的menu下面新增About: about即可，其中About是在页面显示的名称，可自定义，about是新创建的目录，名称必须一致 草稿文章的处理 在source/_drafts目录下面存放的是草稿文章，默认情况下草稿文章是不会发布到博客上面去，可以通过以下两种方式进行发布。1、修改全局配置文件_config.yml的render_drafts为true，此时文章还在_drafts目录下面2、可以通过如下命令将文章迁移到_post目录进行发布，此时文章就在_post目录下面了，_drafts目录下就会被删除掉hexo publish draft 草稿文件名称新增草稿文章有两种方式：1、自己手动在_drafts目录下新建md文件。2、通过下面命令来新建hexo new draft 草稿名称 百度统计 百度统计，可以对博客网站的UV、PV等情况进行监控统计。第一步，需要到百度统计去注册账户第二步，登录百度统计管理平台，在网站中心选项卡配置我们的博客地址信息第三步，获取统计的JS代码第四步，在themes/主题/layout/_partial目录下面新建baidu_tongji.ejs文件，将复制的统计js代码粘贴进去，可以在主题_config.yml配置文件中定义一个变量来控制是否启用百度统计。 &lt;% if(theme.baidu_tongji){ %&gt; &lt;!-- baidu统计 --&gt; &lt;script&gt; var _hmt = _hmt || []; (function() { var hm = document.createElement(&quot;script&quot;); hm.src = &quot;//hm.baidu.com/hm.js?265d75f1ac95ef1760822f57dba2111c&quot;; var s = document.getElementsByTagName(&quot;script&quot;)[0]; s.parentNode.insertBefore(hm, s); })(); &lt;/script&gt; &lt;!-- baidu统计end --&gt; &lt;% } %&gt; 第五步，编辑同目录下面的head.ejs，在&lt;/head&gt;之前增加代码 &lt;!-- 添加baidu统计 --&gt; &lt;%- partial(&#39;baidu_tongji&#39;) %&gt; &lt;!-- end 添加baidu统计 --&gt; 第六步，发布hexo博客到github，不知道怎么发布可以参看第一篇文章《使用Hexo在Github上构建免费Blog应用》第七步，在百度统计管理平台-网站中心去验证下首页代码是否安装正确第八步，如果安装正确，一般过24小时就可以百度统计就可以采集到博客的统计信息了 自定义挂件 在博客的右边显示了很多挂件，hexo默认提供了5个挂件：分类、最近发布的文章、标签、标签云、查询自定义挂件第一步在themes/主题/layout/_widget目录下面新建myWidget.ejs文件 &lt;div class=&quot;widget tag&quot;&gt; &lt;h3 class=&quot;title&quot;&gt;自定义挂件&lt;/h3&gt; &lt;ul class=&quot;entry&quot;&gt; &lt;li&gt;自定义挂件1&lt;/li&gt; &lt;li&gt;自定义挂件2&lt;/li&gt; &lt;li&gt;自定义挂件3&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;404&quot;&gt;404&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; 第二步：编辑主题下面的配置文件_config.yml,在widgets变量下面增加新建的自定义挂件ejs文件名 widgets: - search - category - tag - recent_posts - tagcloud - myWidget 第三步：重启服务并访问其实自定义挂件这里可以放些第三方的小插件等等.. 配置404页面 404页面，用于在请求不到对应资源的时候响应给用户的界面。关于404页面，我们可以做的更有意义些，有很多关于404的公益项目，在这里我们选择腾讯公益404。第一步，在blog根目录下面新建404.html，将腾讯公益404js代码粘贴进去&lt;script type=&quot;text/javascript&quot; src=&quot;http://www.qq.com/404/search_children.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;第二步，发布blog到github上面，本地是无法看到效果的，一定要发布到github上面去。第三步，查看效果 图床 之前把所有图片都托管在github上，发现访问有点慢，后来改把所有图片资源都放到七牛云上托管了，速度还可以。七牛注册成功后，会有10GB永久免费存储空间+每月10GB下载流量、10万次PUT请求、100万次Get请求，对于目前个人博客来说已经够用了。在这里我也发一个七牛邀请码 先到这里，下面以后再补上 博客访问量统计]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Hexo博客配置留言和分享功能]]></title>
      <url>%2F2016%2F01%2F28%2Fhexo-config-leave-message-shared%2F</url>
      <content type="text"><![CDATA[接上一篇《使用Hexo在Github上构建免费Blog应用》，这篇介绍下如何在Hexo博客上配置留言和分享功能。我们的留言控件采用多说这款插件，话不多说，直接进入主题吧。 第一步，打开多说官网,点击“我要安装”，然后选择登录模式，这里可以选择QQ、微信、baidu等账户进行登录 第二步，登录成功后，是多说的管理平台，在左边的导航栏选择“工具”菜单，然后获取插件代码。 第三步，将代码拷贝到comment.ejs文件中。注意comment.ejs在themes/light/layout/_partial/目录下面，我们可以在全局配置文件_config.yml中添加一个变量duoshuo来控制是否显示多说留言控件。需要根据自身情况修改data-thread-key、data-title、data-url属性值。 第四步，重启hexo，打开浏览器访问http://localhost:4000 查看一篇博客，可以看到我们的多说留言已经集成到博客上面去了 到这里，多说留言插件就已经正常集成到我们的博客上去了。对于留言的管理，我们可以登录到多说提供的管理平台上去操作，具体的操作步骤就不在本篇讨论了。 接下来，我们配置下分享功能，这里还是采用多说提供的控件 第一步，登录多说管理平台，点击左边菜单“分享”按钮，选好样式之后复制生成的代码。 第二步，将代码拷贝到share.ejs文件中。注意share.ejs在themes/light/layout/_partial/post/目录下面，我们可以在themes目录下的配置文件_config.yml中添加一个变量addthis/shared来控制分享功能的显示。同样，这里需要根据自身情况修改data-thread-key、data-title、data-images、data-content、data-url属性值 第三步，重启hexo，打开浏览器访问http://localhost:4000 查看一篇博客，可以看到我们的分享功能已经集成到博客上面去了 到这里，留言、分享功能就已经全部集成到我们的博客上面去了。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[使用Hexo在Github上构建免费Blog应用]]></title>
      <url>%2F2016%2F01%2F27%2Fhexo-on-github-build-blog%2F</url>
      <content type="text"><![CDATA[&nbsp;&nbsp;&nbsp;&nbsp;”A fast, simple &amp; powerful blog framework”这是Hexo官方上面的介绍，Hexo是基于Node.js的一个静态blog框架，通过Hexo可以仅仅使用几条简短的命令就能方便我们快速创建自己的blog。Hexo可以部署在Node服务器上，也可以部署在github上面。当然部署在github上好处多多，不紧可以省去服务器的成本，还可以免去了相关系统运维方便的事情。目录 Hexo介绍 Hexo安装 Hexo使用 Hexo发布到Github Hexo主题 Hexo介绍 &nbsp;&nbsp;&nbsp;&nbsp;”A fast, simple &amp; powerful blog framework”这是Hexo官方上面的介绍，Hexo是基于Node.js的一个静态blog框架，通过Hexo可以仅仅使用几条简短的命令就能方便我们快速创建自己的blog。Hexo可以部署在Node服务器上，也可以部署在github上面。当然部署在github上好处多多，不紧可以省去服务器的成本，还可以免去了相关系统运维方便的事情。 Hexo安装 #查看Node版本 E:\demo\nodejs&gt;node -v v0.12.7 #查看Npm版本 E:\demo\nodejs&gt;npm -v 3.5.3 #全局安装hexo-cli E:\demo\nodejs&gt;npm install hexo-cli -g #查看hexo版本 E:\demo\nodejs&gt;hexo -v hexo-cli: 0.2.0 os: Windows_NT 6.1.7601 win32 x64 http_parser: 2.3 node: 0.12.7 v8: 3.28.71.19 uv: 1.6.1 zlib: 1.2.8 modules: 14 openssl: 1.0.1p #初始化hexo E:\demo\nodejs&gt;hexo init blog INFO Cloning hexo-starter to E:\demo\nodejs\blog Cloning into &#39;E:\demo\nodejs\blog&#39;... remote: Counting objects: 40, done. remote: Total 40 (delta 0), reused 0 (delta 0), pack-reused 40 Unpacking objects: 100% (40/40), done. #安装hexo E:\demo\nodejs&gt;cd blog&amp;npm install #启动hexo E:\demo\nodejs\blog&gt;hexo server INFO Hexo is running at http://0.0.0.0:4000/. Press Ctrl+C to stop. 到这里Hexo就搭建好了,打开浏览器访问：http://localhost:4000 正常情况会显示如下 Hexo使用 1、Hexo目录和文件node_modules:依赖的nodejs模块文件scaffolds：工具模版文件，文件以md扩展名，语法采用markdownsource:存放blog正文内容source_posts:正式发布内容themes:存放blog皮肤样式目录themes\landscape:blog默认样式目录_config.yml:全局配置文件 2、_config.yml全局配置文件，很多网站的相关信息都在这里面进行配置，例如等会要进行配置的root、deploy等属性。 3、hexo -h可以通过help查看hexo可以使用的命令，常用的例如有init、generate、clean、publish、new等。 4、创建新文章有两种方式创建文章：1：手动在_post目录下面添加md文件2：通过hexo命令创建 E:\demo\nodejs\blog&gt;hexo new first INFO Created: E:\demo\nodejs\blog\source\_posts\first.md 可以看到在_post目录下新增了first.md文件再次访问：http://localhost:4000 可以发现我们刚才新加的文章已经发布上去了。 5、语法关于文章内容采用的语法是有要求的，包括以下三部分：1：基本信息：标题，发布日期，分类目录，标签，类型，固定发布链接2：正文：markdown语法和Swig语法(掌握一个就行)3：特殊标记：引用，链接，图片，代码块，iframe编辑文章内容： --- title: 我的第一篇文章 date: 2016-01-26 14:45:07 tags: - 第一次 - 日记 categories: - 日志 - 2015 - 01 - 26 --- 这是**我的第一篇文章**，是用hexo创建的。 # 引用 ** Markdown语法 ** &gt; Every interaction is both precious and an opportunity to delight. # 代码块 ** Markdown语法 ** `compact([0,1,false,2,&#39;&#39;,3]);` # 链接 ** Markdown语法 ** [我的日志](http://www.linmuxi.com) # 图片 * 图片，对于本地图片，需要在source目录下面新建一个images目录存放图片 * ** Markdown语法 ** ![这是第一张图片](images/1.png) ![这是第一张图片](http://linmuxi.github.io/me/project/realtimeData/images/realtimeData_02.png) Hexo发布到Github 1、静态化处理github只托管静态文件，所以这里我们需要将hexo项目的node剥离出来生成只包括html、js、css文件的静态资源文件。使用hexo提供的命令可以轻松实现: E:\demo\nodejs\blog&gt;hexo generate INFO Files loaded in 314 ms INFO Generated: js/script.js INFO Generated: fancybox/jquery.fancybox.pack.js ... INFO 36 files generated in 907 ms 生成的静态文件全部都在更目录下的public文件夹下面。 2、发布到Github1：在github上新建rep、gh-pages分支这里我的rep命名为：nodejs-hexo2：修改_config.yml root: /nodejs-hexo deploy: type: git repo: https://github.com/linmuxi/nodejs-hexo.git branch: gh-pages 注意：编辑的时候注意空格问题，冒号后面是有空格的。 Hexo主题 Hexo默认主题是landscape，我们可以到Hexo网站去下载其他主题并应用到我们的blog上面去。首先，找到我们需要的主题git地址，并下载到Hexo根目录下面的thems文件夹下。 E:\demo\nodejs\blog&gt;git clone git://github.com/tommy351/hexo-theme-light.git the mes/light Cloning into &#39;themes/light&#39;... remote: Counting objects: 892, done. rRemote: Total 892 (delta 0), reused 0 (delta 0), pack-reused 892eceiving object Receiving objects: 94% (839/892), 156.01 KiB | 124.00 KiB/s Receiving objects: 100% (892/892), 346.40 KiB | 124.00 KiB/s, done. Resolving deltas: 100% (391/391), done. Checking connectivity... done. 这样主题文件就下载好了，然后修改全局配置文件_config.xml,将theme的值改成对应的them文件夹名称，这里我们下载的是light。直接就可以打开浏览器输入：http://localhost:4000 查看应用新主题之后的效果了。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Node.js基础中间件Connect]]></title>
      <url>%2F2016%2F01%2F26%2Fnode-js-connect%2F</url>
      <content type="text"><![CDATA[什么是中间件？什么是Connect？中间件应该是个比较广的概念，我们常常听到或接触到的例如有ESB中间件、消息中间件、应用服务器中间件等等,百度之概念为中间件是一种独立的系统软件或服务程序，分布式应用软件借助这种软件在不同的技术之间共享资源。 Connect是Node平台的中间件框架，著名的Express就是基于Connect的。 Nodejs提供了20多种内置的中间件： logger: 用户请求日志中间件 csrf: 跨域请求伪造保护中间件 compress: gzip压缩中间件 basicAuth: basic认证中间件 bodyParser: 请求内容解析中间件 json: JSON解析中间件 urlencoded: application/x-www-form-urlencode请求解析中间件 multipart: multipart/form-data请求解析中间件 timeout: 请求超时中间件 cookieParser: cookie解析中间件 session: 会话管理中间件 cookieSession: 基于cookies的会话中间件 methodOverride: HTTP伪造中间件 reponseTime: 计算响应时间中间件 staticCache: 缓存中间件 static: 静态文件处理中间件 directory: 目录列表中间件 vhost: 虚拟二级域名映射中间件 favicon: 网页图标中间件 limit: 请求内容大小限制中间件 query: URL解析中间件 errorHadnler: 错误处理中间件 当然还有很多第三方中间件 关于内置中间件的具体用法可以参考：Nodejs内置中间件用法 Nodejs内置中间件API 这里，我们主要分享下如何实现自定义中间件,下面我们定义了一个中间件，处理逻辑是禁止早上9点以前的访问： var connect = require(&quot;connect&quot;); var app = connect(); //注册自定义中间件(将中间件添加到中间件队列中，等待事件触发执行) app.use(access).use(test); function access(req,res,next){ var hour = new Date().getHours(); if(hour &lt; 9){ res.writeHead(503,{&quot;Content-Type&quot;:&quot;text/plain;charset=utf-8&quot;}); res.end(&quot;禁止访问&quot;); }else{ next();//转入下一个中间件处理 } } function test(req,res,next){ res.writeHead(200,{&quot;Content-Type&quot;:&quot;text/plain&quot;}); res.end(&quot;Hello World !!!&quot;); } app.listen(3000); 其实我对中间件的理解就是，定义一个函数对象并注册到中间件队列中，然后等待事件触发进行回调该函数对象。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Node.js日志管理log4js]]></title>
      <url>%2F2016%2F01%2F25%2Fnode-js-log4js%2F</url>
      <content type="text"><![CDATA[Nodejs采用log4js进行日志管理，log4js的输出级别有6个: trace, debug, info, warn, error, fatal 安装log4js npm install log4js 代码app.js var express = require(&quot;express&quot;); var app = express(); var log4js = require(&quot;./logger&quot;); var logger = log4js.logger(&quot;normal&quot;,&quot;info&quot;); /** 日志级别对应规则： http responses 3xx, level = WARN http responses 4xx &amp; 5xx, level = ERROR else, level = INFO **/ app.use(log4js.connectLogger(logger,{level:&quot;auto&quot;})); app.all(&quot;*&quot;,function(req,res,next){ logger.info(req.ip+&quot; &quot;+req.originalUrl+&quot; access&quot;); next(); }); app.all(&quot;/hello&quot;,function(req,res,next){ res.sendfile(&quot;hello.html&quot;); }); app.all(&quot;/hello2&quot;,function(req,res,next){ res.send(&quot;hello&quot;); }); app.listen(3000,function(){ logger.trace(&quot;服务启动trace&quot;); logger.debug(&quot;服务启动debug&quot;); logger.info(&quot;服务启动info&quot;); logger.warn(&quot;服务启动warn&quot;); logger.error(&quot;服务启动error&quot;); logger.fatal(&quot;服务启动fatal&quot;); console.log(&quot;服务启动console.log&quot;); }); 代码logger.js var log4js = require(&quot;log4js&quot;); log4js.configure({ appenders:[ { type:&quot;console&quot;//控制台输出日志 }, { type:&quot;file&quot;,// 文件记录日志 filename:&#39;logs/access.log&#39;,// logs目录必须手动新建 maxLogSize:1024,//文件最大size 单位：K backups:3,// 备份文件总数,默认1 category:&#39;normal&#39;//日志类型，下面getLogger对象就是根据这个 } ], replaceConsole:true //以[INFO] console代替console默认样式 }); exports.logger = function(category,level){ var logger = log4js.getLogger(category); logger.setLevel(level); return logger; } exports.connectLogger = function(logger,options){ return log4js.connectLogger(logger,options); } 运行输出]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Node.js+Express+ejs基础入门]]></title>
      <url>%2F2016%2F01%2F19%2Fnodejs-express-ejs-demo01%2F</url>
      <content type="text"><![CDATA[学习Nodejs、express做的一个简单分页查询，前端分页控件用的是bootstrap-paginator dbhelper var mysql = require(&quot;mysql&quot;); var pool = mysql.createPool({ host:&quot;localhost&quot;, user:&quot;root&quot;, password:&quot;root&quot;, database:&quot;mydb&quot;, port:&quot;3306&quot;, connectionLimit:10 }); var helper = function(){ this.query = function(sql,callback){ pool.getConnection(function(err,conn){ if(err)console.log(&quot;获取连接失败,%s&quot;,err); conn.query(sql,function(err,rows,fields){ if(err)console.log(&quot;查询失败,%s&quot;,err); callback(rows); }); conn.release(); }); }; this.insert = function(sql,callback){ pool.getConnection(function(err,conn){ if(err)console.log(&quot;获取连接失败,%s&quot;,err); conn.query(sql,function(err,res){ if(err)console.log(&quot;新增失败,%s&quot;,err); callback(res.insertId); }); conn.release(); }); }; this.update = function(sql,callback){ pool.getConnection(function(err,conn){ if(err)console.log(&quot;获取连接失败,%s&quot;,err); conn.query(sql,function(err,res){ if(err)console.log(&quot;修改失败,%s&quot;,err); //callback(res.changedRows); callback(res.affectedRows); }); conn.release(); }) }; this.delete = function(sql,callback){ pool.getConnection(function(err,conn){ if(err)console.log(&quot;获取连接失败,%s&quot;,err); conn.query(sql,function(err,res){ if(err)console.log(&quot;删除失败,%s&quot;,err); callback(res.affectedRows); }); conn.release(); }) } } exports.helper = helper; Controller var fs = require(&quot;fs&quot;); var express = require(&quot;express&quot;); var app = express(); app.set(&quot;view engine&quot;,&quot;ejs&quot;); app.set(&quot;views&quot;,&quot;../views&quot;); var dbhelper = require(&quot;./dbhelper&quot;); var helper = new dbhelper.helper(); var rootContext = &quot;/test&quot;; function wrapRootContextUrl(url){ return rootContext+url; } //静态资源托管 app.use(wrapRootContextUrl(&quot;/user&quot;),express.static(&quot;../../nodejs-paginator&quot;)); app.get(&#39;/(test)?&#39;,function(req,res,next){ res.send(&quot;welcome!&quot;); }); app.get(wrapRootContextUrl(&quot;/user/userList&quot;),function(req,res,next){ var p = req.query.p; var limit = req.query.limit; var data = {currentPage:p,totalPages:0}; helper.query(&quot;select count(1) count from user_info&quot;,function(result){ if(result){ data.totalPages = Math.ceil(result[0].count/limit); //console.log(&quot;获取总数：&quot;+data.totalPages); } helper.query(&quot;SELECT id,user_name userName,PASSWORD password FROM user_info LIMIT &quot;+(p-1)*limit+&quot;,&quot;+limit,function(result){ data.items = result; //console.log(&quot;返回前获取：&quot;+data.totalPages); res.render(&quot;index&quot;,data); }); }); }); app.listen(3000,function(){ console.log(&quot;服务启动&quot;); }); Ejs模版 &lt;!DOCTYPE html&gt; &lt;html lang=&quot;en&quot;&gt; &lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;用户列表&lt;/title&gt; &lt;link rel=&quot;stylesheet&quot; href=&quot;css/bootstrap-responsive.css&quot;&gt; &lt;link rel=&quot;stylesheet&quot; href=&quot;css/bootstrap.css&quot;&gt; &lt;link rel=&quot;stylesheet&quot; href=&quot;css/documentation.css&quot;&gt; &lt;link rel=&quot;stylesheet&quot; href=&quot;css/highlight.js/sunburst.css&quot;&gt; &lt;script src=&quot;lib/jquery.min.js&quot;&gt;&lt;/script&gt; &lt;script src=&quot;lib/bootstrap.min.js&quot;&gt;&lt;/script&gt; &lt;script src=&quot;lib/bootstrap-paginator.js&quot;&gt;&lt;/script&gt; &lt;/head&gt; &lt;body&gt; &lt;table border=&quot;1&quot; style=&quot;width:300px;margin:0 auto;margin-top:10px;&quot;&gt; &lt;tr&gt; &lt;td&gt;ID&lt;/td&gt; &lt;td&gt;UserName&lt;/td&gt; &lt;td&gt;Password&lt;/td&gt; &lt;/tr&gt; &lt;%for(var i = 0;i&lt;items.length;i++){ %&gt; &lt;tr&gt; &lt;td&gt;&lt;%=items[i].id%&gt;&lt;/td&gt; &lt;td&gt;&lt;%=items[i].userName%&gt;&lt;/td&gt; &lt;td&gt;&lt;%=items[i].password%&gt;&lt;/td&gt; &lt;/tr&gt; &lt;%}%&gt; &lt;/table&gt; &lt;div id=&quot;example&quot;&gt;&lt;/div&gt; &lt;script type=&quot;text/javascript&quot;&gt; var options = { currentPage:&quot;&lt;%=currentPage%&gt;&quot;, totalPages:&quot;&lt;%=totalPages%&gt;&quot;, size:&quot;large&quot;, alignment:&quot;center&quot;, itemContainerClass: function (type, page, current) { return (page === current) ? &quot;active&quot; : &quot;pointer-cursor&quot;; }, onPageClicked: function(e,originalEvent,type,page){ //alert(&quot;Page item clicked, type: &quot;+type+&quot; page: &quot;+page); }, onPageChanged: function(e,oldPage,newPage){ //alert(&quot;Current page changed, old: &quot;+oldPage+&quot; new: &quot;+newPage); }, pageUrl:function(type,page,current){ return &quot;/Test/user/userlist?p=&quot;+page+&quot;&amp;limit=5&quot;; } } $(&quot;#example&quot;).bootstrapPaginator(options); &lt;/script&gt; &lt;/body&gt; &lt;/html&gt;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Node.js入门]]></title>
      <url>%2F2016%2F01%2F17%2Fnode-js-intro%2F</url>
      <content type="text"><![CDATA[本篇主要分享Node环境安装和Hello World示例目录： Node.js介绍 安装Node环境 Hello World！ Node.js介绍Node.js® is a JavaScript runtime built on Chrome’s V8 JavaScript engine. Node.js uses an event-driven, non-blocking I/O model that makes it lightweight and efficient. Node.js’ package ecosystem, npm, is the largest ecosystem of open source libraries in the world.Node.js是基于Chrome V8 JavaScript引擎构建的JavaScript运行时环境，Node.js使用事件驱动、非阻塞式I/O模型，使其轻量又高效。Node.js的包管理器npm，是全球最大的开源库生态系统。 安装Node环境 本章节介绍window和Linux下安装Node的方法。Node.js安装包及源码下载地址：https://nodejs.org/en/download/ Window上安装Node.js1、window安装包(.msi)下载对应操作系统的msi文件，按照提示步骤进行安装，安装完成后，检测PATH环境变量是否包含Nodejs,没有包含则需要将Nodejs的安装路径配置到PATH中。安装配置完成后，在dos命令中输入:node -v 进行检测。 Linux上安装Node.js1、源码安装 从Github上获取Node.js源码：sudo git clone https://github.com/nodejs/node.git 创建编译文件：sudo ./configure 编译：sudo make 安装：sudo make install 查看版本：node -v 2、apt-get安装命令：sudo apt-get install nodejs 安装nodejs命令：sudo apt-get install npm 安装npm Hello World 1、交互模式打开终端，输入node回车进入命令交互模式： 2、脚本模式新建文件helloworld.js,内容为：console.log(“Hello World!”);打开终端，输入命令：node helloworld.js]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[WebApp for Android TV]]></title>
      <url>%2F2016%2F01%2F14%2Fwebapp-for-android-tv%2F</url>
      <content type="text"><![CDATA[一款在TV上显示实时交易数据的android应用由于对android这块不是很精通，特别是android做图形化这方面，所以一开始拿到设计效果图就没有考虑用原生android来进行开发，好在项目组也没有做硬性要求。 关于图形报表选择方面，我比较熟悉fusioncharts和echarts，目前个人比较偏向使用echarts，所以就定了这个工具做图形化报表形式。 项目环境是前端我负责，后端其他同事负责，数据交互采用http协议+json格式。 由于页面是采用android的webview嵌入进去的，大家都知道webview的性能确实不咋滴。所以在使用的过程中还是存在很多问题的1、地图图形上的地理位置光标无法正常闪动，暂时也没能解决2、动态刷新图表数据的时候，会出现重影问题。 数据动态刷新是调用echarts的接口方法来实现的，在web浏览器是正常的，但是在tv上就会出现重影的问题，后来没有办法就在每次刷新的时候重新init对象了，问题暂时解决3、动画效果显示会出现卡顿或不显示的问题，后面直接关掉动画效果 android运行环境：4.4.2 全部代码已经提交到github上：https://github.com/linmuxi/realtimeData 实现之后的效果图：]]></content>
    </entry>

    
  
  
</search>
